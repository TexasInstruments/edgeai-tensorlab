{
 "cells": [
  {
   "cell_type": "raw",
   "id": "annual-night",
   "metadata": {},
   "source": [
    "# Copyright (c) 2018-2021, Texas Instruments\n",
    "# All Rights Reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "# * Redistributions of source code must retain the above copyright notice, this\n",
    "#   list of conditions and the following disclaimer.\n",
    "#\n",
    "# * Redistributions in binary form must reproduce the above copyright notice,\n",
    "#   this list of conditions and the following disclaimer in the documentation\n",
    "#   and/or other materials provided with the distribution.\n",
    "#\n",
    "# * Neither the name of the copyright holder nor the names of its\n",
    "#   contributors may be used to endorse or promote products derived from\n",
    "#   this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from jacinto_ai_benchmark import *\n",
    "\n",
    "# the cwd must be the root of the respository\n",
    "if os.path.split(os.getcwd())[-1] == 'scripts' or os.path.split(os.getcwd())[-1] == 'tutorials':\n",
    "    os.chdir('../')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "experienced-lithuania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSDK_BASE_PATH=/user/a0393608/work/code/ti/processor-sdk-vision/ti-processor-sdk-rtos-j721e-evm-07_02_00_06\n",
      "TIDL_BASE_PATH=/user/a0393608/work/code/ti/processor-sdk-vision/ti-processor-sdk-rtos-j721e-evm-07_02_00_06/tidl_j7_01_04_00_08\n",
      "ARM64_GCC_PATH=/user/a0393608/work/code/ti/processor-sdk-vision/ti-processor-sdk-rtos-j721e-evm-07_02_00_06/gcc-arm-9.2-2019.12-x86_64-aarch64-none-linux-gnu\n",
      "LD_LIBRARY_PATH=:/user/a0393608/work/code/ti/bitbucket/processor-sdk-vision/tidl-build-tools/protobuf-3.5.1-fpic/src/.libs:/user/a0393608/work/code/ti/bitbucket/processor-sdk-vision/tidl-build-tools/protobuf-3.5.1-fpic/src/.libs:/user/a0393608/work/code/ti/processor-sdk-vision/ti-processor-sdk-rtos-j721e-evm-07_02_00_06/tidl_j7_01_04_00_08/ti_dl/utils/tidlModelImport/out:/user/a0393608/work/code/ti/processor-sdk-vision/ti-processor-sdk-rtos-j721e-evm-07_02_00_06/tidl_j7_01_04_00_08/ti_dl/rt/out/PC/x86_64/LINUX/release:/user/a0393608/work/code/ti/processor-sdk-vision/ti-processor-sdk-rtos-j721e-evm-07_02_00_06/tidl_j7_01_04_00_08/ti_dl/tfl_delegate/out/PC/x86_64/LINUX/release\n",
      "TIDL_RT_PERFSTATS=1\n"
     ]
    }
   ],
   "source": [
    "# make sure these have been set in the calling environment\n",
    "print(f\"PSDK_BASE_PATH={os.environ['PSDK_BASE_PATH']}\")\n",
    "print(f\"TIDL_BASE_PATH={os.environ['TIDL_BASE_PATH']}\")\n",
    "print(f\"ARM64_GCC_PATH={os.environ['ARM64_GCC_PATH']}\")\n",
    "print(f\"LD_LIBRARY_PATH={os.environ['LD_LIBRARY_PATH']}\")\n",
    "print(f\"TIDL_RT_PERFSTATS={os.environ['TIDL_RT_PERFSTATS']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minor-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_file = 'accuracy_minimal_pc.yaml'\n",
    "\n",
    "# number of frames to do import/calibration on - recommended somewhere between 20 to 100\n",
    "num_frames_calib = 10\n",
    "\n",
    "# max number of frames to do inference on. if the dataset has less frames than this, that numerb will be used\n",
    "num_frames = 100\n",
    "\n",
    "# quantization bit precision - 8 or 16 or 32\n",
    "tidl_tensor_bits = 32\n",
    "\n",
    "# wild card list to match against the model_path - only matching models will be run\n",
    "# examples: ['classification'] ['imagenet1k'] ['torchvision']\n",
    "# examples: ['resnet18.onnx', 'resnet50_v1.tflite']\n",
    "# example: None (Note: None means no filter - run all the models)\n",
    "model_selection = ['edgeai-tv/mobilenet_v1_20190906.onnx',\n",
    "                   'torchvision/mobilenet_v2_tv.onnx']\n",
    "\n",
    "# wild card list to match against the tasks. it null, all tasks will be run\n",
    "# example: ['classification', 'detection', 'segmentation']\n",
    "# example: 'classification'\n",
    "# example: None (Note: None means no filter - run all the tasks)\n",
    "task_selection = None\n",
    "    \n",
    "# whether to load the datasets or not. set to False to load no datasets\n",
    "# set to True to try and load all datasets (the dataset folders must be available in ./dependencies/datasets).\n",
    "# for selective loading, provide a list of dataset names such as ['imagenet', 'coco', 'cityscapes', 'ade20k', 'voc2012']\n",
    "dataset_loading = ['imagenet']\n",
    "\n",
    "# for parallel execution on cpu or gpu. if you don't have gpu, these actual numbers don't matter,\n",
    "# but the size of the list determines the number of parallel processes\n",
    "# if you have gpu's these entries can be gpu ids which will be used to set CUDA_VISIBLE_DEVICES\n",
    "# null will run the models sequentially.\n",
    "parallel_devices = [0,1,2,3,0,1,2,3] #None\n",
    "\n",
    "# important parameter. set this to 'pc' to do import and inference in pc\n",
    "# set this to 'evm' to run inference in device. for inference on device run_import\n",
    "# below should be switched off and it is assumed that the artifacts are already created.\n",
    "target_machine = 'pc' #'evm' #'pc'\n",
    "\n",
    "# create the settings object keyword arguments provided here will override what is in the yaml file\n",
    "settings = config_settings.ConfigSettings(settings_file, model_selection=model_selection, \n",
    "                                          task_selection=task_selection, dataset_loading=dataset_loading,\n",
    "                                          num_frames_calib=num_frames_calib, num_frames=num_frames,\n",
    "                                          tidl_tensor_bits=tidl_tensor_bits, target_machine=target_machine,\n",
    "                                          parallel_devices=parallel_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "permanent-canvas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_dir = ./work_dirs/benchmark_modelzoo/32bits\n"
     ]
    }
   ],
   "source": [
    "work_dir = os.path.join('./work_dirs', 'benchmark_modelzoo', f'{settings.tidl_tensor_bits}bits')\n",
    "print(f'work_dir = {work_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the datasets and download if they are missing\n",
    "download_ok = configs.download_datasets(settings)\n",
    "print(f'download_ok = {download_ok}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "devoted-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default configs available\n",
    "pipeline_configs = configs.get_configs(settings, work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pipeline_runner which will manage the sessions.\n",
    "pipeline_runner = pipelines.PipelineRunner(settings, pipeline_configs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "professional-substance",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "# at this point, pipeline_runner.pipeline_configs is a dictionary that has the selected configs\n",
    "\n",
    "# Note: to manually slice and select a subset of configs, slice it this way (just an example)\n",
    "# import itertools\n",
    "# pipeline_runner.pipeline_configs = dict(itertools.islice(pipeline_runner.pipeline_configs.items(), 10, 20))\n",
    "\n",
    "# some examples of accessing params from it - here 0th entry is used an example.\n",
    "# pipeline_config = pipeline_runner.pipeline_configs.values()[0]\n",
    "# pipeline_config['preprocess'].get_param('resize') gives the resize dimension\n",
    "# pipeline_config['preprocess'].get_param('crop') gives the crop dimension\n",
    "# pipeline_config['session'].get_param('run_dir') gives the folder where artifacts are located\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now actually run the configs\n",
    "if settings.run_import or settings.run_inference:\n",
    "    pipeline_runner.run()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the logs and display it\n",
    "if settings.collect_results:\n",
    "    results = pipelines.collect_results(settings, work_dir, print_results=True)\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
