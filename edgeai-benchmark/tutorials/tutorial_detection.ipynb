{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5c3202",
   "metadata": {},
   "source": [
    "## Model Compilation Jupyter Notebook Example\n",
    "\n",
    "This notebook shows the example of model compilation using edgeai-benchmark.\n",
    "\n",
    "This script uses TIDL to compile a model and output in a format that edgeai-sdk can understand.\n",
    "\n",
    "jai_benchmark is a python package provided in edgeai-benchmark that provides several functions to assist model compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fd730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import argparse\n",
    "import cv2\n",
    "from jai_benchmark import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f68d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ssd/files/a0393608/work/code/ti/edgeai-algo/edgeai-benchmark/tidl_tools\n",
      "/data/ssd/files/a0393608/work/code/ti/edgeai-algo/edgeai-benchmark\n"
     ]
    }
   ],
   "source": [
    "# the cwd must be the root of the respository\n",
    "if os.path.split(os.getcwd())[-1] in ('scripts', 'tutorials'):\n",
    "    os.chdir('../')\n",
    "#\n",
    "print(os.environ['TIDL_TOOLS_PATH'])\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4bf6ec",
   "metadata": {},
   "source": [
    "#### Create a temporary directory. \n",
    "\n",
    "This is were the compiled artifacts will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed12c333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TemporaryDirectory '/tmp/tmpxnd97n5t'>\n"
     ]
    }
   ],
   "source": [
    "modelartifacts_tempdir = tempfile.TemporaryDirectory()\n",
    "print(modelartifacts_tempdir)\n",
    "modelartifacts_custom = os.path.join(modelartifacts_tempdir.name, 'modelartifacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acd99c",
   "metadata": {},
   "source": [
    "#### Read settings from settings_import_on_pc.yaml\n",
    "\n",
    "Modify the settings as necessary in the constructor of settings.ConfigSettings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b47491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_dir = /tmp/tmpxnd97n5t/modelartifacts/32bits\n"
     ]
    }
   ],
   "source": [
    "settings = config_settings.ConfigSettings('./settings_import_on_pc.yaml', \n",
    "                modelartifacts_path=modelartifacts_custom,\n",
    "                calibration_frames=10, calibration_iterations=10, num_frames=100)\n",
    "\n",
    "work_dir = os.path.join(settings.modelartifacts_path, f'{settings.tensor_bits}bits')\n",
    "print(f'work_dir = {work_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5937d8b1",
   "metadata": {},
   "source": [
    "#### Create Dataset Reader classes\n",
    "\n",
    "Change the dataset paths according to your dataset location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90745b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "INFO:\u001b[33m20220329-161215: dataset exists - will reuse - \u001b[39m./dependencies/datasets/coco\n",
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[34m\n",
      "INFO:\u001b[33m20220329-161216: dataset exists - will reuse - \u001b[39m./dependencies/datasets/coco\n",
      "loading annotations into memory...\n",
      "Done (t=0.92s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_calib_cfg = dict(\n",
    "    path=f'{settings.datasets_path}/coco',\n",
    "    split='val2017',\n",
    "    shuffle=True,\n",
    "    num_frames=min(settings.calibration_frames,5000),\n",
    "    name='coco'\n",
    ")\n",
    "\n",
    "# dataset parameters for actual inference\n",
    "dataset_val_cfg = dict(\n",
    "    path=f'{settings.datasets_path}/coco',\n",
    "    split='val2017',\n",
    "    shuffle=False, # can be set to True as well, if needed\n",
    "    num_frames=min(settings.num_frames,5000),\n",
    "    name='coco'\n",
    ")\n",
    "\n",
    "calib_dataset = datasets.COCODetection(**dataset_calib_cfg, download=True)\n",
    "val_dataset = datasets.COCODetection(**dataset_val_cfg, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb928333",
   "metadata": {},
   "source": [
    "#### Session runtime_options\n",
    "\n",
    "The default runtime_options can be overriden by passing a runtime_options dict to this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0b4f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jai_benchmark.sessions.tflitert_session.TFLiteRTSession'>\n",
      "{'tensor_bits': 32, 'accuracy_level': 1, 'debug_level': 0, 'priority': 0, 'advanced_options:high_resolution_optimization': 0, 'advanced_options:pre_batchnorm_fold': 1, 'advanced_options:calibration_frames': 10, 'advanced_options:calibration_iterations': 10, 'advanced_options:quantization_scale_type': 0, 'advanced_options:activation_clipping': 1, 'advanced_options:weight_clipping': 1, 'advanced_options:bias_calibration': 1, 'advanced_options:channel_wise_quantization': 0, 'advanced_options:output_feature_16bit_names_list': '', 'advanced_options:params_16bit_names_list': '', 'advanced_options:add_data_convert_ops': 3}\n"
     ]
    }
   ],
   "source": [
    "# choose one session_name depending on the model type\n",
    "# tflitert for tflite models, onnxrt for onnx models, tvmdlr for mxnet models.\n",
    "session_name = constants.SESSION_NAME_TFLITERT\n",
    "#session_name = constants.SESSION_NAME_ONNXRT\n",
    "#session_name = constants.SESSION_NAME_TVMDLR\n",
    "\n",
    "session_type = settings.get_session_type(session_name)\n",
    "runtime_options = settings.get_runtime_options(session_name, is_qat=False)\n",
    "\n",
    "print(session_type)\n",
    "print(runtime_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "049e28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_transforms = preprocess.PreProcessTransforms(settings)\n",
    "postproc_transforms = postprocess.PostProcessTransforms(settings)\n",
    "\n",
    "# these session cfgs also has some default input mean and scale. \n",
    "# if your model needs a difference mean and scale, update the session cfg dict being used with those values\n",
    "onnx_session_cfg = sessions.get_onnx_session_cfg(settings, work_dir=work_dir)\n",
    "tflite_session_cfg = sessions.get_tflite_session_cfg(settings, work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d9087",
   "metadata": {},
   "source": [
    "#### Create pipeline_configs\n",
    "\n",
    "pipeline_configs is nothing but a dict with the various model configs that we want to compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81db0343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'od-mlpefmnv1': {'task_type': 'detection', 'calibration_dataset': <jai_benchmark.datasets.coco_det.COCODetection object at 0x7f75da1296a0>, 'input_dataset': <jai_benchmark.datasets.coco_det.COCODetection object at 0x7f75da129470>, 'preprocess': <jai_benchmark.preprocess.PreProcessTransforms object at 0x7f7685ec2b70>, 'session': <jai_benchmark.sessions.tflitert_session.TFLiteRTSession object at 0x7f75cf3401d0>, 'postprocess': <jai_benchmark.postprocess.PostProcessTransforms object at 0x7f75cf3404a8>, 'metric': {'label_offset_pred': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17, 17: 18, 18: 19, 19: 20, 20: 21, 21: 22, 22: 23, 23: 24, 24: 25, 25: 26, 26: 27, 27: 28, 28: 29, 29: 30, 30: 31, 31: 32, 32: 33, 33: 34, 34: 35, 35: 36, 36: 37, 37: 38, 38: 39, 39: 40, 40: 41, 41: 42, 42: 43, 43: 44, 44: 45, 45: 46, 46: 47, 47: 48, 48: 49, 49: 50, 50: 51, 51: 52, 52: 53, 53: 54, 54: 55, 55: 56, 56: 57, 57: 58, 58: 59, 59: 60, 60: 61, 61: 62, 62: 63, 63: 64, 64: 65, 65: 66, 66: 67, 67: 68, 68: 69, 69: 70, 70: 71, 71: 72, 72: 73, 73: 74, 74: 75, 75: 76, 76: 77, 77: 78, 78: 79, 79: 80, 80: 81, 81: 82, 82: 83, 83: 84, 84: 85, 85: 86, 86: 87, 87: 88, 88: 89, 89: 90, -1: 0, 90: 91}}, 'model_info': {'metric_reference': {'accuracy_ap[.5:.95]%': 23.0}}}}\n"
     ]
    }
   ],
   "source": [
    "pipeline_configs = {\n",
    "    'od-mlpefmnv1': dict(\n",
    "        task_type='detection',\n",
    "        calibration_dataset=calib_dataset,\n",
    "        input_dataset=val_dataset,\n",
    "        preprocess=preproc_transforms.get_transform_tflite((300,300), (300,300), backend='cv2'),\n",
    "        session=session_type(**tflite_session_cfg,\n",
    "            runtime_options=runtime_options,\n",
    "            model_path=f'{settings.models_path}/vision/detection/coco/mlperf/ssd_mobilenet_v1_coco_20180128.tflite'),\n",
    "        postprocess=postproc_transforms.get_transform_detection_tflite(),\n",
    "        metric=dict(label_offset_pred=datasets.coco_det_label_offset_90to90()),\n",
    "        model_info=dict(metric_reference={'accuracy_ap[.5:.95]%':23.0})\n",
    "    )\n",
    "}\n",
    "print(pipeline_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71fc46",
   "metadata": {},
   "source": [
    "#### Model Compilation\n",
    "\n",
    "This will take a few minutes. Please be patient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c124a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configs to run: ['od-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite']\n",
      "number of configs: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd8fc55998041e3a8c8f36346c6d069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TASKS                                                       |   0%|          || 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASKS                                                       |          |     0% 0/1| [< ]\u001b[34m\n",
      "INFO:\u001b[33m20220329-161254: starting process on parallel_device - \u001b[39m0\n",
      "\u001b[34mINFO:\u001b[33m20220329-161259: model_path - \u001b[39m/data/ssd/files/a0393608/work/code/ti/edgeai-algo/edgeai-modelzoo/models/vision/detection/coco/mlperf/ssd_mobilenet_v1_coco_20180128.tflite\n",
      "\u001b[34mINFO:\u001b[33m20220329-161259: model_file - \u001b[39m/tmp/tmpxnd97n5t/modelartifacts/32bits/od-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite/model/ssd_mobilenet_v1_coco_20180128.tflite\n",
      "Downloading 1/1: /data/ssd/files/a0393608/work/code/ti/edgeai-algo/edgeai-modelzoo/models/vision/detection/coco/mlperf/ssd_mobilenet_v1_coco_20180128.tflite\n",
      "Download done for /data/ssd/files/a0393608/work/code/ti/edgeai-algo/edgeai-modelzoo/models/vision/detection/coco/mlperf/ssd_mobilenet_v1_coco_20180128.tflite\n",
      "/tmp/tmpxnd97n5t/modelartifacts/32bits/od-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite/model/ssd_mobilenet_v1_coco_20180128.tflite\n",
      "\u001b[34m\n",
      "INFO:\u001b[33m20220329-161300: running - \u001b[39mod-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite\u001b[34m\n",
      "INFO:\u001b[33m20220329-161300: pipeline_config - \u001b[39m{'task_type': 'detection', 'calibration_dataset': <jai_benchmark.datasets.coco_det.COCODetection object at 0x7f771ddbe780>, 'input_dataset': <jai_benchmark.datasets.coco_det.COCODetection object at 0x7f771ddbe860>, 'preprocess': <jai_benchmark.preprocess.PreProcessTransforms object at 0x7f760cfaccf8>, 'session': <jai_benchmark.sessions.tflitert_session.TFLiteRTSession object at 0x7f7720358160>, 'postprocess': <jai_benchmark.postprocess.PostProcessTransforms object at 0x7f77203581d0>, 'metric': {'label_offset_pred': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17, 17: 18, 18: 19, 19: 20, 20: 21, 21: 22, 22: 23, 23: 24, 24: 25, 25: 26, 26: 27, 27: 28, 28: 29, 29: 30, 30: 31, 31: 32, 32: 33, 33: 34, 34: 35, 35: 36, 36: 37, 37: 38, 38: 39, 39: 40, 40: 41, 41: 42, 42: 43, 43: 44, 44: 45, 45: 46, 46: 47, 47: 48, 48: 49, 49: 50, 50: 51, 51: 52, 52: 53, 53: 54, 54: 55, 55: 56, 56: 57, 57: 58, 58: 59, 59: 60, 60: 61, 61: 62, 62: 63, 63: 64, 64: 65, 65: 66, 66: 67, 67: 68, 68: 69, 69: 70, 70: 71, 71: 72, 72: 73, 73: 74, 74: 75, 75: 76, 76: 77, 77: 78, 78: 79, 79: 80, 80: 81, 81: 82, 82: 83, 83: 84, 84: 85, 85: 86, 86: 87, 87: 88, 88: 89, 89: 90, -1: 0, 90: 91}}, 'model_info': {'metric_reference': {'accuracy_ap[.5:.95]%': 23.0}}}\u001b[34m\n",
      "INFO:\u001b[33m20220329-161300: import  - \u001b[39mod-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite\u001b[34m\n",
      "INFO:\u001b[33m20220329-161321: import completed  - \u001b[39mod-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite - 21 sec\u001b[34m\n",
      "INFO:\u001b[33m20220329-161321: infer  - \u001b[39mod-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eec6e0af1464b0684e38e28968d3c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "infer : od-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_c|   0%|          || 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer : od-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_c|          |     0% 0/100| [< ]\u001b[34m\n",
      "INFO:\u001b[33m20220329-161627: infer completed  - \u001b[39mod-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite - 187 secLoading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.93s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.42s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.507\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
      "\u001b[32m\n",
      "\n",
      "SUCCESS:\u001b[33m20220329-161630: benchmark results - \u001b[39m{'infer_path': 'od-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite', 'accuracy_ap[.5:.95]%': 32.884864, 'accuracy_ap50%': 50.666097, 'num_subgraphs': 1, 'infer_time_core_ms': 1853.355596, 'infer_time_subgraph_ms': 1853.341536, 'ddr_transfer_mb': 0.0, 'perfsim_time_ms': 0.0, 'perfsim_ddr_transfer_mb': 0.0, 'perfsim_gmacs': 0.0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the model compliation/import and inference\n",
    "tools.run_accuracy(settings, work_dir, pipeline_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d982aa0",
   "metadata": {},
   "source": [
    "#### Package artifacts\n",
    "\n",
    "Package the artifacts into a .tar.gz file, keeping only the necessary files for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a664e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packaging artifacts to /tmp/tmpxnd97n5t/modelartifacts/32bits_package please wait...\n",
      "\u001b[32mSUCCESS:\u001b[33m20220329-161638: finished packaging - \u001b[39m/tmp/tmpxnd97n5t/modelartifacts/32bits/od-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite\n"
     ]
    }
   ],
   "source": [
    "out_dir = f'{work_dir}_package'\n",
    "tools.package_artifacts(settings, work_dir, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01cc894",
   "metadata": {},
   "source": [
    "#### Download\n",
    "\n",
    "Download the packaged .tar.gz artifact\n",
    "\n",
    "TODO: add a download link here, that the user can click to download the packaged artifact .tar.gz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "514f7dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download the atricats files from the folder: /tmp/tmpxnd97n5t/modelartifacts/32bits_package\n",
      "['artifacts.yaml', 'artifacts.list', 'od-mlpefmnv1_tflitert_coco_mlperf_ssd_mobilenet_v1_coco_20180128_tflite.tar.gz', 'extract.sh']\n"
     ]
    }
   ],
   "source": [
    "print(f'download the atricats files from the folder: {out_dir}')\n",
    "print(os.listdir(out_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bad73d",
   "metadata": {},
   "source": [
    "#### Cleanup\n",
    "\n",
    "Remove the temporary folders that we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6230cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "modelartifacts_tempdir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c237d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
