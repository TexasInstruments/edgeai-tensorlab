# ูุนุงููุฑ ุงูุฃุฏุงุก
<Tip warning={true}>

ุฃุฏูุงุช ููุงุณ ุงูุฃุฏุงุก ูู Hugging Face ุฃุตุจุญุช ูุฏููุฉุููููุตุญ ุจุงุณุชุฎุฏุงู ููุชุจุงุช ุฎุงุฑุฌูุฉ ูููุงุณ ุณุฑุนุฉ ูุชุนููุฏ ุงูุฐุงูุฑุฉ ูููุงุฐุฌ Transformer.

</Tip>

[[open-in-colab]]

ูููู ูุธุฑุฉ ุนูู ููููุฉ ุชูููู ุฃุฏุงุก ููุงุฐุฌ ๐ค Transformersุ ูุฃูุถู ุงูููุงุฑุณุงุชุ ููุนุงููุฑ ุงูุฃุฏุงุก ุงููุชุงุญุฉ ุจุงููุนู.

ููููู ุงูุนุซูุฑ ุนูู ุฏูุชุฑ ููุงุญุธุงุช ูุดุฑุญ ุจุงูุชูุตูู ููููุฉ ููุงุณ ุฃุฏุงุก ููุงุฐุฌ ๐ค Transformers [ููุง](https://github.com/huggingface/notebooks/tree/main/examples/benchmark.ipynb).

## ููููุฉ ููุงุณ ุฃุฏุงุก ููุงุฐุฌ ๐ค Transformers

ุชุณูุญ ุงููุฆุชุงู [`PyTorchBenchmark`] ู [`TensorFlowBenchmark`] ุจุชูููู ุฃุฏุงุก ููุงุฐุฌ ๐ค Transformers ุจูุฑููุฉ. ุชุชูุญ ููุง ูุฆุงุช ุงูุชูููู ููุงุณ ุงูุฃุฏุงุก ููุงุณ _ุงูุงุณุชุฎุฏุงู ุงูุฃูุตู ููุฐุงูุฑุฉ_ ู _ุงูููุช ุงููุงุฒู_ ููู ูู _ุงูุงุณุชุฏูุงู_ ู _ุงูุชุฏุฑูุจ_.

<Tip>

ููุงุ ูููุนุฑููู _ุงูุงุณุชุฏูุงู_ ุจุฃูู ุชูุฑูุฑุฉ ุฃูุงููุฉ ูุงุญุฏุฉุ ููุชู ุชุนุฑูู _ุงูุชุฏุฑูุจ_ ุจุฃูู ุชูุฑูุฑุฉ ุฃูุงููุฉ ูุงุญุฏุฉ ูุชูุฑูุฑุฉ ุฎูููุฉ ูุงุญุฏุฉ.

</Tip>

ุชุชููุน ูุฆุงุช ุชูููู ุงูุฃุฏุงุก [`PyTorchBenchmark`] ู [`TensorFlowBenchmark`] ูุงุฆููุง ูู ุงูููุน [`PyTorchBenchmarkArguments`] ู [`TensorFlowBenchmarkArguments`]ุ ุนูู ุงูุชูุงููุ ููุชูููุฐ. [`PyTorchBenchmarkArguments`] ู [`TensorFlowBenchmarkArguments`] ูู ูุฆุงุช ุจูุงูุงุช ูุชุญุชูู ุนูู ุฌููุน ุงูุชููููุงุช ุฐุงุช ุงูุตูุฉ ููุฆุฉ ุชูููู ุงูุฃุฏุงุก ุงูููุงุจูุฉ. ูู ุงููุซุงู ุงูุชุงููุ ูุชู ุชูุถูุญ ููููุฉ ุชูููู ุฃุฏุงุก ูููุฐุฌ BERT ูู ุงูููุน _bert-base-cased_.

<frameworkcontent>
<pt>
  
```py
>>> from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments

>>> args = PyTorchBenchmarkArguments(models=["google-bert/bert-base-uncased"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512])
>>> benchmark = PyTorchBenchmark(args)
```
</pt>
<tf>
  
```py
>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments

>>> args = TensorFlowBenchmarkArguments(
...     models=["google-bert/bert-base-uncased"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]
... )
>>> benchmark = TensorFlowBenchmark(args)
```
</tf>
</frameworkcontent>

ููุงุ ูุชู ุชูุฑูุฑ ุซูุงุซุฉ ูุนุงู๏ปปุช ุฅูู ูุฆุงุช ุจูุงูุงุช ุญุฌุฉ ููุงุณ ุงูุฃุฏุงุกุ ููู `models` ู `batch_sizes` ู `sequence_lengths`. ุงููุนุงูู `models` ูุทููุจุฉ ูุชุชููุน `ูุงุฆูุฉ` ูู ุจูุนุฑููุงุช ุงููููุฐุฌ ูู [ูุฑูุฒ ุงูููุงุฐุฌ](https://huggingface.co/models) ุชุญุฏุฏ ูุนุงู๏ปปุช ุงููุงุฆูุฉ `batch_sizes` ู `sequence_lengths` ุญุฌู `input_ids` ุงูุฐู ูุชู ููุงุณ ุฃุฏุงุก ุงููููุฐุฌ ุนููู. ููุงู ุงูุนุฏูุฏ ูู ุงููุนููุงุช ุงูุฃุฎุฑู ุงูุชู ูููู ุชูููููุง ุนุจุฑ ูุฆุงุช ุจูุงูุงุช ูุนุงู ููุงุณ ุงูุฃุฏุงุก. ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ูุฐู ุงููุนููุงุชุ ููููู ุฅูุง ุงูุฑุฌูุน ูุจุงุดุฑุฉ ุฅูู ุงููููุงุช `src/transformers/benchmark/benchmark_args_utils.py`ุ `src/transformers/benchmark/benchmark_args.py` (ูู PyTorch) ู `src/transformers/benchmark/benchmark_args_tf.py` (ูู Tensorflow). ุฃูุ ุจุฏูุงู ูู ุฐููุ ูู ุจุชุดุบูู ุฃูุงูุฑ shell ุงูุชุงููุฉ ูู ุงููุฌูุฏ ุงูุฑุฆูุณู ูุทุจุงุนุฉ ูุงุฆูุฉ ูุตููุฉ ุจุฌููุน ุงููุนููุงุช ุงููุงุจูุฉ ููุชูููู ูู PyTorch ู Tensorflow ุนูู ุงูุชูุงูู.

<frameworkcontent>
<pt>
  
```bash
python examples/pytorch/benchmarking/run_benchmark.py --help
```

ููููู ุจุจุณุงุทุฉ ุชุดุบูู ูุงุฆู ุงูุชูููู ุงูุฐู ุชู ุชููุฆุชู ุนู ุทุฑูู ุงุณุชุฏุนุงุก `benchmark.run()`.

```py
>>> results = benchmark.run()
>>> print(results)
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length     Time in s                  
--------------------------------------------------------------------------------
google-bert/bert-base-uncased          8               8             0.006     
google-bert/bert-base-uncased          8               32            0.006     
google-bert/bert-base-uncased          8              128            0.018     
google-bert/bert-base-uncased          8              512            0.088     
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length    Memory in MB 
--------------------------------------------------------------------------------
google-bert/bert-base-uncased          8               8             1227
google-bert/bert-base-uncased          8               32            1281
google-bert/bert-base-uncased          8              128            1307
google-bert/bert-base-uncased          8              512            1539
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: PyTorch
- use_torchscript: False
- framework_version: 1.4.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 08:58:43.371351
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</pt>
<tf>
  
```bash
python examples/tensorflow/benchmarking/run_benchmark_tf.py --help
```

ููููู ุจุนุฏ ุฐูู ุชุดุบูู ูุงุฆู ููุงุณ ุงูุฃุฏุงุก ุงูุฐู ุชู ุชููุฆุชู ุนู ุทุฑูู ุงุณุชุฏุนุงุก `benchmark.run()`.

```py
>>> results = benchmark.run()
>>> print(results)
>>> results = benchmark.run()
>>> print(results)
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length     Time in s                  
--------------------------------------------------------------------------------
google-bert/bert-base-uncased          8               8             0.005
google-bert/bert-base-uncased          8               32            0.008
google-bert/bert-base-uncased          8              128            0.022
google-bert/bert-base-uncased          8              512            0.105
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length    Memory in MB 
--------------------------------------------------------------------------------
google-bert/bert-base-uncased          8               8             1330
google-bert/bert-base-uncased          8               32            1330
google-bert/bert-base-uncased          8              128            1330
google-bert/bert-base-uncased          8              512            1770
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 202.11.0
- framework: Tensorflow
- use_xla: False
- framework_version: 2.2.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:26:35.617317
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</tf>
</frameworkcontent>

ุจุดูู ุงูุชุฑุงุถูุ ูุชู ุชูููู _ุงูููุช_ ู _ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ_ ูู _ุงูุงุณุชุฏูุงู_. ูู ูุซุงู ุงููุฎุฑุฌุงุช ุฃุนูุงูุ ููุธูุฑ ุงููุณูุงู ุงูุฃููุงู ุงููุชูุฌุฉ ุงูููุงุจูุฉ ูู _ููุช ุงูุงุณุชุฏูุงู_ ู _ุฐุงูุฑุฉ ุงูุงุณุชุฏูุงู_. ุจุงูุฅุถุงูุฉ ุฅูู ุฐููุ ูุชู ุทุจุงุนุฉ ุฌููุน ุงููุนูููุงุช ุฐุงุช ุงูุตูุฉ ุญูู ุจูุฆุฉ ุงูุญูุณุจุฉุ ุนูู ุณุจูู ุงููุซุงู ููุน ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU)ุ ูุงููุธุงูุ ูุฅุตุฏุงุฑุงุช ุงูููุชุจุฉุ ููุง ุฅูู ุฐููุ ูู ุงููุณู ุงูุซุงูุซ ุชุญุช _ูุนูููุงุช ุงูุจูุฆุฉ_. ูููู ุญูุธ ูุฐู ุงููุนูููุงุช ุจุดูู ุงุฎุชูุงุฑู ูู ููู _.csv_ ุนูุฏ ุฅุถุงูุฉ ุงููุนุงูู `save_to_csv=True` ุฅูู [`PyTorchBenchmarkArguments`] ู [`TensorFlowBenchmarkArguments`] ุนูู ุงูุชูุงูู. ูู ูุฐู ุงูุญุงูุฉุ ูุชู ุญูุธ ูู ูุณู ูู ููู _.csv_ ูููุตู. ูููู ุงุฎุชูุงุฑูุง ุชุญุฏูุฏ ูุณุงุฑ ูู ููู _.csv_ ุนุจุฑ ูุฆุงุช ุจูุงูุงุช ูุนุงูู ููุงุณ ุงูุฃุฏุงุก.

ุจุฏูุงู ูู ุชูููู ุงูููุงุฐุฌ ุงููุฏุฑุจุฉ ูุณุจููุง ุนุจุฑ ูุนุฑูู ุงููููุฐุฌุ ุนูู ุณุจูู ุงููุซุงู `google-bert/bert-base-uncased`ุ ููููู ูููุณุชุฎุฏู ุจุฏูุงู ูู ุฐูู ููุงุณ ุฃุฏุงุก ุชูููู ุนุดูุงุฆู ูุฃู ูุฆุฉ ูููุฐุฌ ูุชุงุญุฉ. ูู ูุฐู ุงูุญุงูุฉุ ูุฌุจ ุฅุฏุฑุงุฌ "ูุงุฆูุฉ" ูู ุงูุชููููุงุช ูุน ูุนุงูู ููุงุณ ุงูุฃุฏุงุก ููุง ูู ููุถุญ ุฃุฏูุงู.

<frameworkcontent>
<pt>
  
```py
>>> from transformers import PyTorchBenchmarkุ PyTorchBenchmarkArgumentsุ BertConfig

>>> args = PyTorchBenchmarkArguments(
...     models=["bert-base"ุ "bert-384-hid"ุ "bert-6-lay"]ุ batch_sizes=[8]ุ sequence_lengths=[8ุ 32ุ 128ุ 512]
... )
>>> config_base = BertConfig()
>>> config_384_hid = BertConfig(hidden_size=384)
>>> config_6_lay = BertConfig(num_hidden_layers=6)

>>> benchmark = PyTorchBenchmark(argsุ configs=[config_baseุ config_384_hidุ config_6_lay])
>>> benchmark.run()
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length       Time in s                  
--------------------------------------------------------------------------------
bert-base                  8              128            0.006
bert-base                  8              512            0.006
bert-base                  8              128            0.018     
bert-base                  8              512            0.088     
bert-384-hid              8               8             0.006     
bert-384-hid              8               32            0.006     
bert-384-hid              8              128            0.011     
bert-384-hid              8              512            0.054     
bert-6-lay                 8               8             0.003     
bert-6-lay                 8               32            0.004     
bert-6-lay                 8              128            0.009     
bert-6-lay                 8              512            0.044
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length      Memory in MB
## ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก

ูู ูุฐุง ุงููุณูุ ูุชู ููุงุณ _ููุช ุงูุงุณุชุฏูุงู_ ู _ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ_ ููุงุณุชุฏูุงูุ ููุฎุชูู ุชููููุงุช `BertModel`. ูุชู ุนุฑุถ ุงููุชุงุฆุฌ ูู ุฌุฏููุ ูุน ุชูุณูู ูุฎุชูู ููููุงู ููู ูู PyTorch ู TensorFlow.

--------------------------------------------------------------------------------
| ุงุณู ุงููููุฐุฌ | ุญุฌู ุงูุฏูุนุฉ | ุทูู ุงูุชุณูุณู | ุงูุฐุงูุฑุฉ ุจุงูููุบุงุจุงูุช |
--------------------------------------------------------------------------------
| bert-base | 8 | 8 | 1277 |
| bert-base | 8 | 32 | 1281 |
| bert-base | 8 | 128 | 1307 |
| bert-base | 8 | 512 | 1539 |
| bert-384-hid | 8 | 8 | 1005 |
| bert-384-hid | 8 | 32 | 1027 |
| bert-384-hid | 8 | 128 | 1035 |
| bert-384-hid | 8 | 512 | 1255 |
| bert-6-lay | 8 | 8 | 1097 |
| bert-6-lay | 8 | 32 | 1101 |
| bert-6-lay | 8 | 128 | 1127 |
| bert-6-lay | 8 | 512 | 1359 |
--------------------------------------------------------------------------------

==================== ูุนูููุงุช ุงูุจูุฆุฉ ====================

- transformers_version: 2.11.0
- framework: PyTorch
- use_torchscript: False
- framework_version: 1.4.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:35:25.143267
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</pt>
<tf>
  
```py
>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments, BertConfig

>>> args = TensorFlowBenchmarkArguments(
...     models=["bert-base", "bert-384-hid", "bert-6-lay"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]
... )
>>> config_base = BertConfig()
>>> config_384_hid = BertConfig(hidden_size=384)
>>> config_6_lay = BertConfig(num_hidden_layers=6)

>>> benchmark = TensorFlowBenchmark(args, configs=[config_base, config_384_hid, config_6_lay])
>>> benchmark.run()
==================== ูุชุงุฆุฌ ุงูุณุฑุนุฉ ูู ุงูุงุณุชุฏูุงู ====================
--------------------------------------------------------------------------------
| ุงุณู ุงููููุฐุฌ | ุญุฌู ุงูุฏูุนุฉ | ุทูู ุงูุชุณูุณู | ุงูููุช ุจุงูุซุงููุฉ |
--------------------------------------------------------------------------------
| bert-base | 8 | 8 | 0.005 |
| bert-base | 8 | 32 | 0.008 |
| bert-base | 8 | 128 | 0.022 |
| bert-base | 8 | 512 | 0.106 |
| bert-384-hid | 8 | 8 | 0.005 |
| bert-384-hid | 8 | 32 | 0.007 |
| bert-384-hid | 8 | 128 | 0.018 |
| bert-384-hid | 8 | 512 | 0.064 |
| bert-6-lay | 8 | 8 | 0.002 |
| bert-6-lay | 8 | 32 | 0.003 |
| bert-6-lay | 8 | 128 | 0.0011 |
| bert-6-lay | 8 | 512 | 0.074 |
--------------------------------------------------------------------------------

==================== ูุชุงุฆุฌ ุงูุฐุงูุฑุฉ ูู ุงูุงุณุชุฏูุงู ====================
--------------------------------------------------------------------------------
| ุงุณู ุงููููุฐุฌ | ุญุฌู ุงูุฏูุนุฉ | ุทูู ุงูุชุณูุณู | ุงูุฐุงูุฑุฉ ุจุงูููุบุงุจุงูุช |
--------------------------------------------------------------------------------
| ุงุณู ุงููููุฐุฌ | ุญุฌู ุงูุฏูุนุฉ | ุทูู ุงูุชุณูุณู | ุงูุฐุงูุฑุฉ ุจุงูููุบุงุจุงูุช |
--------------------------------------------------------------------------------
| bert-base | 8 | 8 | 1330 |
| bert-base | 8 | 32 | 1330 |
| bert-base | 8 | 128 | 1330 |
| bert-base | 8 | 512 | 1770 |
| bert-384-hid | 8 | 8 | 1330 |
| bert-384-hid | 8 | 32 | 1330 |
| bert-384-hid | 8 | 128 | 1330 |
| bert-384-hid | 8 | 512 | 1540 |
| bert-6-lay | 8 | 8 | 1330 |
| bert-6-lay | 8 | 32 | 1330 |
| bert-6-lay | 8 | 128 | 1330 |
| bert-6-lay | 8 | 512 | 1540 |
--------------------------------------------------------------------------------

==================== ูุนูููุงุช ุงูุจูุฆุฉ ====================

- transformers_version: 2.11.0
- framework: Tensorflow
- use_xla: False
- framework_version: 2.2.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:38:15.487125
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</tf>
</frameworkcontent>

ูุฑุฉ ุฃุฎุฑูุ ูุชู ููุงุณ _ููุช ุงูุงุณุชุฏูุงู_ ู _ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ_ ููุงุณุชุฏูุงูุ ูููู ูุฐู ุงููุฑุฉ ูุชููููุงุช ูุฎุตุตุฉ ูู `BertModel`. ูููู ุฃู ุชููู ูุฐู ุงูููุฒุฉ ูููุฏุฉ ุจุดูู ุฎุงุต ุนูุฏ ุงุชุฎุงุฐ ูุฑุงุฑ ุจุดุฃู ุงูุชูููู ุงูุฐู ูุฌุจ ุชุฏุฑูุจ ุงููููุฐุฌ ุนููู.

## ุฃูุถู ุงูููุงุฑุณุงุช ูู ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก

ูุณุฑุฏ ูุฐุง ุงููุณู ุจุนุถ ุฃูุถู ุงูููุงุฑุณุงุช ุงูุชู ูุฌุจ ูุฑุงุนุงุชูุง ุนูุฏ ุฅุฌุฑุงุก ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ููููุฐุฌ ูุง.

- ุญุงููุงูุ ูุชู ุฏุนู ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ุนูู ุฌูุงุฒ ูุงุญุฏ ููุท. ุนูุฏ ุฅุฌุฑุงุก ุงูุงุฎุชุจุงุฑ ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU)ุ ููุตู ุจุฃู ูููู ุงููุณุชุฎุฏู ุจุชุญุฏูุฏ ุงูุฌูุงุฒ ุงูุฐู ูุฌุจ ุชุดุบูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุนููู ูู ุฎูุงู ุชุนููู ูุชุบูุฑ ุงูุจูุฆุฉ `CUDA_VISIBLE_DEVICES` ูู ุงูุดูุ ุนูู ุณุจูู ุงููุซุงู `export CUDA_VISIBLE_DEVICES=0` ูุจู ุชุดุบูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ.
- ูุฌุจ ุชุนููู ุงูุฎูุงุฑ `no_multi_processing` ุฅูู `True` ููุท ูุฃุบุฑุงุถ ุงูุงุฎุชุจุงุฑ ูุงูุชุตุญูุญ. ููุถูุงู ููุงุณ ุงูุฐุงูุฑุฉ ุจุฏูุฉุ ููุตู ุจุชุดุบูู ูู ุงุฎุชุจุงุฑ ุฐุงูุฑุฉ ูู ุนูููุฉ ูููุตูุฉ ูุงูุชุฃูุฏ ูู ุชุนููู `no_multi_processing` ุฅูู `True`.
- ูุฌุจ ุฏุงุฆููุง ุฐูุฑ ูุนูููุงุช ุงูุจูุฆุฉ ุนูุฏ ูุดุงุฑูุฉ ูุชุงุฆุฌ ุชูููู ุงููููุฐุฌ. ููููู ุฃู ุชุฎุชูู ุงููุชุงุฆุฌ ุงุฎุชูุงููุง ูุจูุฑูุง ุจูู ุฃุฌูุฒุฉ GPU ุงููุฎุชููุฉ ูุฅุตุฏุงุฑุงุช ุงูููุชุจุงุชุ ููุง ุฅูู ุฐููุ ูุฐูู ูุฅู ูุชุงุฆุฌ ุงูุงุฎุชุจุงุฑ ุจููุฑุฏูุง ููุณุช ูููุฏุฉ ุฌุฏูุง ูููุฌุชูุน.

## ูุดุงุฑูุฉ ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ุงูุฎุงุต ุจู

ูู ุงูุณุงุจูุ ุชู ุฅุฌุฑุงุก ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ูุฌููุน ุงูููุงุฐุฌ ุงูุฃุณุงุณูุฉ ุงููุชุงุญุฉ (10 ูู ุฐูู ุงูููุช) ูููุงุณ _ููุช ุงูุงุณุชุฏูุงู_ุ ุนุจุฑ ุงูุนุฏูุฏ ูู ุงูุฅุนุฏุงุฏุงุช ุงููุฎุชููุฉ: ุจุงุณุชุฎุฏุงู PyTorchุ ูุน TorchScript ูุจุฏูููุงุ ุจุงุณุชุฎุฏุงู TensorFlowุ ูุน XLA ูุจุฏููู. ุชู ุฅุฌุฑุงุก ุฌููุน ูุฐู ุงูุงุฎุชุจุงุฑุงุช ุนูู ูุญุฏุงุช ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) (ุจุงุณุชุซูุงุก XLA TensorFlow) ููุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU).

ูุชู ุดุฑุญ ูุฐุง ุงูููุฌ ุจุงูุชูุตูู ูู [ููุดูุฑ ุงููุฏููุฉ ูุฐุง](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2) ูุชุชููุฑ ุงููุชุงุฆุฌ [ููุง](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit?usp=sharing).

ูุน ุฃุฏูุงุช ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ุงูุฌุฏูุฏุฉุ ุฃุตุจุญ ูู ุงูุฃุณูู ูู ุฃู ููุช ูุถู ูุดุงุฑูุฉ ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ุงูุฎุงุต ุจู ูุน ุงููุฌุชูุน:

- [ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ูู PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch/benchmarking/README.md).
- [ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ูู TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/benchmarking/README.md).
