[39m
=> args:  {'model_config': {'input_channels': 3, 'output_type': 'classification', 'output_channels': None, 'strides': None, 'num_tiles_x': 1, 'num_tiles_y': 1, 'en_make_divisible_by8': True, 'enable_fp16': False, 'num_classes': 1000}, 'dataset_config': {}, 'input_channel_reverse': False, 'data_path': './data/datasets/image_folder_classification', 'model_name': 'mobilenetv2_tv_x1', 'model': None, 'dataset_name': 'image_folder_classification', 'save_path': None, 'phase': 'training', 'date': '2020-12-13_16-53-07', 'workers': 12, 'logger': <pytorch_jacinto_ai.xnn.utils.logger.TeeLogger object at 0x7f91a1719110>, 'epochs': 10, 'warmup_epochs': 5, 'warmup_factor': 0.001, 'epoch_size': 0, 'epoch_size_val': 0, 'start_epoch': 0, 'stop_epoch': 10, 'batch_size': 256, 'total_batch_size': 256, 'iter_size': 1, 'lr': 0.0001, 'lr_clips': None, 'lr_calib': 0.05, 'momentum': 0.9, 'weight_decay': 4e-05, 'bias_decay': None, 'shuffle': True, 'shuffle_val': True, 'rand_seed': 1, 'print_freq': 100, 'resume': None, 'evaluate_start': False, 'world_size': 1, 'dist_url': 'tcp://224.66.41.62:23456', 'dist_backend': 'gloo', 'optimizer': 'sgd', 'scheduler': 'cosine', 'milestones': (30, 60, 90), 'multistep_gamma': 0.1, 'polystep_power': 1.0, 'step_size': 1, 'beta': 0.999, 'pretrained': '/data/adas_vision_data1/users/manu/modelzoo/pytorch/image_classification/imagenet1k/jacinto_ai/mobilenet_v2_2019-12-24_15-32-12.pth', 'img_resize': 256, 'img_crop': 224, 'rand_scale': (0.2, 1.0), 'data_augument': 'inception', 'count_flops': True, 'save_onnx': True, 'print_model': False, 'run_soon': True, 'multi_color_modes': None, 'image_mean': (123.675, 116.28, 103.53), 'image_scale': (0.017125, 0.017507, 0.017429), 'parallel_model': True, 'quantize': True, 'bitwidth_weights': 8, 'bitwidth_activations': 8, 'histogram_range': True, 'bias_calibration': True, 'per_channel_q': False, 'constrain_bias': None, 'freeze_bn': False, 'save_mod_files': False, 'opset_version': 11, 'best_prec1': -1, 'num_inputs': 1, 'distributed': False}
batch_size: 256
best_prec1: -1
beta: 0.999
bias_calibration: True
bias_decay: None
bitwidth_activations: 8
bitwidth_weights: 8
constrain_bias: None
count_flops: True
data_augument: inception
data_path: ./data/datasets/image_folder_classification
dataset_config: {}
dataset_name: image_folder_classification
date: 2020-12-13_16-53-07
dist_backend: gloo
dist_url: tcp://224.66.41.62:23456
distributed: False
epoch_size: 0
epoch_size_val: 0
epochs: 10
evaluate_start: False
freeze_bn: False
histogram_range: True
image_mean: (123.675, 116.28, 103.53)
image_scale: (0.017125, 0.017507, 0.017429)
img_crop: 224
img_resize: 256
input_channel_reverse: False
iter_size: 1
logger: <pytorch_jacinto_ai.xnn.utils.logger.TeeLogger object at 0x7f91a1719110>
lr: 0.0001
lr_calib: 0.05
lr_clips: None
milestones: (30, 60, 90)
model: None
model_config: {'input_channels': 3, 'output_type': 'classification', 'output_channels': None, 'strides': None, 'num_tiles_x': 1, 'num_tiles_y': 1, 'en_make_divisible_by8': True, 'enable_fp16': False, 'num_classes': 1000}
model_name: mobilenetv2_tv_x1
momentum: 0.9
multi_color_modes: None
multistep_gamma: 0.1
num_inputs: 1
opset_version: 11
optimizer: sgd
parallel_model: True
per_channel_q: False
phase: training
polystep_power: 1.0
pretrained: /data/adas_vision_data1/users/manu/modelzoo/pytorch/image_classification/imagenet1k/jacinto_ai/mobilenet_v2_2019-12-24_15-32-12.pth
print_freq: 100
print_model: False
quantize: True
rand_scale: (0.2, 1.0)
rand_seed: 1
resume: None
run_soon: True
save_mod_files: False
save_onnx: True
save_path: None
scheduler: cosine
shuffle: True
shuffle_val: True
start_epoch: 0
step_size: 1
stop_epoch: 10
total_batch_size: 256
warmup_epochs: 5
warmup_factor: 0.001
weight_decay: 4e-05
workers: 12
world_size: 1
=> resize resolution: 256
=> crop resolution  : 224
=> using pre-trained weights from: /data/adas_vision_data1/users/manu/modelzoo/pytorch/image_classification/imagenet1k/jacinto_ai/mobilenet_v2_2019-12-24_15-32-12.pth
=> creating model 'mobilenetv2_tv_x1'
32
3
1
3 3
32
32
32
3 3
16
32
1
1 1
96
16
1
1 1
96
96
96
3 3
24
96
1
1 1
144
24
1
1 1
144
144
144
3 3
24
144
1
1 1
144
24
1
1 1
144
144
144
3 3
32
144
1
1 1
192
32
1
1 1
192
192
192
3 3
32
192
1
1 1
192
32
1
1 1
192
192
192
3 3
32
192
1
1 1
192
32
1
1 1
192
192
192
3 3
64
192
1
1 1
384
64
1
1 1
384
384
384
3 3
64
384
1
1 1
384
64
1
1 1
384
384
384
3 3
64
384
1
1 1
384
64
1
1 1
384
384
384
3 3
64
384
1
1 1
384
64
1
1 1
384
384
384
3 3
96
384
1
1 1
576
96
1
1 1
576
576
576
3 3
96
576
1
1 1
576
96
1
1 1
576
576
576
3 3
96
576
1
1 1
576
96
1
1 1
576
576
576
3 3
160
576
1
1 1
960
160
1
1 1
960
960
960
3 3
160
960
1
1 1
960
160
1
1 1
960
960
960
3 3
160
960
1
1 1
960
160
1
1 1
960
960
960
3 3
320
960
1
1 1
1280
320
1
1 1
[33m=> model surgery by 'model_surgery_quantize'[39m
=> feature size is:  torch.Size([1, 1280, 7, 7])
32
3
1
3 3
32
32
32
3 3
16
32
1
1 1
96
16
1
1 1
96
96
96
3 3
24
96
1
1 1
144
24
1
1 1
144
144
144
3 3
24
144
1
1 1
144
24
1
1 1
144
144
144
3 3
32
144
1
1 1
192
32
1
1 1
192
192
192
3 3
32
192
1
1 1
192
32
1
1 1
192
192
192
3 3
32
192
1
1 1
192
32
1
1 1
192
192
192
3 3
64
192
1
1 1
384
64
1
1 1
384
384
384
3 3
64
384
1
1 1
384
64
1
1 1
384
384
384
3 3
64
384
1
1 1
384
64
1
1 1
384
384
384
3 3
64
384
1
1 1
384
64
1
1 1
384
384
384
3 3
96
384
1
1 1
576
96
1
1 1
576
576
576
3 3
96
576
1
1 1
576
96
1
1 1
576
576
576
3 3
96
576
1
1 1
576
96
1
1 1
576
576
576
3 3
160
576
1
1 1
960
160
1
1 1
960
960
960
3 3
160
960
1
1 1
960
160
1
1 1
960
960
960
3 3
160
960
1
1 1
960
160
1
1 1
960
960
960
3 3
320
960
1
1 1
1280
320
1
1 1
[33m=> The following layers in the model could not be loaded from pre-trained: [39m
classifier.1.activation_q.clips_act
features.0.0.activation_in.clips_act
features.0.2.clips_act
features.1.conv.0.2.clips_act
features.1.conv.2.activation_q.clips_act
features.2.conv.0.2.clips_act
features.2.conv.1.2.clips_act
features.2.conv.3.activation_q.clips_act
features.3.conv.0.2.clips_act
features.3.conv.1.2.clips_act
features.3.conv.3.activation_q.clips_act
features.3.add.activation_q.clips_act
features.4.conv.0.2.clips_act
features.4.conv.1.2.clips_act
features.4.conv.3.activation_q.clips_act
features.5.conv.0.2.clips_act
features.5.conv.1.2.clips_act
features.5.conv.3.activation_q.clips_act
features.5.add.activation_q.clips_act
features.6.conv.0.2.clips_act
features.6.conv.1.2.clips_act
features.6.conv.3.activation_q.clips_act
features.6.add.activation_q.clips_act
features.7.conv.0.2.clips_act
features.7.conv.1.2.clips_act
features.7.conv.3.activation_q.clips_act
features.8.conv.0.2.clips_act
features.8.conv.1.2.clips_act
features.8.conv.3.activation_q.clips_act
features.8.add.activation_q.clips_act
features.9.conv.0.2.clips_act
features.9.conv.1.2.clips_act
features.9.conv.3.activation_q.clips_act
features.9.add.activation_q.clips_act
features.10.conv.0.2.clips_act
features.10.conv.1.2.clips_act
features.10.conv.3.activation_q.clips_act
features.10.add.activation_q.clips_act
features.11.conv.0.2.clips_act
features.11.conv.1.2.clips_act
features.11.conv.3.activation_q.clips_act
features.12.conv.0.2.clips_act
features.12.conv.1.2.clips_act
features.12.conv.3.activation_q.clips_act
features.12.add.activation_q.clips_act
features.13.conv.0.2.clips_act
features.13.conv.1.2.clips_act
features.13.conv.3.activation_q.clips_act
features.13.add.activation_q.clips_act
features.14.conv.0.2.clips_act
features.14.conv.1.2.clips_act
features.14.conv.3.activation_q.clips_act
features.15.conv.0.2.clips_act
features.15.conv.1.2.clips_act
features.15.conv.3.activation_q.clips_act
features.15.add.activation_q.clips_act
features.16.conv.0.2.clips_act
features.16.conv.1.2.clips_act
features.16.conv.3.activation_q.clips_act
features.16.add.activation_q.clips_act
features.17.conv.0.2.clips_act
features.17.conv.1.2.clips_act
features.17.conv.3.activation_q.clips_act
features.18.2.clips_act
=> Resize = 256, Crop = 224, GFLOPs = 0.598988544, GMACs = 0.299494272
QuantTrainModule(
  (module): MobileNetV2TV(
    (classifier): Sequential(
      (0): Identity()
      (1): QuantTrainLinear(
        in_features=1280, out_features=1000, bias=True
        (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
      )
    )
    (features): Sequential(
      (0): Sequential(
        (0): QuantTrainConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (activation_in): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
        )
        (1): QuantTrainBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): QuantTrainBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): QuantTrainConv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): QuantTrainBatchNorm2d(
            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): QuantTrainBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): QuantTrainBatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): QuantTrainBatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): QuantTrainBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): QuantTrainBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): QuantTrainBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): QuantTrainBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): QuantTrainBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): QuantTrainBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): QuantTrainBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): QuantTrainBatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): QuantTrainBatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
            (1): QuantTrainBatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
            (1): QuantTrainBatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
            (1): QuantTrainBatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
        (add): AddBlock(inplace=False, signed=True)
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): Sequential(
            (0): QuantTrainConv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): QuantTrainBatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (1): Sequential(
            (0): QuantTrainConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
            (1): QuantTrainBatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
          )
          (2): QuantTrainConv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): QuantTrainBatchNorm2d(
            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
            (activation_q): QuantTrainPAct2(inplace=False, signed=None, clips=(tensor(-8.), tensor(8.)))
          )
        )
      )
      (18): Sequential(
        (0): QuantTrainConv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): QuantTrainBatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): QuantTrainPAct2(inplace=False, signed=False, clips=(tensor(0.), tensor(8.)))
      )
    )
  )
)=> args:  {'model_config': {'input_channels': 3, 'output_type': 'classification', 'output_channels': None, 'strides': None, 'num_tiles_x': 1, 'num_tiles_y': 1, 'en_make_divisible_by8': True, 'enable_fp16': False, 'num_classes': 1000}, 'dataset_config': {}, 'input_channel_reverse': False, 'data_path': './data/datasets/image_folder_classification', 'model_name': 'mobilenetv2_tv_x1', 'model': None, 'dataset_name': 'image_folder_classification', 'save_path': None, 'phase': 'training', 'date': '2020-12-13_16-53-07', 'workers': 12, 'logger': <pytorch_jacinto_ai.xnn.utils.logger.TeeLogger object at 0x7f91a1719110>, 'epochs': 10, 'warmup_epochs': 5, 'warmup_factor': 0.001, 'epoch_size': 0, 'epoch_size_val': 0, 'start_epoch': 0, 'stop_epoch': 10, 'batch_size': 256, 'total_batch_size': 256, 'iter_size': 1, 'lr': 0.0001, 'lr_clips': None, 'lr_calib': 0.05, 'momentum': 0.9, 'weight_decay': 4e-05, 'bias_decay': None, 'shuffle': True, 'shuffle_val': True, 'rand_seed': 1, 'print_freq': 100, 'resume': None, 'evaluate_start': False, 'world_size': 1, 'dist_url': 'tcp://224.66.41.62:23456', 'dist_backend': 'gloo', 'optimizer': 'sgd', 'scheduler': 'cosine', 'milestones': (30, 60, 90), 'multistep_gamma': 0.1, 'polystep_power': 1.0, 'step_size': 1, 'beta': 0.999, 'pretrained': '/data/adas_vision_data1/users/manu/modelzoo/pytorch/image_classification/imagenet1k/jacinto_ai/mobilenet_v2_2019-12-24_15-32-12.pth', 'img_resize': 256, 'img_crop': 224, 'rand_scale': (0.2, 1.0), 'data_augument': 'inception', 'count_flops': True, 'save_onnx': True, 'print_model': False, 'run_soon': True, 'multi_color_modes': None, 'image_mean': (123.675, 116.28, 103.53), 'image_scale': (0.017125, 0.017507, 0.017429), 'parallel_model': True, 'quantize': True, 'bitwidth_weights': 8, 'bitwidth_activations': 8, 'histogram_range': True, 'bias_calibration': True, 'per_channel_q': False, 'constrain_bias': None, 'freeze_bn': False, 'save_mod_files': False, 'opset_version': 11, 'best_prec1': -1, 'num_inputs': 1, 'distributed': False}
=> optimizer type   : sgd
=> learning rate    : 0.0001
=> resize resolution: 256
=> crop resolution  : 224
=> batch size       : 256
=> total batch size : 256
=> epoch size       : 0
=> data augument    : inception
=> epochs           : 10
[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=16:53 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=16:53 IST
=> training   0.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=13.383 DataTime=4.391 Loss=1.044 Prec@1=73.828 Prec@5=90.625 rate=0 Hz, eta=?, total=0:00:00, wall=16:53 IST
=> training   0.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=13.383 DataTime=4.391 Loss=1.044 Prec@1=73.828 Prec@5=90.625 rate=7153.56 Hz, eta=0:00:00, total=0:00:00, wall=16:53 IST
=> training   0.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=13.383 DataTime=4.391 Loss=1.044 Prec@1=73.828 Prec@5=90.625 rate=7153.56 Hz, eta=0:00:00, total=0:00:00, wall=16:55 IST
=> training   0.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.273 DataTime=0.234 Loss=0.811 Prec@1=79.653 Prec@5=93.735 rate=7153.56 Hz, eta=0:00:00, total=0:00:00, wall=16:55 IST
=> training   2.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.273 DataTime=0.234 Loss=0.811 Prec@1=79.653 Prec@5=93.735 rate=0.88 Hz, eta=1:33:22, total=0:01:55, wall=16:55 IST
=> training   2.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.273 DataTime=0.234 Loss=0.811 Prec@1=79.653 Prec@5=93.735 rate=0.88 Hz, eta=1:33:22, total=0:01:55, wall=16:57 IST
=> training   2.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.224 DataTime=0.215 Loss=0.819 Prec@1=79.355 Prec@5=93.791 rate=0.88 Hz, eta=1:33:22, total=0:01:55, wall=16:57 IST
=> training   4.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.224 DataTime=0.215 Loss=0.819 Prec@1=79.355 Prec@5=93.791 rate=0.86 Hz, eta=1:32:43, total=0:03:52, wall=16:57 IST
=> training   4.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.224 DataTime=0.215 Loss=0.819 Prec@1=79.355 Prec@5=93.791 rate=0.86 Hz, eta=1:32:43, total=0:03:52, wall=16:59 IST
=> training   4.02% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.218 DataTime=0.209 Loss=0.823 Prec@1=79.172 Prec@5=93.692 rate=0.86 Hz, eta=1:32:43, total=0:03:52, wall=16:59 IST
=> training   6.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.218 DataTime=0.209 Loss=0.823 Prec@1=79.172 Prec@5=93.692 rate=0.85 Hz, eta=1:32:04, total=0:05:53, wall=16:59 IST
=> training   6.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.218 DataTime=0.209 Loss=0.823 Prec@1=79.172 Prec@5=93.692 rate=0.85 Hz, eta=1:32:04, total=0:05:53, wall=17:01 IST
=> training   6.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.209 DataTime=0.207 Loss=0.825 Prec@1=79.085 Prec@5=93.688 rate=0.85 Hz, eta=1:32:04, total=0:05:53, wall=17:01 IST
=> training   8.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.209 DataTime=0.207 Loss=0.825 Prec@1=79.085 Prec@5=93.688 rate=0.85 Hz, eta=1:30:13, total=0:07:51, wall=17:01 IST
=> training   8.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.209 DataTime=0.207 Loss=0.825 Prec@1=79.085 Prec@5=93.688 rate=0.85 Hz, eta=1:30:13, total=0:07:51, wall=17:03 IST
=> training   8.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.192 DataTime=0.205 Loss=0.826 Prec@1=79.033 Prec@5=93.674 rate=0.85 Hz, eta=1:30:13, total=0:07:51, wall=17:03 IST
=> training   10.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.192 DataTime=0.205 Loss=0.826 Prec@1=79.033 Prec@5=93.674 rate=0.86 Hz, eta=1:27:29, total=0:09:43, wall=17:03 IST
=> training   10.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.192 DataTime=0.205 Loss=0.826 Prec@1=79.033 Prec@5=93.674 rate=0.86 Hz, eta=1:27:29, total=0:09:43, wall=17:05 IST
=> training   10.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.179 DataTime=0.204 Loss=0.827 Prec@1=79.002 Prec@5=93.678 rate=0.86 Hz, eta=1:27:29, total=0:09:43, wall=17:05 IST
=> training   12.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.179 DataTime=0.204 Loss=0.827 Prec@1=79.002 Prec@5=93.678 rate=0.86 Hz, eta=1:24:56, total=0:11:35, wall=17:05 IST
=> training   12.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.179 DataTime=0.204 Loss=0.827 Prec@1=79.002 Prec@5=93.678 rate=0.86 Hz, eta=1:24:56, total=0:11:35, wall=17:06 IST
=> training   12.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.171 DataTime=0.203 Loss=0.828 Prec@1=78.969 Prec@5=93.664 rate=0.86 Hz, eta=1:24:56, total=0:11:35, wall=17:06 IST
=> training   14.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.171 DataTime=0.203 Loss=0.828 Prec@1=78.969 Prec@5=93.664 rate=0.87 Hz, eta=1:22:37, total=0:13:27, wall=17:06 IST
=> training   14.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.171 DataTime=0.203 Loss=0.828 Prec@1=78.969 Prec@5=93.664 rate=0.87 Hz, eta=1:22:37, total=0:13:27, wall=17:08 IST
=> training   14.01% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.164 DataTime=0.203 Loss=0.829 Prec@1=78.990 Prec@5=93.655 rate=0.87 Hz, eta=1:22:37, total=0:13:27, wall=17:08 IST
=> training   16.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.164 DataTime=0.203 Loss=0.829 Prec@1=78.990 Prec@5=93.655 rate=0.87 Hz, eta=1:20:23, total=0:15:18, wall=17:08 IST
=> training   16.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.164 DataTime=0.203 Loss=0.829 Prec@1=78.990 Prec@5=93.655 rate=0.87 Hz, eta=1:20:23, total=0:15:18, wall=17:10 IST
=> training   16.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.159 DataTime=0.202 Loss=0.830 Prec@1=78.953 Prec@5=93.648 rate=0.87 Hz, eta=1:20:23, total=0:15:18, wall=17:10 IST
=> training   18.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.159 DataTime=0.202 Loss=0.830 Prec@1=78.953 Prec@5=93.648 rate=0.87 Hz, eta=1:18:14, total=0:17:10, wall=17:10 IST
=> training   18.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.159 DataTime=0.202 Loss=0.830 Prec@1=78.953 Prec@5=93.648 rate=0.87 Hz, eta=1:18:14, total=0:17:10, wall=17:12 IST
=> training   18.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.155 DataTime=0.202 Loss=0.829 Prec@1=78.972 Prec@5=93.673 rate=0.87 Hz, eta=1:18:14, total=0:17:10, wall=17:12 IST
=> training   20.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.155 DataTime=0.202 Loss=0.829 Prec@1=78.972 Prec@5=93.673 rate=0.88 Hz, eta=1:16:10, total=0:19:02, wall=17:12 IST
=> training   20.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.155 DataTime=0.202 Loss=0.829 Prec@1=78.972 Prec@5=93.673 rate=0.88 Hz, eta=1:16:10, total=0:19:02, wall=17:14 IST
=> training   20.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.151 DataTime=0.202 Loss=0.831 Prec@1=78.935 Prec@5=93.651 rate=0.88 Hz, eta=1:16:10, total=0:19:02, wall=17:14 IST
=> training   22.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.151 DataTime=0.202 Loss=0.831 Prec@1=78.935 Prec@5=93.651 rate=0.88 Hz, eta=1:14:07, total=0:20:54, wall=17:14 IST
=> training   22.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.151 DataTime=0.202 Loss=0.831 Prec@1=78.935 Prec@5=93.651 rate=0.88 Hz, eta=1:14:07, total=0:20:54, wall=17:16 IST
=> training   22.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.148 DataTime=0.202 Loss=0.830 Prec@1=78.954 Prec@5=93.651 rate=0.88 Hz, eta=1:14:07, total=0:20:54, wall=17:16 IST
=> training   24.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.148 DataTime=0.202 Loss=0.830 Prec@1=78.954 Prec@5=93.651 rate=0.88 Hz, eta=1:12:06, total=0:22:45, wall=17:16 IST
=> training   24.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.148 DataTime=0.202 Loss=0.830 Prec@1=78.954 Prec@5=93.651 rate=0.88 Hz, eta=1:12:06, total=0:22:45, wall=17:18 IST
=> training   24.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.146 DataTime=0.201 Loss=0.830 Prec@1=78.957 Prec@5=93.652 rate=0.88 Hz, eta=1:12:06, total=0:22:45, wall=17:18 IST
=> training   25.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.146 DataTime=0.201 Loss=0.830 Prec@1=78.957 Prec@5=93.652 rate=0.88 Hz, eta=1:10:06, total=0:24:37, wall=17:18 IST
=> training   25.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.146 DataTime=0.201 Loss=0.830 Prec@1=78.957 Prec@5=93.652 rate=0.88 Hz, eta=1:10:06, total=0:24:37, wall=17:20 IST
=> training   25.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.144 DataTime=0.201 Loss=0.831 Prec@1=78.973 Prec@5=93.635 rate=0.88 Hz, eta=1:10:06, total=0:24:37, wall=17:20 IST
=> training   27.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.144 DataTime=0.201 Loss=0.831 Prec@1=78.973 Prec@5=93.635 rate=0.88 Hz, eta=1:08:07, total=0:26:29, wall=17:20 IST
=> training   27.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.144 DataTime=0.201 Loss=0.831 Prec@1=78.973 Prec@5=93.635 rate=0.88 Hz, eta=1:08:07, total=0:26:29, wall=17:21 IST
=> training   27.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.142 DataTime=0.201 Loss=0.831 Prec@1=78.969 Prec@5=93.622 rate=0.88 Hz, eta=1:08:07, total=0:26:29, wall=17:21 IST
=> training   29.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.142 DataTime=0.201 Loss=0.831 Prec@1=78.969 Prec@5=93.622 rate=0.88 Hz, eta=1:06:10, total=0:28:20, wall=17:21 IST
=> training   29.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.142 DataTime=0.201 Loss=0.831 Prec@1=78.969 Prec@5=93.622 rate=0.88 Hz, eta=1:06:10, total=0:28:20, wall=17:23 IST
=> training   29.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.140 DataTime=0.201 Loss=0.830 Prec@1=78.999 Prec@5=93.623 rate=0.88 Hz, eta=1:06:10, total=0:28:20, wall=17:23 IST
=> training   31.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.140 DataTime=0.201 Loss=0.830 Prec@1=78.999 Prec@5=93.623 rate=0.88 Hz, eta=1:04:13, total=0:30:12, wall=17:23 IST
=> training   31.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.140 DataTime=0.201 Loss=0.830 Prec@1=78.999 Prec@5=93.623 rate=0.88 Hz, eta=1:04:13, total=0:30:12, wall=17:25 IST
=> training   31.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.139 DataTime=0.201 Loss=0.829 Prec@1=79.019 Prec@5=93.633 rate=0.88 Hz, eta=1:04:13, total=0:30:12, wall=17:25 IST
=> training   33.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.139 DataTime=0.201 Loss=0.829 Prec@1=79.019 Prec@5=93.633 rate=0.88 Hz, eta=1:02:17, total=0:32:04, wall=17:25 IST
=> training   33.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.139 DataTime=0.201 Loss=0.829 Prec@1=79.019 Prec@5=93.633 rate=0.88 Hz, eta=1:02:17, total=0:32:04, wall=17:27 IST
=> training   33.99% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.138 DataTime=0.201 Loss=0.829 Prec@1=79.029 Prec@5=93.627 rate=0.88 Hz, eta=1:02:17, total=0:32:04, wall=17:27 IST
=> training   35.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.138 DataTime=0.201 Loss=0.829 Prec@1=79.029 Prec@5=93.627 rate=0.88 Hz, eta=1:00:21, total=0:33:55, wall=17:27 IST
=> training   35.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.138 DataTime=0.201 Loss=0.829 Prec@1=79.029 Prec@5=93.627 rate=0.88 Hz, eta=1:00:21, total=0:33:55, wall=17:29 IST
=> training   35.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.137 DataTime=0.201 Loss=0.830 Prec@1=79.014 Prec@5=93.620 rate=0.88 Hz, eta=1:00:21, total=0:33:55, wall=17:29 IST
=> training   37.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.137 DataTime=0.201 Loss=0.830 Prec@1=79.014 Prec@5=93.620 rate=0.89 Hz, eta=0:58:26, total=0:35:47, wall=17:29 IST
=> training   37.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.137 DataTime=0.201 Loss=0.830 Prec@1=79.014 Prec@5=93.620 rate=0.89 Hz, eta=0:58:26, total=0:35:47, wall=17:31 IST
=> training   37.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.136 DataTime=0.201 Loss=0.830 Prec@1=79.010 Prec@5=93.608 rate=0.89 Hz, eta=0:58:26, total=0:35:47, wall=17:31 IST
=> training   39.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.136 DataTime=0.201 Loss=0.830 Prec@1=79.010 Prec@5=93.608 rate=0.89 Hz, eta=0:56:31, total=0:37:39, wall=17:31 IST
=> training   39.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.136 DataTime=0.201 Loss=0.830 Prec@1=79.010 Prec@5=93.608 rate=0.89 Hz, eta=0:56:31, total=0:37:39, wall=17:33 IST
=> training   39.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.135 DataTime=0.201 Loss=0.830 Prec@1=79.020 Prec@5=93.614 rate=0.89 Hz, eta=0:56:31, total=0:37:39, wall=17:33 IST
=> training   41.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.135 DataTime=0.201 Loss=0.830 Prec@1=79.020 Prec@5=93.614 rate=0.89 Hz, eta=0:54:36, total=0:39:30, wall=17:33 IST
=> training   41.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.135 DataTime=0.201 Loss=0.830 Prec@1=79.020 Prec@5=93.614 rate=0.89 Hz, eta=0:54:36, total=0:39:30, wall=17:34 IST
=> training   41.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.134 DataTime=0.200 Loss=0.830 Prec@1=79.023 Prec@5=93.615 rate=0.89 Hz, eta=0:54:36, total=0:39:30, wall=17:34 IST
=> training   43.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.134 DataTime=0.200 Loss=0.830 Prec@1=79.023 Prec@5=93.615 rate=0.89 Hz, eta=0:52:42, total=0:41:22, wall=17:34 IST
=> training   43.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.134 DataTime=0.200 Loss=0.830 Prec@1=79.023 Prec@5=93.615 rate=0.89 Hz, eta=0:52:42, total=0:41:22, wall=17:36 IST
=> training   43.98% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.133 DataTime=0.200 Loss=0.830 Prec@1=79.022 Prec@5=93.613 rate=0.89 Hz, eta=0:52:42, total=0:41:22, wall=17:36 IST
=> training   45.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.133 DataTime=0.200 Loss=0.830 Prec@1=79.022 Prec@5=93.613 rate=0.89 Hz, eta=0:50:48, total=0:43:14, wall=17:36 IST
=> training   45.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.133 DataTime=0.200 Loss=0.830 Prec@1=79.022 Prec@5=93.613 rate=0.89 Hz, eta=0:50:48, total=0:43:14, wall=17:38 IST
=> training   45.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.133 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.618 rate=0.89 Hz, eta=0:50:48, total=0:43:14, wall=17:38 IST
=> training   47.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.133 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.618 rate=0.89 Hz, eta=0:48:54, total=0:45:06, wall=17:38 IST
=> training   47.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.133 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.618 rate=0.89 Hz, eta=0:48:54, total=0:45:06, wall=17:40 IST
=> training   47.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.132 DataTime=0.200 Loss=0.830 Prec@1=78.985 Prec@5=93.603 rate=0.89 Hz, eta=0:48:54, total=0:45:06, wall=17:40 IST
=> training   49.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.132 DataTime=0.200 Loss=0.830 Prec@1=78.985 Prec@5=93.603 rate=0.89 Hz, eta=0:47:01, total=0:46:57, wall=17:40 IST
=> training   49.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.132 DataTime=0.200 Loss=0.830 Prec@1=78.985 Prec@5=93.603 rate=0.89 Hz, eta=0:47:01, total=0:46:57, wall=17:42 IST
=> training   49.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.830 Prec@1=78.981 Prec@5=93.606 rate=0.89 Hz, eta=0:47:01, total=0:46:57, wall=17:42 IST
=> training   51.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.830 Prec@1=78.981 Prec@5=93.606 rate=0.89 Hz, eta=0:45:07, total=0:48:49, wall=17:42 IST
=> training   51.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.830 Prec@1=78.981 Prec@5=93.606 rate=0.89 Hz, eta=0:45:07, total=0:48:49, wall=17:44 IST
=> training   51.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.830 Prec@1=78.978 Prec@5=93.609 rate=0.89 Hz, eta=0:45:07, total=0:48:49, wall=17:44 IST
=> training   53.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.830 Prec@1=78.978 Prec@5=93.609 rate=0.89 Hz, eta=0:43:14, total=0:50:41, wall=17:44 IST
=> training   53.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.830 Prec@1=78.978 Prec@5=93.609 rate=0.89 Hz, eta=0:43:14, total=0:50:41, wall=17:46 IST
=> training   53.97% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.831 Prec@1=78.968 Prec@5=93.600 rate=0.89 Hz, eta=0:43:14, total=0:50:41, wall=17:46 IST
=> training   55.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.831 Prec@1=78.968 Prec@5=93.600 rate=0.89 Hz, eta=0:41:21, total=0:52:33, wall=17:46 IST
=> training   55.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.131 DataTime=0.200 Loss=0.831 Prec@1=78.968 Prec@5=93.600 rate=0.89 Hz, eta=0:41:21, total=0:52:33, wall=17:47 IST
=> training   55.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.976 Prec@5=93.604 rate=0.89 Hz, eta=0:41:21, total=0:52:33, wall=17:47 IST
=> training   57.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.976 Prec@5=93.604 rate=0.89 Hz, eta=0:39:28, total=0:54:25, wall=17:47 IST
=> training   57.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.976 Prec@5=93.604 rate=0.89 Hz, eta=0:39:28, total=0:54:25, wall=17:49 IST
=> training   57.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.970 Prec@5=93.600 rate=0.89 Hz, eta=0:39:28, total=0:54:25, wall=17:49 IST
=> training   59.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.970 Prec@5=93.600 rate=0.89 Hz, eta=0:37:35, total=0:56:17, wall=17:49 IST
=> training   59.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.970 Prec@5=93.600 rate=0.89 Hz, eta=0:37:35, total=0:56:17, wall=17:51 IST
=> training   59.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.961 Prec@5=93.598 rate=0.89 Hz, eta=0:37:35, total=0:56:17, wall=17:51 IST
=> training   61.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.961 Prec@5=93.598 rate=0.89 Hz, eta=0:35:42, total=0:58:09, wall=17:51 IST
=> training   61.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.130 DataTime=0.200 Loss=0.831 Prec@1=78.961 Prec@5=93.598 rate=0.89 Hz, eta=0:35:42, total=0:58:09, wall=17:53 IST
=> training   61.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.958 Prec@5=93.600 rate=0.89 Hz, eta=0:35:42, total=0:58:09, wall=17:53 IST
=> training   63.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.958 Prec@5=93.600 rate=0.89 Hz, eta=0:33:49, total=1:00:01, wall=17:53 IST
=> training   63.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.958 Prec@5=93.600 rate=0.89 Hz, eta=0:33:49, total=1:00:01, wall=17:55 IST
=> training   63.96% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.956 Prec@5=93.602 rate=0.89 Hz, eta=0:33:49, total=1:00:01, wall=17:55 IST
=> training   65.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.956 Prec@5=93.602 rate=0.89 Hz, eta=0:31:56, total=1:01:53, wall=17:55 IST
=> training   65.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.956 Prec@5=93.602 rate=0.89 Hz, eta=0:31:56, total=1:01:53, wall=17:57 IST
=> training   65.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.964 Prec@5=93.603 rate=0.89 Hz, eta=0:31:56, total=1:01:53, wall=17:57 IST
=> training   67.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.964 Prec@5=93.603 rate=0.89 Hz, eta=0:30:04, total=1:03:45, wall=17:57 IST
=> training   67.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.129 DataTime=0.200 Loss=0.831 Prec@1=78.964 Prec@5=93.603 rate=0.89 Hz, eta=0:30:04, total=1:03:45, wall=17:59 IST
=> training   67.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.831 Prec@1=78.963 Prec@5=93.604 rate=0.89 Hz, eta=0:30:04, total=1:03:45, wall=17:59 IST
=> training   69.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.831 Prec@1=78.963 Prec@5=93.604 rate=0.89 Hz, eta=0:28:11, total=1:05:37, wall=17:59 IST
=> training   69.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.831 Prec@1=78.963 Prec@5=93.604 rate=0.89 Hz, eta=0:28:11, total=1:05:37, wall=18:01 IST
=> training   69.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.962 Prec@5=93.610 rate=0.89 Hz, eta=0:28:11, total=1:05:37, wall=18:01 IST
=> training   71.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.962 Prec@5=93.610 rate=0.89 Hz, eta=0:26:18, total=1:07:29, wall=18:01 IST
=> training   71.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.962 Prec@5=93.610 rate=0.89 Hz, eta=0:26:18, total=1:07:29, wall=18:02 IST
=> training   71.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.965 Prec@5=93.613 rate=0.89 Hz, eta=0:26:18, total=1:07:29, wall=18:02 IST
=> training   73.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.965 Prec@5=93.613 rate=0.89 Hz, eta=0:24:26, total=1:09:21, wall=18:02 IST
=> training   73.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.965 Prec@5=93.613 rate=0.89 Hz, eta=0:24:26, total=1:09:21, wall=18:04 IST
=> training   73.95% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.962 Prec@5=93.615 rate=0.89 Hz, eta=0:24:26, total=1:09:21, wall=18:04 IST
=> training   75.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.962 Prec@5=93.615 rate=0.89 Hz, eta=0:22:33, total=1:11:13, wall=18:04 IST
=> training   75.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.962 Prec@5=93.615 rate=0.89 Hz, eta=0:22:33, total=1:11:13, wall=18:06 IST
=> training   75.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.619 rate=0.89 Hz, eta=0:22:33, total=1:11:13, wall=18:06 IST
=> training   77.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.619 rate=0.89 Hz, eta=0:20:41, total=1:13:05, wall=18:06 IST
=> training   77.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.128 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.619 rate=0.89 Hz, eta=0:20:41, total=1:13:05, wall=18:08 IST
=> training   77.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.965 Prec@5=93.622 rate=0.89 Hz, eta=0:20:41, total=1:13:05, wall=18:08 IST
=> training   79.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.965 Prec@5=93.622 rate=0.89 Hz, eta=0:18:48, total=1:14:57, wall=18:08 IST
=> training   79.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.965 Prec@5=93.622 rate=0.89 Hz, eta=0:18:48, total=1:14:57, wall=18:10 IST
=> training   79.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.957 Prec@5=93.613 rate=0.89 Hz, eta=0:18:48, total=1:14:57, wall=18:10 IST
=> training   81.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.957 Prec@5=93.613 rate=0.89 Hz, eta=0:16:56, total=1:16:49, wall=18:10 IST
=> training   81.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.957 Prec@5=93.613 rate=0.89 Hz, eta=0:16:56, total=1:16:49, wall=18:12 IST
=> training   81.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.957 Prec@5=93.613 rate=0.89 Hz, eta=0:16:56, total=1:16:49, wall=18:12 IST
=> training   83.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.957 Prec@5=93.613 rate=0.89 Hz, eta=0:15:03, total=1:18:41, wall=18:12 IST
=> training   83.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.957 Prec@5=93.613 rate=0.89 Hz, eta=0:15:03, total=1:18:41, wall=18:14 IST
=> training   83.94% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.974 Prec@5=93.614 rate=0.89 Hz, eta=0:15:03, total=1:18:41, wall=18:14 IST
=> training   85.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.974 Prec@5=93.614 rate=0.89 Hz, eta=0:13:11, total=1:20:33, wall=18:14 IST
=> training   85.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.974 Prec@5=93.614 rate=0.89 Hz, eta=0:13:11, total=1:20:33, wall=18:15 IST
=> training   85.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.975 Prec@5=93.618 rate=0.89 Hz, eta=0:13:11, total=1:20:33, wall=18:15 IST
=> training   87.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.975 Prec@5=93.618 rate=0.89 Hz, eta=0:11:18, total=1:22:25, wall=18:15 IST
=> training   87.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.975 Prec@5=93.618 rate=0.89 Hz, eta=0:11:18, total=1:22:25, wall=18:17 IST
=> training   87.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.974 Prec@5=93.613 rate=0.89 Hz, eta=0:11:18, total=1:22:25, wall=18:17 IST
=> training   89.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.974 Prec@5=93.613 rate=0.89 Hz, eta=0:09:26, total=1:24:17, wall=18:17 IST
=> training   89.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.127 DataTime=0.200 Loss=0.830 Prec@1=78.974 Prec@5=93.613 rate=0.89 Hz, eta=0:09:26, total=1:24:17, wall=18:19 IST
=> training   89.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.615 rate=0.89 Hz, eta=0:09:26, total=1:24:17, wall=18:19 IST
=> training   91.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.615 rate=0.89 Hz, eta=0:07:33, total=1:26:09, wall=18:19 IST
=> training   91.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.615 rate=0.89 Hz, eta=0:07:33, total=1:26:09, wall=18:21 IST
=> training   91.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.613 rate=0.89 Hz, eta=0:07:33, total=1:26:09, wall=18:21 IST
=> training   93.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.613 rate=0.89 Hz, eta=0:05:41, total=1:28:01, wall=18:21 IST
=> training   93.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.613 rate=0.89 Hz, eta=0:05:41, total=1:28:01, wall=18:23 IST
=> training   93.93% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.611 rate=0.89 Hz, eta=0:05:41, total=1:28:01, wall=18:23 IST
=> training   95.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.611 rate=0.89 Hz, eta=0:03:49, total=1:29:53, wall=18:23 IST
=> training   95.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.611 rate=0.89 Hz, eta=0:03:49, total=1:29:53, wall=18:25 IST
=> training   95.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.973 Prec@5=93.617 rate=0.89 Hz, eta=0:03:49, total=1:29:53, wall=18:25 IST
=> training   97.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.973 Prec@5=93.617 rate=0.89 Hz, eta=0:01:56, total=1:31:45, wall=18:25 IST
=> training   97.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.973 Prec@5=93.617 rate=0.89 Hz, eta=0:01:56, total=1:31:45, wall=18:27 IST
=> training   97.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.609 rate=0.89 Hz, eta=0:01:56, total=1:31:45, wall=18:27 IST
=> training   99.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.609 rate=0.89 Hz, eta=0:00:04, total=1:33:36, wall=18:27 IST
=> training   99.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.963 Prec@5=93.609 rate=0.89 Hz, eta=0:00:04, total=1:33:36, wall=18:27 IST
=> training   99.92% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.962 Prec@5=93.608 rate=0.89 Hz, eta=0:00:04, total=1:33:36, wall=18:27 IST
=> training   100.00% of 1x5005...Epoch=1/10 LR=0.00000 Time=1.126 DataTime=0.200 Loss=0.830 Prec@1=78.962 Prec@5=93.608 rate=0.89 Hz, eta=0:00:00, total=1:33:43, wall=18:27 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 4.000 4.000 8.000 2.000 4.000 8.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 4.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=18:27 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=18:27 IST
=> validation 0.00% of 1x196...Epoch=1/10 LR=0.00000 Time=8.013 Loss=1.249 Prec@1=74.219 Prec@5=85.156 rate=0 Hz, eta=?, total=0:00:00, wall=18:27 IST
=> validation 0.51% of 1x196...Epoch=1/10 LR=0.00000 Time=8.013 Loss=1.249 Prec@1=74.219 Prec@5=85.156 rate=7427.30 Hz, eta=0:00:00, total=0:00:00, wall=18:27 IST
=> validation 0.51% of 1x196...Epoch=1/10 LR=0.00000 Time=8.013 Loss=1.249 Prec@1=74.219 Prec@5=85.156 rate=7427.30 Hz, eta=0:00:00, total=0:00:00, wall=18:28 IST
=> validation 0.51% of 1x196...Epoch=1/10 LR=0.00000 Time=0.709 Loss=1.179 Prec@1=71.198 Prec@5=89.770 rate=7427.30 Hz, eta=0:00:00, total=0:00:00, wall=18:28 IST
=> validation 51.53% of 1x196...Epoch=1/10 LR=0.00000 Time=0.709 Loss=1.179 Prec@1=71.198 Prec@5=89.770 rate=1.59 Hz, eta=0:00:59, total=0:01:03, wall=18:28 IST
** validation 51.53% of 1x196...Epoch=1/10 LR=0.00000 Time=0.709 Loss=1.179 Prec@1=71.198 Prec@5=89.770 rate=1.59 Hz, eta=0:00:59, total=0:01:03, wall=18:29 IST
** validation 51.53% of 1x196...Epoch=1/10 LR=0.00000 Time=0.649 Loss=1.170 Prec@1=71.156 Prec@5=90.050 rate=1.59 Hz, eta=0:00:59, total=0:01:03, wall=18:29 IST
** validation 100.00% of 1x196...Epoch=1/10 LR=0.00000 Time=0.649 Loss=1.170 Prec@1=71.156 Prec@5=90.050 rate=1.64 Hz, eta=0:00:00, total=0:01:59, wall=18:29 IST
[39m[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=18:29 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=18:29 IST
=> training   0.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=6.840 DataTime=4.540 Loss=0.891 Prec@1=75.781 Prec@5=94.531 rate=0 Hz, eta=?, total=0:00:00, wall=18:29 IST
=> training   0.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=6.840 DataTime=4.540 Loss=0.891 Prec@1=75.781 Prec@5=94.531 rate=152.73 Hz, eta=0:00:32, total=0:00:00, wall=18:29 IST
=> training   0.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=6.840 DataTime=4.540 Loss=0.891 Prec@1=75.781 Prec@5=94.531 rate=152.73 Hz, eta=0:00:32, total=0:00:00, wall=18:31 IST
=> training   0.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.188 DataTime=0.242 Loss=0.837 Prec@1=78.740 Prec@5=93.487 rate=152.73 Hz, eta=0:00:32, total=0:00:00, wall=18:31 IST
=> training   2.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.188 DataTime=0.242 Loss=0.837 Prec@1=78.740 Prec@5=93.487 rate=0.89 Hz, eta=1:31:34, total=0:01:53, wall=18:31 IST
=> training   2.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.188 DataTime=0.242 Loss=0.837 Prec@1=78.740 Prec@5=93.487 rate=0.89 Hz, eta=1:31:34, total=0:01:53, wall=18:33 IST
=> training   2.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.154 DataTime=0.221 Loss=0.840 Prec@1=78.632 Prec@5=93.408 rate=0.89 Hz, eta=1:31:34, total=0:01:53, wall=18:33 IST
=> training   4.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.154 DataTime=0.221 Loss=0.840 Prec@1=78.632 Prec@5=93.408 rate=0.89 Hz, eta=1:29:39, total=0:03:45, wall=18:33 IST
=> training   4.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.154 DataTime=0.221 Loss=0.840 Prec@1=78.632 Prec@5=93.408 rate=0.89 Hz, eta=1:29:39, total=0:03:45, wall=18:35 IST
=> training   4.02% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.142 DataTime=0.213 Loss=0.838 Prec@1=78.731 Prec@5=93.437 rate=0.89 Hz, eta=1:29:39, total=0:03:45, wall=18:35 IST
=> training   6.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.142 DataTime=0.213 Loss=0.838 Prec@1=78.731 Prec@5=93.437 rate=0.89 Hz, eta=1:27:46, total=0:05:36, wall=18:35 IST
=> training   6.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.142 DataTime=0.213 Loss=0.838 Prec@1=78.731 Prec@5=93.437 rate=0.89 Hz, eta=1:27:46, total=0:05:36, wall=18:37 IST
=> training   6.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.136 DataTime=0.210 Loss=0.836 Prec@1=78.784 Prec@5=93.518 rate=0.89 Hz, eta=1:27:46, total=0:05:36, wall=18:37 IST
=> training   8.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.136 DataTime=0.210 Loss=0.836 Prec@1=78.784 Prec@5=93.518 rate=0.89 Hz, eta=1:25:53, total=0:07:28, wall=18:37 IST
=> training   8.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.136 DataTime=0.210 Loss=0.836 Prec@1=78.784 Prec@5=93.518 rate=0.89 Hz, eta=1:25:53, total=0:07:28, wall=18:38 IST
=> training   8.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.133 DataTime=0.208 Loss=0.835 Prec@1=78.822 Prec@5=93.512 rate=0.89 Hz, eta=1:25:53, total=0:07:28, wall=18:38 IST
=> training   10.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.133 DataTime=0.208 Loss=0.835 Prec@1=78.822 Prec@5=93.512 rate=0.89 Hz, eta=1:24:00, total=0:09:20, wall=18:38 IST
=> training   10.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.133 DataTime=0.208 Loss=0.835 Prec@1=78.822 Prec@5=93.512 rate=0.89 Hz, eta=1:24:00, total=0:09:20, wall=18:40 IST
=> training   10.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.130 DataTime=0.206 Loss=0.836 Prec@1=78.882 Prec@5=93.522 rate=0.89 Hz, eta=1:24:00, total=0:09:20, wall=18:40 IST
=> training   12.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.130 DataTime=0.206 Loss=0.836 Prec@1=78.882 Prec@5=93.522 rate=0.89 Hz, eta=1:22:07, total=0:11:12, wall=18:40 IST
=> training   12.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.130 DataTime=0.206 Loss=0.836 Prec@1=78.882 Prec@5=93.522 rate=0.89 Hz, eta=1:22:07, total=0:11:12, wall=18:42 IST
=> training   12.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.129 DataTime=0.205 Loss=0.834 Prec@1=78.955 Prec@5=93.519 rate=0.89 Hz, eta=1:22:07, total=0:11:12, wall=18:42 IST
=> training   14.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.129 DataTime=0.205 Loss=0.834 Prec@1=78.955 Prec@5=93.519 rate=0.89 Hz, eta=1:20:15, total=0:13:04, wall=18:42 IST
=> training   14.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.129 DataTime=0.205 Loss=0.834 Prec@1=78.955 Prec@5=93.519 rate=0.89 Hz, eta=1:20:15, total=0:13:04, wall=18:44 IST
=> training   14.01% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.127 DataTime=0.205 Loss=0.833 Prec@1=78.924 Prec@5=93.540 rate=0.89 Hz, eta=1:20:15, total=0:13:04, wall=18:44 IST
=> training   16.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.127 DataTime=0.205 Loss=0.833 Prec@1=78.924 Prec@5=93.540 rate=0.89 Hz, eta=1:18:24, total=0:14:56, wall=18:44 IST
=> training   16.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.127 DataTime=0.205 Loss=0.833 Prec@1=78.924 Prec@5=93.540 rate=0.89 Hz, eta=1:18:24, total=0:14:56, wall=18:46 IST
=> training   16.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.127 DataTime=0.204 Loss=0.831 Prec@1=78.970 Prec@5=93.591 rate=0.89 Hz, eta=1:18:24, total=0:14:56, wall=18:46 IST
=> training   18.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.127 DataTime=0.204 Loss=0.831 Prec@1=78.970 Prec@5=93.591 rate=0.89 Hz, eta=1:16:32, total=0:16:48, wall=18:46 IST
=> training   18.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.127 DataTime=0.204 Loss=0.831 Prec@1=78.970 Prec@5=93.591 rate=0.89 Hz, eta=1:16:32, total=0:16:48, wall=18:48 IST
=> training   18.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.126 DataTime=0.203 Loss=0.832 Prec@1=78.940 Prec@5=93.585 rate=0.89 Hz, eta=1:16:32, total=0:16:48, wall=18:48 IST
=> training   20.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.126 DataTime=0.203 Loss=0.832 Prec@1=78.940 Prec@5=93.585 rate=0.89 Hz, eta=1:14:40, total=0:18:40, wall=18:48 IST
=> training   20.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.126 DataTime=0.203 Loss=0.832 Prec@1=78.940 Prec@5=93.585 rate=0.89 Hz, eta=1:14:40, total=0:18:40, wall=18:50 IST
=> training   20.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.125 DataTime=0.203 Loss=0.831 Prec@1=78.943 Prec@5=93.583 rate=0.89 Hz, eta=1:14:40, total=0:18:40, wall=18:50 IST
=> training   22.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.125 DataTime=0.203 Loss=0.831 Prec@1=78.943 Prec@5=93.583 rate=0.89 Hz, eta=1:12:48, total=0:20:31, wall=18:50 IST
=> training   22.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.125 DataTime=0.203 Loss=0.831 Prec@1=78.943 Prec@5=93.583 rate=0.89 Hz, eta=1:12:48, total=0:20:31, wall=18:52 IST
=> training   22.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.125 DataTime=0.203 Loss=0.833 Prec@1=78.893 Prec@5=93.563 rate=0.89 Hz, eta=1:12:48, total=0:20:31, wall=18:52 IST
=> training   24.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.125 DataTime=0.203 Loss=0.833 Prec@1=78.893 Prec@5=93.563 rate=0.89 Hz, eta=1:10:56, total=0:22:23, wall=18:52 IST
=> training   24.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.125 DataTime=0.203 Loss=0.833 Prec@1=78.893 Prec@5=93.563 rate=0.89 Hz, eta=1:10:56, total=0:22:23, wall=18:53 IST
=> training   24.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.833 Prec@1=78.899 Prec@5=93.560 rate=0.89 Hz, eta=1:10:56, total=0:22:23, wall=18:53 IST
=> training   25.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.833 Prec@1=78.899 Prec@5=93.560 rate=0.89 Hz, eta=1:09:04, total=0:24:15, wall=18:53 IST
=> training   25.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.833 Prec@1=78.899 Prec@5=93.560 rate=0.89 Hz, eta=1:09:04, total=0:24:15, wall=18:55 IST
=> training   25.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.833 Prec@1=78.908 Prec@5=93.566 rate=0.89 Hz, eta=1:09:04, total=0:24:15, wall=18:55 IST
=> training   27.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.833 Prec@1=78.908 Prec@5=93.566 rate=0.89 Hz, eta=1:07:12, total=0:26:07, wall=18:55 IST
=> training   27.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.833 Prec@1=78.908 Prec@5=93.566 rate=0.89 Hz, eta=1:07:12, total=0:26:07, wall=18:57 IST
=> training   27.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.831 Prec@1=78.935 Prec@5=93.581 rate=0.89 Hz, eta=1:07:12, total=0:26:07, wall=18:57 IST
=> training   29.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.831 Prec@1=78.935 Prec@5=93.581 rate=0.89 Hz, eta=1:05:20, total=0:27:59, wall=18:57 IST
=> training   29.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.202 Loss=0.831 Prec@1=78.935 Prec@5=93.581 rate=0.89 Hz, eta=1:05:20, total=0:27:59, wall=18:59 IST
=> training   29.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.830 Prec@1=78.959 Prec@5=93.598 rate=0.89 Hz, eta=1:05:20, total=0:27:59, wall=18:59 IST
=> training   31.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.830 Prec@1=78.959 Prec@5=93.598 rate=0.89 Hz, eta=1:03:28, total=0:29:51, wall=18:59 IST
=> training   31.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.830 Prec@1=78.959 Prec@5=93.598 rate=0.89 Hz, eta=1:03:28, total=0:29:51, wall=19:01 IST
=> training   31.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.831 Prec@1=78.959 Prec@5=93.591 rate=0.89 Hz, eta=1:03:28, total=0:29:51, wall=19:01 IST
=> training   33.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.831 Prec@1=78.959 Prec@5=93.591 rate=0.89 Hz, eta=1:01:36, total=0:31:43, wall=19:01 IST
=> training   33.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.831 Prec@1=78.959 Prec@5=93.591 rate=0.89 Hz, eta=1:01:36, total=0:31:43, wall=19:03 IST
=> training   33.99% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.831 Prec@1=78.952 Prec@5=93.594 rate=0.89 Hz, eta=1:01:36, total=0:31:43, wall=19:03 IST
=> training   35.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.831 Prec@1=78.952 Prec@5=93.594 rate=0.89 Hz, eta=0:59:45, total=0:33:35, wall=19:03 IST
=> training   35.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.202 Loss=0.831 Prec@1=78.952 Prec@5=93.594 rate=0.89 Hz, eta=0:59:45, total=0:33:35, wall=19:05 IST
=> training   35.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.201 Loss=0.830 Prec@1=78.969 Prec@5=93.598 rate=0.89 Hz, eta=0:59:45, total=0:33:35, wall=19:05 IST
=> training   37.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.201 Loss=0.830 Prec@1=78.969 Prec@5=93.598 rate=0.89 Hz, eta=0:57:53, total=0:35:27, wall=19:05 IST
=> training   37.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.201 Loss=0.830 Prec@1=78.969 Prec@5=93.598 rate=0.89 Hz, eta=0:57:53, total=0:35:27, wall=19:06 IST
=> training   37.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.960 Prec@5=93.598 rate=0.89 Hz, eta=0:57:53, total=0:35:27, wall=19:06 IST
=> training   39.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.960 Prec@5=93.598 rate=0.89 Hz, eta=0:56:01, total=0:37:19, wall=19:06 IST
=> training   39.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.960 Prec@5=93.598 rate=0.89 Hz, eta=0:56:01, total=0:37:19, wall=19:08 IST
=> training   39.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.955 Prec@5=93.601 rate=0.89 Hz, eta=0:56:01, total=0:37:19, wall=19:08 IST
=> training   41.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.955 Prec@5=93.601 rate=0.89 Hz, eta=0:54:09, total=0:39:10, wall=19:08 IST
=> training   41.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.955 Prec@5=93.601 rate=0.89 Hz, eta=0:54:09, total=0:39:10, wall=19:10 IST
=> training   41.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.945 Prec@5=93.601 rate=0.89 Hz, eta=0:54:09, total=0:39:10, wall=19:10 IST
=> training   43.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.945 Prec@5=93.601 rate=0.89 Hz, eta=0:52:17, total=0:41:03, wall=19:10 IST
=> training   43.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.945 Prec@5=93.601 rate=0.89 Hz, eta=0:52:17, total=0:41:03, wall=19:12 IST
=> training   43.98% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.961 Prec@5=93.596 rate=0.89 Hz, eta=0:52:17, total=0:41:03, wall=19:12 IST
=> training   45.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.961 Prec@5=93.596 rate=0.89 Hz, eta=0:50:26, total=0:42:55, wall=19:12 IST
=> training   45.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.961 Prec@5=93.596 rate=0.89 Hz, eta=0:50:26, total=0:42:55, wall=19:14 IST
=> training   45.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.976 Prec@5=93.598 rate=0.89 Hz, eta=0:50:26, total=0:42:55, wall=19:14 IST
=> training   47.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.976 Prec@5=93.598 rate=0.89 Hz, eta=0:48:34, total=0:44:47, wall=19:14 IST
=> training   47.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.976 Prec@5=93.598 rate=0.89 Hz, eta=0:48:34, total=0:44:47, wall=19:16 IST
=> training   47.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.969 Prec@5=93.600 rate=0.89 Hz, eta=0:48:34, total=0:44:47, wall=19:16 IST
=> training   49.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.969 Prec@5=93.600 rate=0.89 Hz, eta=0:46:42, total=0:46:39, wall=19:16 IST
=> training   49.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.969 Prec@5=93.600 rate=0.89 Hz, eta=0:46:42, total=0:46:39, wall=19:18 IST
=> training   49.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.965 Prec@5=93.596 rate=0.89 Hz, eta=0:46:42, total=0:46:39, wall=19:18 IST
=> training   51.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.965 Prec@5=93.596 rate=0.89 Hz, eta=0:44:51, total=0:48:31, wall=19:18 IST
=> training   51.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.965 Prec@5=93.596 rate=0.89 Hz, eta=0:44:51, total=0:48:31, wall=19:19 IST
=> training   51.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.982 Prec@5=93.602 rate=0.89 Hz, eta=0:44:51, total=0:48:31, wall=19:19 IST
=> training   53.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.982 Prec@5=93.602 rate=0.89 Hz, eta=0:42:59, total=0:50:23, wall=19:19 IST
=> training   53.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.982 Prec@5=93.602 rate=0.89 Hz, eta=0:42:59, total=0:50:23, wall=19:21 IST
=> training   53.97% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.962 Prec@5=93.599 rate=0.89 Hz, eta=0:42:59, total=0:50:23, wall=19:21 IST
=> training   55.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.962 Prec@5=93.599 rate=0.89 Hz, eta=0:41:07, total=0:52:15, wall=19:21 IST
=> training   55.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.962 Prec@5=93.599 rate=0.89 Hz, eta=0:41:07, total=0:52:15, wall=19:23 IST
=> training   55.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.971 Prec@5=93.598 rate=0.89 Hz, eta=0:41:07, total=0:52:15, wall=19:23 IST
=> training   57.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.971 Prec@5=93.598 rate=0.89 Hz, eta=0:39:15, total=0:54:07, wall=19:23 IST
=> training   57.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.971 Prec@5=93.598 rate=0.89 Hz, eta=0:39:15, total=0:54:07, wall=19:25 IST
=> training   57.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.967 Prec@5=93.596 rate=0.89 Hz, eta=0:39:15, total=0:54:07, wall=19:25 IST
=> training   59.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.967 Prec@5=93.596 rate=0.89 Hz, eta=0:37:23, total=0:56:00, wall=19:25 IST
=> training   59.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.831 Prec@1=78.967 Prec@5=93.596 rate=0.89 Hz, eta=0:37:23, total=0:56:00, wall=19:27 IST
=> training   59.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.830 Prec@1=78.982 Prec@5=93.604 rate=0.89 Hz, eta=0:37:23, total=0:56:00, wall=19:27 IST
=> training   61.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.830 Prec@1=78.982 Prec@5=93.604 rate=0.89 Hz, eta=0:35:31, total=0:57:52, wall=19:27 IST
=> training   61.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.201 Loss=0.830 Prec@1=78.982 Prec@5=93.604 rate=0.89 Hz, eta=0:35:31, total=0:57:52, wall=19:29 IST
=> training   61.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.600 rate=0.89 Hz, eta=0:35:31, total=0:57:52, wall=19:29 IST
=> training   63.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.600 rate=0.89 Hz, eta=0:33:40, total=0:59:44, wall=19:29 IST
=> training   63.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.971 Prec@5=93.600 rate=0.89 Hz, eta=0:33:40, total=0:59:44, wall=19:31 IST
=> training   63.96% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.986 Prec@5=93.609 rate=0.89 Hz, eta=0:33:40, total=0:59:44, wall=19:31 IST
=> training   65.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.986 Prec@5=93.609 rate=0.89 Hz, eta=0:31:48, total=1:01:36, wall=19:31 IST
=> training   65.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.986 Prec@5=93.609 rate=0.89 Hz, eta=0:31:48, total=1:01:36, wall=19:33 IST
=> training   65.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.988 Prec@5=93.605 rate=0.89 Hz, eta=0:31:48, total=1:01:36, wall=19:33 IST
=> training   67.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.988 Prec@5=93.605 rate=0.89 Hz, eta=0:29:56, total=1:03:28, wall=19:33 IST
=> training   67.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.122 DataTime=0.200 Loss=0.830 Prec@1=78.988 Prec@5=93.605 rate=0.89 Hz, eta=0:29:56, total=1:03:28, wall=19:35 IST
=> training   67.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.993 Prec@5=93.604 rate=0.89 Hz, eta=0:29:56, total=1:03:28, wall=19:35 IST
=> training   69.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.993 Prec@5=93.604 rate=0.89 Hz, eta=0:28:06, total=1:05:25, wall=19:35 IST
=> training   69.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.993 Prec@5=93.604 rate=0.89 Hz, eta=0:28:06, total=1:05:25, wall=19:36 IST
=> training   69.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.982 Prec@5=93.597 rate=0.89 Hz, eta=0:28:06, total=1:05:25, wall=19:36 IST
=> training   71.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.982 Prec@5=93.597 rate=0.89 Hz, eta=0:26:14, total=1:07:18, wall=19:36 IST
=> training   71.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.982 Prec@5=93.597 rate=0.89 Hz, eta=0:26:14, total=1:07:18, wall=19:38 IST
=> training   71.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.991 Prec@5=93.594 rate=0.89 Hz, eta=0:26:14, total=1:07:18, wall=19:38 IST
=> training   73.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.991 Prec@5=93.594 rate=0.89 Hz, eta=0:24:22, total=1:09:10, wall=19:38 IST
=> training   73.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.991 Prec@5=93.594 rate=0.89 Hz, eta=0:24:22, total=1:09:10, wall=19:40 IST
=> training   73.95% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.982 Prec@5=93.602 rate=0.89 Hz, eta=0:24:22, total=1:09:10, wall=19:40 IST
=> training   75.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.982 Prec@5=93.602 rate=0.89 Hz, eta=0:22:30, total=1:11:02, wall=19:40 IST
=> training   75.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.982 Prec@5=93.602 rate=0.89 Hz, eta=0:22:30, total=1:11:02, wall=19:42 IST
=> training   75.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.986 Prec@5=93.607 rate=0.89 Hz, eta=0:22:30, total=1:11:02, wall=19:42 IST
=> training   77.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.986 Prec@5=93.607 rate=0.89 Hz, eta=0:20:37, total=1:12:54, wall=19:42 IST
=> training   77.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.986 Prec@5=93.607 rate=0.89 Hz, eta=0:20:37, total=1:12:54, wall=19:44 IST
=> training   77.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.991 Prec@5=93.610 rate=0.89 Hz, eta=0:20:37, total=1:12:54, wall=19:44 IST
=> training   79.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.991 Prec@5=93.610 rate=0.89 Hz, eta=0:18:46, total=1:14:47, wall=19:44 IST
=> training   79.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.991 Prec@5=93.610 rate=0.89 Hz, eta=0:18:46, total=1:14:47, wall=19:46 IST
=> training   79.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.992 Prec@5=93.614 rate=0.89 Hz, eta=0:18:46, total=1:14:47, wall=19:46 IST
=> training   81.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.992 Prec@5=93.614 rate=0.89 Hz, eta=0:16:54, total=1:16:40, wall=19:46 IST
=> training   81.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.830 Prec@1=78.992 Prec@5=93.614 rate=0.89 Hz, eta=0:16:54, total=1:16:40, wall=19:48 IST
=> training   81.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.829 Prec@1=79.001 Prec@5=93.622 rate=0.89 Hz, eta=0:16:54, total=1:16:40, wall=19:48 IST
=> training   83.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.829 Prec@1=79.001 Prec@5=93.622 rate=0.89 Hz, eta=0:15:01, total=1:18:32, wall=19:48 IST
=> training   83.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.829 Prec@1=79.001 Prec@5=93.622 rate=0.89 Hz, eta=0:15:01, total=1:18:32, wall=19:50 IST
=> training   83.94% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.829 Prec@1=79.015 Prec@5=93.627 rate=0.89 Hz, eta=0:15:01, total=1:18:32, wall=19:50 IST
=> training   85.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.829 Prec@1=79.015 Prec@5=93.627 rate=0.89 Hz, eta=0:13:09, total=1:20:25, wall=19:50 IST
=> training   85.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.123 DataTime=0.200 Loss=0.829 Prec@1=79.015 Prec@5=93.627 rate=0.89 Hz, eta=0:13:09, total=1:20:25, wall=19:51 IST
=> training   85.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.011 Prec@5=93.631 rate=0.89 Hz, eta=0:13:09, total=1:20:25, wall=19:51 IST
=> training   87.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.011 Prec@5=93.631 rate=0.89 Hz, eta=0:11:17, total=1:22:17, wall=19:51 IST
=> training   87.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.011 Prec@5=93.631 rate=0.89 Hz, eta=0:11:17, total=1:22:17, wall=19:53 IST
=> training   87.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.018 Prec@5=93.629 rate=0.89 Hz, eta=0:11:17, total=1:22:17, wall=19:53 IST
=> training   89.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.018 Prec@5=93.629 rate=0.89 Hz, eta=0:09:25, total=1:24:10, wall=19:53 IST
=> training   89.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.018 Prec@5=93.629 rate=0.89 Hz, eta=0:09:25, total=1:24:10, wall=19:55 IST
=> training   89.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.019 Prec@5=93.628 rate=0.89 Hz, eta=0:09:25, total=1:24:10, wall=19:55 IST
=> training   91.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.019 Prec@5=93.628 rate=0.89 Hz, eta=0:07:33, total=1:26:03, wall=19:55 IST
=> training   91.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.019 Prec@5=93.628 rate=0.89 Hz, eta=0:07:33, total=1:26:03, wall=19:57 IST
=> training   91.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.628 rate=0.89 Hz, eta=0:07:33, total=1:26:03, wall=19:57 IST
=> training   93.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.628 rate=0.89 Hz, eta=0:05:41, total=1:27:56, wall=19:57 IST
=> training   93.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.628 rate=0.89 Hz, eta=0:05:41, total=1:27:56, wall=19:59 IST
=> training   93.93% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.625 rate=0.89 Hz, eta=0:05:41, total=1:27:56, wall=19:59 IST
=> training   95.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.625 rate=0.89 Hz, eta=0:03:48, total=1:29:48, wall=19:59 IST
=> training   95.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.017 Prec@5=93.625 rate=0.89 Hz, eta=0:03:48, total=1:29:48, wall=20:01 IST
=> training   95.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.021 Prec@5=93.624 rate=0.89 Hz, eta=0:03:48, total=1:29:48, wall=20:01 IST
=> training   97.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.021 Prec@5=93.624 rate=0.89 Hz, eta=0:01:56, total=1:31:42, wall=20:01 IST
=> training   97.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.021 Prec@5=93.624 rate=0.89 Hz, eta=0:01:56, total=1:31:42, wall=20:03 IST
=> training   97.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.020 Prec@5=93.626 rate=0.89 Hz, eta=0:01:56, total=1:31:42, wall=20:03 IST
=> training   99.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.020 Prec@5=93.626 rate=0.89 Hz, eta=0:00:04, total=1:33:33, wall=20:03 IST
=> training   99.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.020 Prec@5=93.626 rate=0.89 Hz, eta=0:00:04, total=1:33:33, wall=20:03 IST
=> training   99.92% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.019 Prec@5=93.626 rate=0.89 Hz, eta=0:00:04, total=1:33:33, wall=20:03 IST
=> training   100.00% of 1x5005...Epoch=2/10 LR=0.00002 Time=1.124 DataTime=0.200 Loss=0.829 Prec@1=79.019 Prec@5=93.626 rate=0.89 Hz, eta=0:00:00, total=1:33:37, wall=20:03 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 4.000 4.000 8.000 2.000 4.000 8.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 4.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=20:03 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=20:03 IST
=> validation 0.00% of 1x196...Epoch=2/10 LR=0.00002 Time=8.096 Loss=1.053 Prec@1=69.141 Prec@5=91.016 rate=0 Hz, eta=?, total=0:00:00, wall=20:03 IST
=> validation 0.51% of 1x196...Epoch=2/10 LR=0.00002 Time=8.096 Loss=1.053 Prec@1=69.141 Prec@5=91.016 rate=8176.16 Hz, eta=0:00:00, total=0:00:00, wall=20:03 IST
=> validation 0.51% of 1x196...Epoch=2/10 LR=0.00002 Time=8.096 Loss=1.053 Prec@1=69.141 Prec@5=91.016 rate=8176.16 Hz, eta=0:00:00, total=0:00:00, wall=20:04 IST
=> validation 0.51% of 1x196...Epoch=2/10 LR=0.00002 Time=0.743 Loss=1.164 Prec@1=71.074 Prec@5=90.172 rate=8176.16 Hz, eta=0:00:00, total=0:00:00, wall=20:04 IST
=> validation 51.53% of 1x196...Epoch=2/10 LR=0.00002 Time=0.743 Loss=1.164 Prec@1=71.074 Prec@5=90.172 rate=1.51 Hz, eta=0:01:02, total=0:01:06, wall=20:04 IST
** validation 51.53% of 1x196...Epoch=2/10 LR=0.00002 Time=0.743 Loss=1.164 Prec@1=71.074 Prec@5=90.172 rate=1.51 Hz, eta=0:01:02, total=0:01:06, wall=20:05 IST
** validation 51.53% of 1x196...Epoch=2/10 LR=0.00002 Time=0.679 Loss=1.177 Prec@1=70.974 Prec@5=90.004 rate=1.51 Hz, eta=0:01:02, total=0:01:06, wall=20:05 IST
** validation 100.00% of 1x196...Epoch=2/10 LR=0.00002 Time=0.679 Loss=1.177 Prec@1=70.974 Prec@5=90.004 rate=1.57 Hz, eta=0:00:00, total=0:02:04, wall=20:05 IST
[39m[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=20:05 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=20:05 IST
=> training   0.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=6.869 DataTime=4.897 Loss=0.726 Prec@1=82.812 Prec@5=94.922 rate=0 Hz, eta=?, total=0:00:00, wall=20:05 IST
=> training   0.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=6.869 DataTime=4.897 Loss=0.726 Prec@1=82.812 Prec@5=94.922 rate=7877.61 Hz, eta=0:00:00, total=0:00:00, wall=20:05 IST
=> training   0.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=6.869 DataTime=4.897 Loss=0.726 Prec@1=82.812 Prec@5=94.922 rate=7877.61 Hz, eta=0:00:00, total=0:00:00, wall=20:07 IST
=> training   0.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.190 DataTime=0.246 Loss=0.818 Prec@1=79.293 Prec@5=93.835 rate=7877.61 Hz, eta=0:00:00, total=0:00:00, wall=20:07 IST
=> training   2.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.190 DataTime=0.246 Loss=0.818 Prec@1=79.293 Prec@5=93.835 rate=0.89 Hz, eta=1:31:44, total=0:01:53, wall=20:07 IST
=> training   2.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.190 DataTime=0.246 Loss=0.818 Prec@1=79.293 Prec@5=93.835 rate=0.89 Hz, eta=1:31:44, total=0:01:53, wall=20:09 IST
=> training   2.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.159 DataTime=0.223 Loss=0.819 Prec@1=79.274 Prec@5=93.814 rate=0.89 Hz, eta=1:31:44, total=0:01:53, wall=20:09 IST
=> training   4.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.159 DataTime=0.223 Loss=0.819 Prec@1=79.274 Prec@5=93.814 rate=0.89 Hz, eta=1:30:02, total=0:03:46, wall=20:09 IST
=> training   4.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.159 DataTime=0.223 Loss=0.819 Prec@1=79.274 Prec@5=93.814 rate=0.89 Hz, eta=1:30:02, total=0:03:46, wall=20:11 IST
=> training   4.02% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.148 DataTime=0.215 Loss=0.815 Prec@1=79.353 Prec@5=93.790 rate=0.89 Hz, eta=1:30:02, total=0:03:46, wall=20:11 IST
=> training   6.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.148 DataTime=0.215 Loss=0.815 Prec@1=79.353 Prec@5=93.790 rate=0.89 Hz, eta=1:28:11, total=0:05:38, wall=20:11 IST
=> training   6.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.148 DataTime=0.215 Loss=0.815 Prec@1=79.353 Prec@5=93.790 rate=0.89 Hz, eta=1:28:11, total=0:05:38, wall=20:13 IST
=> training   6.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.142 DataTime=0.211 Loss=0.819 Prec@1=79.328 Prec@5=93.726 rate=0.89 Hz, eta=1:28:11, total=0:05:38, wall=20:13 IST
=> training   8.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.142 DataTime=0.211 Loss=0.819 Prec@1=79.328 Prec@5=93.726 rate=0.89 Hz, eta=1:26:17, total=0:07:30, wall=20:13 IST
=> training   8.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.142 DataTime=0.211 Loss=0.819 Prec@1=79.328 Prec@5=93.726 rate=0.89 Hz, eta=1:26:17, total=0:07:30, wall=20:15 IST
=> training   8.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.139 DataTime=0.209 Loss=0.818 Prec@1=79.382 Prec@5=93.775 rate=0.89 Hz, eta=1:26:17, total=0:07:30, wall=20:15 IST
=> training   10.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.139 DataTime=0.209 Loss=0.818 Prec@1=79.382 Prec@5=93.775 rate=0.89 Hz, eta=1:24:29, total=0:09:23, wall=20:15 IST
=> training   10.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.139 DataTime=0.209 Loss=0.818 Prec@1=79.382 Prec@5=93.775 rate=0.89 Hz, eta=1:24:29, total=0:09:23, wall=20:16 IST
=> training   10.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.207 Loss=0.819 Prec@1=79.305 Prec@5=93.762 rate=0.89 Hz, eta=1:24:29, total=0:09:23, wall=20:16 IST
=> training   12.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.207 Loss=0.819 Prec@1=79.305 Prec@5=93.762 rate=0.89 Hz, eta=1:22:37, total=0:11:16, wall=20:16 IST
=> training   12.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.207 Loss=0.819 Prec@1=79.305 Prec@5=93.762 rate=0.89 Hz, eta=1:22:37, total=0:11:16, wall=20:18 IST
=> training   12.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.206 Loss=0.820 Prec@1=79.243 Prec@5=93.767 rate=0.89 Hz, eta=1:22:37, total=0:11:16, wall=20:18 IST
=> training   14.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.206 Loss=0.820 Prec@1=79.243 Prec@5=93.767 rate=0.89 Hz, eta=1:20:50, total=0:13:10, wall=20:18 IST
=> training   14.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.206 Loss=0.820 Prec@1=79.243 Prec@5=93.767 rate=0.89 Hz, eta=1:20:50, total=0:13:10, wall=20:20 IST
=> training   14.01% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.205 Loss=0.821 Prec@1=79.227 Prec@5=93.760 rate=0.89 Hz, eta=1:20:50, total=0:13:10, wall=20:20 IST
=> training   16.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.205 Loss=0.821 Prec@1=79.227 Prec@5=93.760 rate=0.89 Hz, eta=1:18:58, total=0:15:02, wall=20:20 IST
=> training   16.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.205 Loss=0.821 Prec@1=79.227 Prec@5=93.760 rate=0.89 Hz, eta=1:18:58, total=0:15:02, wall=20:22 IST
=> training   16.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.204 Loss=0.821 Prec@1=79.181 Prec@5=93.757 rate=0.89 Hz, eta=1:18:58, total=0:15:02, wall=20:22 IST
=> training   18.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.204 Loss=0.821 Prec@1=79.181 Prec@5=93.757 rate=0.89 Hz, eta=1:17:13, total=0:16:57, wall=20:22 IST
=> training   18.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.137 DataTime=0.204 Loss=0.821 Prec@1=79.181 Prec@5=93.757 rate=0.89 Hz, eta=1:17:13, total=0:16:57, wall=20:24 IST
=> training   18.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.204 Loss=0.823 Prec@1=79.169 Prec@5=93.725 rate=0.89 Hz, eta=1:17:13, total=0:16:57, wall=20:24 IST
=> training   20.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.204 Loss=0.823 Prec@1=79.169 Prec@5=93.725 rate=0.89 Hz, eta=1:15:20, total=0:18:50, wall=20:24 IST
=> training   20.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.204 Loss=0.823 Prec@1=79.169 Prec@5=93.725 rate=0.89 Hz, eta=1:15:20, total=0:18:50, wall=20:26 IST
=> training   20.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.135 DataTime=0.203 Loss=0.823 Prec@1=79.134 Prec@5=93.729 rate=0.89 Hz, eta=1:15:20, total=0:18:50, wall=20:26 IST
=> training   22.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.135 DataTime=0.203 Loss=0.823 Prec@1=79.134 Prec@5=93.729 rate=0.89 Hz, eta=1:13:26, total=0:20:42, wall=20:26 IST
=> training   22.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.135 DataTime=0.203 Loss=0.823 Prec@1=79.134 Prec@5=93.729 rate=0.89 Hz, eta=1:13:26, total=0:20:42, wall=20:28 IST
=> training   22.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.203 Loss=0.824 Prec@1=79.123 Prec@5=93.712 rate=0.89 Hz, eta=1:13:26, total=0:20:42, wall=20:28 IST
=> training   24.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.203 Loss=0.824 Prec@1=79.123 Prec@5=93.712 rate=0.88 Hz, eta=1:11:39, total=0:22:37, wall=20:28 IST
=> training   24.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.136 DataTime=0.203 Loss=0.824 Prec@1=79.123 Prec@5=93.712 rate=0.88 Hz, eta=1:11:39, total=0:22:37, wall=20:30 IST
=> training   24.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.135 DataTime=0.203 Loss=0.824 Prec@1=79.103 Prec@5=93.703 rate=0.88 Hz, eta=1:11:39, total=0:22:37, wall=20:30 IST
=> training   25.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.135 DataTime=0.203 Loss=0.824 Prec@1=79.103 Prec@5=93.703 rate=0.89 Hz, eta=1:09:45, total=0:24:30, wall=20:30 IST
=> training   25.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.135 DataTime=0.203 Loss=0.824 Prec@1=79.103 Prec@5=93.703 rate=0.89 Hz, eta=1:09:45, total=0:24:30, wall=20:32 IST
=> training   25.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.134 DataTime=0.203 Loss=0.825 Prec@1=79.103 Prec@5=93.704 rate=0.89 Hz, eta=1:09:45, total=0:24:30, wall=20:32 IST
=> training   27.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.134 DataTime=0.203 Loss=0.825 Prec@1=79.103 Prec@5=93.704 rate=0.89 Hz, eta=1:07:50, total=0:26:22, wall=20:32 IST
=> training   27.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.134 DataTime=0.203 Loss=0.825 Prec@1=79.103 Prec@5=93.704 rate=0.89 Hz, eta=1:07:50, total=0:26:22, wall=20:33 IST
=> training   27.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.134 DataTime=0.202 Loss=0.824 Prec@1=79.110 Prec@5=93.702 rate=0.89 Hz, eta=1:07:50, total=0:26:22, wall=20:33 IST
=> training   29.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.134 DataTime=0.202 Loss=0.824 Prec@1=79.110 Prec@5=93.702 rate=0.89 Hz, eta=1:05:56, total=0:28:14, wall=20:33 IST
=> training   29.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.134 DataTime=0.202 Loss=0.824 Prec@1=79.110 Prec@5=93.702 rate=0.89 Hz, eta=1:05:56, total=0:28:14, wall=20:35 IST
=> training   29.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.133 DataTime=0.202 Loss=0.825 Prec@1=79.091 Prec@5=93.690 rate=0.89 Hz, eta=1:05:56, total=0:28:14, wall=20:35 IST
=> training   31.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.133 DataTime=0.202 Loss=0.825 Prec@1=79.091 Prec@5=93.690 rate=0.89 Hz, eta=1:04:02, total=0:30:07, wall=20:35 IST
=> training   31.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.133 DataTime=0.202 Loss=0.825 Prec@1=79.091 Prec@5=93.690 rate=0.89 Hz, eta=1:04:02, total=0:30:07, wall=20:37 IST
=> training   31.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.133 DataTime=0.202 Loss=0.825 Prec@1=79.093 Prec@5=93.684 rate=0.89 Hz, eta=1:04:02, total=0:30:07, wall=20:37 IST
=> training   33.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.133 DataTime=0.202 Loss=0.825 Prec@1=79.093 Prec@5=93.684 rate=0.89 Hz, eta=1:02:08, total=0:31:59, wall=20:37 IST
=> training   33.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.133 DataTime=0.202 Loss=0.825 Prec@1=79.093 Prec@5=93.684 rate=0.89 Hz, eta=1:02:08, total=0:31:59, wall=20:39 IST
=> training   33.99% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.132 DataTime=0.202 Loss=0.825 Prec@1=79.088 Prec@5=93.682 rate=0.89 Hz, eta=1:02:08, total=0:31:59, wall=20:39 IST
=> training   35.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.132 DataTime=0.202 Loss=0.825 Prec@1=79.088 Prec@5=93.682 rate=0.89 Hz, eta=1:00:15, total=0:33:52, wall=20:39 IST
=> training   35.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.132 DataTime=0.202 Loss=0.825 Prec@1=79.088 Prec@5=93.682 rate=0.89 Hz, eta=1:00:15, total=0:33:52, wall=20:41 IST
=> training   35.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.132 DataTime=0.202 Loss=0.825 Prec@1=79.086 Prec@5=93.676 rate=0.89 Hz, eta=1:00:15, total=0:33:52, wall=20:41 IST
=> training   37.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.132 DataTime=0.202 Loss=0.825 Prec@1=79.086 Prec@5=93.676 rate=0.89 Hz, eta=0:58:21, total=0:35:44, wall=20:41 IST
=> training   37.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.132 DataTime=0.202 Loss=0.825 Prec@1=79.086 Prec@5=93.676 rate=0.89 Hz, eta=0:58:21, total=0:35:44, wall=20:43 IST
=> training   37.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.104 Prec@5=93.679 rate=0.89 Hz, eta=0:58:21, total=0:35:44, wall=20:43 IST
=> training   39.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.104 Prec@5=93.679 rate=0.89 Hz, eta=0:56:28, total=0:37:36, wall=20:43 IST
=> training   39.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.104 Prec@5=93.679 rate=0.89 Hz, eta=0:56:28, total=0:37:36, wall=20:45 IST
=> training   39.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.098 Prec@5=93.680 rate=0.89 Hz, eta=0:56:28, total=0:37:36, wall=20:45 IST
=> training   41.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.098 Prec@5=93.680 rate=0.89 Hz, eta=0:54:34, total=0:39:29, wall=20:45 IST
=> training   41.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.098 Prec@5=93.680 rate=0.89 Hz, eta=0:54:34, total=0:39:29, wall=20:46 IST
=> training   41.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.103 Prec@5=93.680 rate=0.89 Hz, eta=0:54:34, total=0:39:29, wall=20:46 IST
=> training   43.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.103 Prec@5=93.680 rate=0.89 Hz, eta=0:52:41, total=0:41:21, wall=20:46 IST
=> training   43.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.131 DataTime=0.201 Loss=0.825 Prec@1=79.103 Prec@5=93.680 rate=0.89 Hz, eta=0:52:41, total=0:41:21, wall=20:48 IST
=> training   43.98% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.124 Prec@5=93.681 rate=0.89 Hz, eta=0:52:41, total=0:41:21, wall=20:48 IST
=> training   45.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.124 Prec@5=93.681 rate=0.89 Hz, eta=0:50:47, total=0:43:13, wall=20:48 IST
=> training   45.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.124 Prec@5=93.681 rate=0.89 Hz, eta=0:50:47, total=0:43:13, wall=20:50 IST
=> training   45.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.128 Prec@5=93.682 rate=0.89 Hz, eta=0:50:47, total=0:43:13, wall=20:50 IST
=> training   47.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.128 Prec@5=93.682 rate=0.89 Hz, eta=0:48:54, total=0:45:05, wall=20:50 IST
=> training   47.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.128 Prec@5=93.682 rate=0.89 Hz, eta=0:48:54, total=0:45:05, wall=20:52 IST
=> training   47.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.120 Prec@5=93.673 rate=0.89 Hz, eta=0:48:54, total=0:45:05, wall=20:52 IST
=> training   49.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.120 Prec@5=93.673 rate=0.89 Hz, eta=0:47:01, total=0:46:58, wall=20:52 IST
=> training   49.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.130 DataTime=0.201 Loss=0.824 Prec@1=79.120 Prec@5=93.673 rate=0.89 Hz, eta=0:47:01, total=0:46:58, wall=20:54 IST
=> training   49.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.113 Prec@5=93.665 rate=0.89 Hz, eta=0:47:01, total=0:46:58, wall=20:54 IST
=> training   51.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.113 Prec@5=93.665 rate=0.89 Hz, eta=0:45:08, total=0:48:50, wall=20:54 IST
=> training   51.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.113 Prec@5=93.665 rate=0.89 Hz, eta=0:45:08, total=0:48:50, wall=20:56 IST
=> training   51.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.109 Prec@5=93.664 rate=0.89 Hz, eta=0:45:08, total=0:48:50, wall=20:56 IST
=> training   53.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.109 Prec@5=93.664 rate=0.89 Hz, eta=0:43:15, total=0:50:42, wall=20:56 IST
=> training   53.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.109 Prec@5=93.664 rate=0.89 Hz, eta=0:43:15, total=0:50:42, wall=20:58 IST
=> training   53.97% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.099 Prec@5=93.668 rate=0.89 Hz, eta=0:43:15, total=0:50:42, wall=20:58 IST
=> training   55.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.099 Prec@5=93.668 rate=0.89 Hz, eta=0:41:22, total=0:52:34, wall=20:58 IST
=> training   55.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.099 Prec@5=93.668 rate=0.89 Hz, eta=0:41:22, total=0:52:34, wall=21:00 IST
=> training   55.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.098 Prec@5=93.676 rate=0.89 Hz, eta=0:41:22, total=0:52:34, wall=21:00 IST
=> training   57.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.098 Prec@5=93.676 rate=0.89 Hz, eta=0:39:29, total=0:54:27, wall=21:00 IST
=> training   57.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.129 DataTime=0.201 Loss=0.824 Prec@1=79.098 Prec@5=93.676 rate=0.89 Hz, eta=0:39:29, total=0:54:27, wall=21:01 IST
=> training   57.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.094 Prec@5=93.681 rate=0.89 Hz, eta=0:39:29, total=0:54:27, wall=21:01 IST
=> training   59.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.094 Prec@5=93.681 rate=0.89 Hz, eta=0:37:36, total=0:56:19, wall=21:01 IST
=> training   59.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.094 Prec@5=93.681 rate=0.89 Hz, eta=0:37:36, total=0:56:19, wall=21:03 IST
=> training   59.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.084 Prec@5=93.668 rate=0.89 Hz, eta=0:37:36, total=0:56:19, wall=21:03 IST
=> training   61.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.084 Prec@5=93.668 rate=0.89 Hz, eta=0:35:43, total=0:58:11, wall=21:03 IST
=> training   61.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.084 Prec@5=93.668 rate=0.89 Hz, eta=0:35:43, total=0:58:11, wall=21:05 IST
=> training   61.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.088 Prec@5=93.670 rate=0.89 Hz, eta=0:35:43, total=0:58:11, wall=21:05 IST
=> training   63.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.088 Prec@5=93.670 rate=0.89 Hz, eta=0:33:51, total=1:00:04, wall=21:05 IST
=> training   63.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.088 Prec@5=93.670 rate=0.89 Hz, eta=0:33:51, total=1:00:04, wall=21:07 IST
=> training   63.96% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.095 Prec@5=93.669 rate=0.89 Hz, eta=0:33:51, total=1:00:04, wall=21:07 IST
=> training   65.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.095 Prec@5=93.669 rate=0.89 Hz, eta=0:31:58, total=1:01:56, wall=21:07 IST
=> training   65.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.095 Prec@5=93.669 rate=0.89 Hz, eta=0:31:58, total=1:01:56, wall=21:09 IST
=> training   65.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.079 Prec@5=93.670 rate=0.89 Hz, eta=0:31:58, total=1:01:56, wall=21:09 IST
=> training   67.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.079 Prec@5=93.670 rate=0.89 Hz, eta=0:30:05, total=1:03:48, wall=21:09 IST
=> training   67.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.079 Prec@5=93.670 rate=0.89 Hz, eta=0:30:05, total=1:03:48, wall=21:11 IST
=> training   67.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.200 Loss=0.825 Prec@1=79.081 Prec@5=93.672 rate=0.89 Hz, eta=0:30:05, total=1:03:48, wall=21:11 IST
=> training   69.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.200 Loss=0.825 Prec@1=79.081 Prec@5=93.672 rate=0.89 Hz, eta=0:28:12, total=1:05:40, wall=21:11 IST
=> training   69.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.128 DataTime=0.200 Loss=0.825 Prec@1=79.081 Prec@5=93.672 rate=0.89 Hz, eta=0:28:12, total=1:05:40, wall=21:13 IST
=> training   69.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.080 Prec@5=93.674 rate=0.89 Hz, eta=0:28:12, total=1:05:40, wall=21:13 IST
=> training   71.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.080 Prec@5=93.674 rate=0.89 Hz, eta=0:26:20, total=1:07:32, wall=21:13 IST
=> training   71.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.080 Prec@5=93.674 rate=0.89 Hz, eta=0:26:20, total=1:07:32, wall=21:15 IST
=> training   71.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.084 Prec@5=93.676 rate=0.89 Hz, eta=0:26:20, total=1:07:32, wall=21:15 IST
=> training   73.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.084 Prec@5=93.676 rate=0.89 Hz, eta=0:24:27, total=1:09:25, wall=21:15 IST
=> training   73.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.084 Prec@5=93.676 rate=0.89 Hz, eta=0:24:27, total=1:09:25, wall=21:16 IST
=> training   73.95% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.092 Prec@5=93.678 rate=0.89 Hz, eta=0:24:27, total=1:09:25, wall=21:16 IST
=> training   75.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.092 Prec@5=93.678 rate=0.89 Hz, eta=0:22:35, total=1:11:17, wall=21:16 IST
=> training   75.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.092 Prec@5=93.678 rate=0.89 Hz, eta=0:22:35, total=1:11:17, wall=21:18 IST
=> training   75.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.102 Prec@5=93.679 rate=0.89 Hz, eta=0:22:35, total=1:11:17, wall=21:18 IST
=> training   77.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.102 Prec@5=93.679 rate=0.89 Hz, eta=0:20:42, total=1:13:10, wall=21:18 IST
=> training   77.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.102 Prec@5=93.679 rate=0.89 Hz, eta=0:20:42, total=1:13:10, wall=21:20 IST
=> training   77.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.096 Prec@5=93.674 rate=0.89 Hz, eta=0:20:42, total=1:13:10, wall=21:20 IST
=> training   79.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.096 Prec@5=93.674 rate=0.89 Hz, eta=0:18:49, total=1:15:02, wall=21:20 IST
=> training   79.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.096 Prec@5=93.674 rate=0.89 Hz, eta=0:18:49, total=1:15:02, wall=21:22 IST
=> training   79.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.099 Prec@5=93.673 rate=0.89 Hz, eta=0:18:49, total=1:15:02, wall=21:22 IST
=> training   81.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.099 Prec@5=93.673 rate=0.89 Hz, eta=0:16:57, total=1:16:55, wall=21:22 IST
=> training   81.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.099 Prec@5=93.673 rate=0.89 Hz, eta=0:16:57, total=1:16:55, wall=21:24 IST
=> training   81.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.101 Prec@5=93.674 rate=0.89 Hz, eta=0:16:57, total=1:16:55, wall=21:24 IST
=> training   83.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.101 Prec@5=93.674 rate=0.89 Hz, eta=0:15:04, total=1:18:47, wall=21:24 IST
=> training   83.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.101 Prec@5=93.674 rate=0.89 Hz, eta=0:15:04, total=1:18:47, wall=21:26 IST
=> training   83.94% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.670 rate=0.89 Hz, eta=0:15:04, total=1:18:47, wall=21:26 IST
=> training   85.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.670 rate=0.89 Hz, eta=0:13:12, total=1:20:39, wall=21:26 IST
=> training   85.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.670 rate=0.89 Hz, eta=0:13:12, total=1:20:39, wall=21:28 IST
=> training   85.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.100 Prec@5=93.668 rate=0.89 Hz, eta=0:13:12, total=1:20:39, wall=21:28 IST
=> training   87.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.100 Prec@5=93.668 rate=0.89 Hz, eta=0:11:19, total=1:22:32, wall=21:28 IST
=> training   87.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.824 Prec@1=79.100 Prec@5=93.668 rate=0.89 Hz, eta=0:11:19, total=1:22:32, wall=21:30 IST
=> training   87.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.664 rate=0.89 Hz, eta=0:11:19, total=1:22:32, wall=21:30 IST
=> training   89.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.664 rate=0.89 Hz, eta=0:09:27, total=1:24:24, wall=21:30 IST
=> training   89.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.664 rate=0.89 Hz, eta=0:09:27, total=1:24:24, wall=21:31 IST
=> training   89.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.102 Prec@5=93.662 rate=0.89 Hz, eta=0:09:27, total=1:24:24, wall=21:31 IST
=> training   91.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.102 Prec@5=93.662 rate=0.89 Hz, eta=0:07:34, total=1:26:17, wall=21:31 IST
=> training   91.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.102 Prec@5=93.662 rate=0.89 Hz, eta=0:07:34, total=1:26:17, wall=21:33 IST
=> training   91.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.103 Prec@5=93.662 rate=0.89 Hz, eta=0:07:34, total=1:26:17, wall=21:33 IST
=> training   93.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.103 Prec@5=93.662 rate=0.89 Hz, eta=0:05:42, total=1:28:09, wall=21:33 IST
=> training   93.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.103 Prec@5=93.662 rate=0.89 Hz, eta=0:05:42, total=1:28:09, wall=21:35 IST
=> training   93.93% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.661 rate=0.89 Hz, eta=0:05:42, total=1:28:09, wall=21:35 IST
=> training   95.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.661 rate=0.89 Hz, eta=0:03:49, total=1:30:02, wall=21:35 IST
=> training   95.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.661 rate=0.89 Hz, eta=0:03:49, total=1:30:02, wall=21:37 IST
=> training   95.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.086 Prec@5=93.658 rate=0.89 Hz, eta=0:03:49, total=1:30:02, wall=21:37 IST
=> training   97.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.086 Prec@5=93.658 rate=0.89 Hz, eta=0:01:57, total=1:31:54, wall=21:37 IST
=> training   97.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.086 Prec@5=93.658 rate=0.89 Hz, eta=0:01:57, total=1:31:54, wall=21:39 IST
=> training   97.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.126 DataTime=0.200 Loss=0.825 Prec@1=79.084 Prec@5=93.653 rate=0.89 Hz, eta=0:01:57, total=1:31:54, wall=21:39 IST
=> training   99.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.126 DataTime=0.200 Loss=0.825 Prec@1=79.084 Prec@5=93.653 rate=0.89 Hz, eta=0:00:04, total=1:33:45, wall=21:39 IST
=> training   99.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.126 DataTime=0.200 Loss=0.825 Prec@1=79.084 Prec@5=93.653 rate=0.89 Hz, eta=0:00:04, total=1:33:45, wall=21:39 IST
=> training   99.92% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.126 DataTime=0.200 Loss=0.825 Prec@1=79.084 Prec@5=93.653 rate=0.89 Hz, eta=0:00:04, total=1:33:45, wall=21:39 IST
=> training   100.00% of 1x5005...Epoch=3/10 LR=0.00004 Time=1.126 DataTime=0.200 Loss=0.825 Prec@1=79.084 Prec@5=93.653 rate=0.89 Hz, eta=0:00:00, total=1:33:49, wall=21:39 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 4.000 4.000 8.000 2.000 4.000 8.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 4.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=21:39 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=21:39 IST
=> validation 0.00% of 1x196...Epoch=3/10 LR=0.00004 Time=8.324 Loss=1.225 Prec@1=71.094 Prec@5=87.891 rate=0 Hz, eta=?, total=0:00:00, wall=21:39 IST
=> validation 0.51% of 1x196...Epoch=3/10 LR=0.00004 Time=8.324 Loss=1.225 Prec@1=71.094 Prec@5=87.891 rate=2731.88 Hz, eta=0:00:00, total=0:00:00, wall=21:39 IST
=> validation 0.51% of 1x196...Epoch=3/10 LR=0.00004 Time=8.324 Loss=1.225 Prec@1=71.094 Prec@5=87.891 rate=2731.88 Hz, eta=0:00:00, total=0:00:00, wall=21:40 IST
=> validation 0.51% of 1x196...Epoch=3/10 LR=0.00004 Time=0.715 Loss=1.175 Prec@1=71.291 Prec@5=89.948 rate=2731.88 Hz, eta=0:00:00, total=0:00:00, wall=21:40 IST
=> validation 51.53% of 1x196...Epoch=3/10 LR=0.00004 Time=0.715 Loss=1.175 Prec@1=71.291 Prec@5=89.948 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=21:40 IST
** validation 51.53% of 1x196...Epoch=3/10 LR=0.00004 Time=0.715 Loss=1.175 Prec@1=71.291 Prec@5=89.948 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=21:41 IST
** validation 51.53% of 1x196...Epoch=3/10 LR=0.00004 Time=0.653 Loss=1.172 Prec@1=71.036 Prec@5=90.018 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=21:41 IST
** validation 100.00% of 1x196...Epoch=3/10 LR=0.00004 Time=0.653 Loss=1.172 Prec@1=71.036 Prec@5=90.018 rate=1.64 Hz, eta=0:00:00, total=0:01:59, wall=21:41 IST
[39m[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=21:41 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=21:41 IST
=> training   0.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=7.057 DataTime=5.179 Loss=0.883 Prec@1=75.781 Prec@5=93.359 rate=0 Hz, eta=?, total=0:00:00, wall=21:41 IST
=> training   0.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=7.057 DataTime=5.179 Loss=0.883 Prec@1=75.781 Prec@5=93.359 rate=2915.00 Hz, eta=0:00:01, total=0:00:00, wall=21:41 IST
=> training   0.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=7.057 DataTime=5.179 Loss=0.883 Prec@1=75.781 Prec@5=93.359 rate=2915.00 Hz, eta=0:00:01, total=0:00:00, wall=21:43 IST
=> training   0.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.192 DataTime=0.248 Loss=0.819 Prec@1=79.134 Prec@5=93.653 rate=2915.00 Hz, eta=0:00:01, total=0:00:00, wall=21:43 IST
=> training   2.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.192 DataTime=0.248 Loss=0.819 Prec@1=79.134 Prec@5=93.653 rate=0.89 Hz, eta=1:31:43, total=0:01:53, wall=21:43 IST
=> training   2.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.192 DataTime=0.248 Loss=0.819 Prec@1=79.134 Prec@5=93.653 rate=0.89 Hz, eta=1:31:43, total=0:01:53, wall=21:45 IST
=> training   2.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.175 DataTime=0.224 Loss=0.811 Prec@1=79.336 Prec@5=93.837 rate=0.89 Hz, eta=1:31:43, total=0:01:53, wall=21:45 IST
=> training   4.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.175 DataTime=0.224 Loss=0.811 Prec@1=79.336 Prec@5=93.837 rate=0.88 Hz, eta=1:31:17, total=0:03:49, wall=21:45 IST
=> training   4.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.175 DataTime=0.224 Loss=0.811 Prec@1=79.336 Prec@5=93.837 rate=0.88 Hz, eta=1:31:17, total=0:03:49, wall=21:47 IST
=> training   4.02% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.159 DataTime=0.216 Loss=0.815 Prec@1=79.257 Prec@5=93.769 rate=0.88 Hz, eta=1:31:17, total=0:03:49, wall=21:47 IST
=> training   6.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.159 DataTime=0.216 Loss=0.815 Prec@1=79.257 Prec@5=93.769 rate=0.88 Hz, eta=1:29:03, total=0:05:41, wall=21:47 IST
=> training   6.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.159 DataTime=0.216 Loss=0.815 Prec@1=79.257 Prec@5=93.769 rate=0.88 Hz, eta=1:29:03, total=0:05:41, wall=21:49 IST
=> training   6.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.151 DataTime=0.211 Loss=0.819 Prec@1=79.206 Prec@5=93.757 rate=0.88 Hz, eta=1:29:03, total=0:05:41, wall=21:49 IST
=> training   8.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.151 DataTime=0.211 Loss=0.819 Prec@1=79.206 Prec@5=93.757 rate=0.88 Hz, eta=1:27:00, total=0:07:34, wall=21:49 IST
=> training   8.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.151 DataTime=0.211 Loss=0.819 Prec@1=79.206 Prec@5=93.757 rate=0.88 Hz, eta=1:27:00, total=0:07:34, wall=21:51 IST
=> training   8.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.153 DataTime=0.209 Loss=0.821 Prec@1=79.168 Prec@5=93.748 rate=0.88 Hz, eta=1:27:00, total=0:07:34, wall=21:51 IST
=> training   10.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.153 DataTime=0.209 Loss=0.821 Prec@1=79.168 Prec@5=93.748 rate=0.88 Hz, eta=1:25:29, total=0:09:30, wall=21:51 IST
=> training   10.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.153 DataTime=0.209 Loss=0.821 Prec@1=79.168 Prec@5=93.748 rate=0.88 Hz, eta=1:25:29, total=0:09:30, wall=21:53 IST
=> training   10.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.148 DataTime=0.207 Loss=0.819 Prec@1=79.200 Prec@5=93.777 rate=0.88 Hz, eta=1:25:29, total=0:09:30, wall=21:53 IST
=> training   12.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.148 DataTime=0.207 Loss=0.819 Prec@1=79.200 Prec@5=93.777 rate=0.88 Hz, eta=1:23:24, total=0:11:22, wall=21:53 IST
=> training   12.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.148 DataTime=0.207 Loss=0.819 Prec@1=79.200 Prec@5=93.777 rate=0.88 Hz, eta=1:23:24, total=0:11:22, wall=21:55 IST
=> training   12.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.145 DataTime=0.206 Loss=0.819 Prec@1=79.209 Prec@5=93.767 rate=0.88 Hz, eta=1:23:24, total=0:11:22, wall=21:55 IST
=> training   14.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.145 DataTime=0.206 Loss=0.819 Prec@1=79.209 Prec@5=93.767 rate=0.88 Hz, eta=1:21:23, total=0:13:15, wall=21:55 IST
=> training   14.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.145 DataTime=0.206 Loss=0.819 Prec@1=79.209 Prec@5=93.767 rate=0.88 Hz, eta=1:21:23, total=0:13:15, wall=21:56 IST
=> training   14.01% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.142 DataTime=0.205 Loss=0.818 Prec@1=79.273 Prec@5=93.738 rate=0.88 Hz, eta=1:21:23, total=0:13:15, wall=21:56 IST
=> training   16.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.142 DataTime=0.205 Loss=0.818 Prec@1=79.273 Prec@5=93.738 rate=0.88 Hz, eta=1:19:25, total=0:15:08, wall=21:56 IST
=> training   16.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.142 DataTime=0.205 Loss=0.818 Prec@1=79.273 Prec@5=93.738 rate=0.88 Hz, eta=1:19:25, total=0:15:08, wall=21:58 IST
=> training   16.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.141 DataTime=0.205 Loss=0.819 Prec@1=79.216 Prec@5=93.721 rate=0.88 Hz, eta=1:19:25, total=0:15:08, wall=21:58 IST
=> training   18.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.141 DataTime=0.205 Loss=0.819 Prec@1=79.216 Prec@5=93.721 rate=0.88 Hz, eta=1:17:29, total=0:17:00, wall=21:58 IST
=> training   18.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.141 DataTime=0.205 Loss=0.819 Prec@1=79.216 Prec@5=93.721 rate=0.88 Hz, eta=1:17:29, total=0:17:00, wall=22:00 IST
=> training   18.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.139 DataTime=0.204 Loss=0.821 Prec@1=79.169 Prec@5=93.709 rate=0.88 Hz, eta=1:17:29, total=0:17:00, wall=22:00 IST
=> training   20.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.139 DataTime=0.204 Loss=0.821 Prec@1=79.169 Prec@5=93.709 rate=0.88 Hz, eta=1:15:33, total=0:18:53, wall=22:00 IST
=> training   20.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.139 DataTime=0.204 Loss=0.821 Prec@1=79.169 Prec@5=93.709 rate=0.88 Hz, eta=1:15:33, total=0:18:53, wall=22:02 IST
=> training   20.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.138 DataTime=0.204 Loss=0.820 Prec@1=79.193 Prec@5=93.713 rate=0.88 Hz, eta=1:15:33, total=0:18:53, wall=22:02 IST
=> training   22.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.138 DataTime=0.204 Loss=0.820 Prec@1=79.193 Prec@5=93.713 rate=0.88 Hz, eta=1:13:37, total=0:20:45, wall=22:02 IST
=> training   22.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.138 DataTime=0.204 Loss=0.820 Prec@1=79.193 Prec@5=93.713 rate=0.88 Hz, eta=1:13:37, total=0:20:45, wall=22:04 IST
=> training   22.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.136 DataTime=0.203 Loss=0.821 Prec@1=79.150 Prec@5=93.706 rate=0.88 Hz, eta=1:13:37, total=0:20:45, wall=22:04 IST
=> training   24.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.136 DataTime=0.203 Loss=0.821 Prec@1=79.150 Prec@5=93.706 rate=0.88 Hz, eta=1:11:40, total=0:22:37, wall=22:04 IST
=> training   24.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.136 DataTime=0.203 Loss=0.821 Prec@1=79.150 Prec@5=93.706 rate=0.88 Hz, eta=1:11:40, total=0:22:37, wall=22:06 IST
=> training   24.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.135 DataTime=0.203 Loss=0.822 Prec@1=79.158 Prec@5=93.710 rate=0.88 Hz, eta=1:11:40, total=0:22:37, wall=22:06 IST
=> training   25.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.135 DataTime=0.203 Loss=0.822 Prec@1=79.158 Prec@5=93.710 rate=0.89 Hz, eta=1:09:45, total=0:24:30, wall=22:06 IST
=> training   25.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.135 DataTime=0.203 Loss=0.822 Prec@1=79.158 Prec@5=93.710 rate=0.89 Hz, eta=1:09:45, total=0:24:30, wall=22:08 IST
=> training   25.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.134 DataTime=0.203 Loss=0.822 Prec@1=79.135 Prec@5=93.707 rate=0.89 Hz, eta=1:09:45, total=0:24:30, wall=22:08 IST
=> training   27.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.134 DataTime=0.203 Loss=0.822 Prec@1=79.135 Prec@5=93.707 rate=0.89 Hz, eta=1:07:50, total=0:26:22, wall=22:08 IST
=> training   27.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.134 DataTime=0.203 Loss=0.822 Prec@1=79.135 Prec@5=93.707 rate=0.89 Hz, eta=1:07:50, total=0:26:22, wall=22:10 IST
=> training   27.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.134 DataTime=0.202 Loss=0.821 Prec@1=79.172 Prec@5=93.722 rate=0.89 Hz, eta=1:07:50, total=0:26:22, wall=22:10 IST
=> training   29.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.134 DataTime=0.202 Loss=0.821 Prec@1=79.172 Prec@5=93.722 rate=0.89 Hz, eta=1:05:56, total=0:28:14, wall=22:10 IST
=> training   29.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.134 DataTime=0.202 Loss=0.821 Prec@1=79.172 Prec@5=93.722 rate=0.89 Hz, eta=1:05:56, total=0:28:14, wall=22:11 IST
=> training   29.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.133 DataTime=0.202 Loss=0.823 Prec@1=79.149 Prec@5=93.703 rate=0.89 Hz, eta=1:05:56, total=0:28:14, wall=22:11 IST
=> training   31.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.133 DataTime=0.202 Loss=0.823 Prec@1=79.149 Prec@5=93.703 rate=0.89 Hz, eta=1:04:01, total=0:30:06, wall=22:11 IST
=> training   31.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.133 DataTime=0.202 Loss=0.823 Prec@1=79.149 Prec@5=93.703 rate=0.89 Hz, eta=1:04:01, total=0:30:06, wall=22:13 IST
=> training   31.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.132 DataTime=0.202 Loss=0.822 Prec@1=79.148 Prec@5=93.712 rate=0.89 Hz, eta=1:04:01, total=0:30:06, wall=22:13 IST
=> training   33.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.132 DataTime=0.202 Loss=0.822 Prec@1=79.148 Prec@5=93.712 rate=0.89 Hz, eta=1:02:07, total=0:31:59, wall=22:13 IST
=> training   33.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.132 DataTime=0.202 Loss=0.822 Prec@1=79.148 Prec@5=93.712 rate=0.89 Hz, eta=1:02:07, total=0:31:59, wall=22:15 IST
=> training   33.99% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.132 DataTime=0.202 Loss=0.822 Prec@1=79.130 Prec@5=93.706 rate=0.89 Hz, eta=1:02:07, total=0:31:59, wall=22:15 IST
=> training   35.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.132 DataTime=0.202 Loss=0.822 Prec@1=79.130 Prec@5=93.706 rate=0.89 Hz, eta=1:00:13, total=0:33:51, wall=22:15 IST
=> training   35.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.132 DataTime=0.202 Loss=0.822 Prec@1=79.130 Prec@5=93.706 rate=0.89 Hz, eta=1:00:13, total=0:33:51, wall=22:17 IST
=> training   35.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.822 Prec@1=79.139 Prec@5=93.701 rate=0.89 Hz, eta=1:00:13, total=0:33:51, wall=22:17 IST
=> training   37.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.822 Prec@1=79.139 Prec@5=93.701 rate=0.89 Hz, eta=0:58:20, total=0:35:43, wall=22:17 IST
=> training   37.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.822 Prec@1=79.139 Prec@5=93.701 rate=0.89 Hz, eta=0:58:20, total=0:35:43, wall=22:19 IST
=> training   37.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.823 Prec@1=79.133 Prec@5=93.693 rate=0.89 Hz, eta=0:58:20, total=0:35:43, wall=22:19 IST
=> training   39.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.823 Prec@1=79.133 Prec@5=93.693 rate=0.89 Hz, eta=0:56:26, total=0:37:35, wall=22:19 IST
=> training   39.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.823 Prec@1=79.133 Prec@5=93.693 rate=0.89 Hz, eta=0:56:26, total=0:37:35, wall=22:21 IST
=> training   39.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.822 Prec@1=79.148 Prec@5=93.702 rate=0.89 Hz, eta=0:56:26, total=0:37:35, wall=22:21 IST
=> training   41.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.822 Prec@1=79.148 Prec@5=93.702 rate=0.89 Hz, eta=0:54:33, total=0:39:28, wall=22:21 IST
=> training   41.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.131 DataTime=0.202 Loss=0.822 Prec@1=79.148 Prec@5=93.702 rate=0.89 Hz, eta=0:54:33, total=0:39:28, wall=22:23 IST
=> training   41.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.821 Prec@1=79.156 Prec@5=93.706 rate=0.89 Hz, eta=0:54:33, total=0:39:28, wall=22:23 IST
=> training   43.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.821 Prec@1=79.156 Prec@5=93.706 rate=0.89 Hz, eta=0:52:40, total=0:41:20, wall=22:23 IST
=> training   43.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.821 Prec@1=79.156 Prec@5=93.706 rate=0.89 Hz, eta=0:52:40, total=0:41:20, wall=22:25 IST
=> training   43.98% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.822 Prec@1=79.148 Prec@5=93.708 rate=0.89 Hz, eta=0:52:40, total=0:41:20, wall=22:25 IST
=> training   45.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.822 Prec@1=79.148 Prec@5=93.708 rate=0.89 Hz, eta=0:50:47, total=0:43:13, wall=22:25 IST
=> training   45.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.822 Prec@1=79.148 Prec@5=93.708 rate=0.89 Hz, eta=0:50:47, total=0:43:13, wall=22:26 IST
=> training   45.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.822 Prec@1=79.154 Prec@5=93.697 rate=0.89 Hz, eta=0:50:47, total=0:43:13, wall=22:26 IST
=> training   47.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.822 Prec@1=79.154 Prec@5=93.697 rate=0.89 Hz, eta=0:48:54, total=0:45:05, wall=22:26 IST
=> training   47.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.130 DataTime=0.201 Loss=0.822 Prec@1=79.154 Prec@5=93.697 rate=0.89 Hz, eta=0:48:54, total=0:45:05, wall=22:28 IST
=> training   47.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.155 Prec@5=93.698 rate=0.89 Hz, eta=0:48:54, total=0:45:05, wall=22:28 IST
=> training   49.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.155 Prec@5=93.698 rate=0.89 Hz, eta=0:47:00, total=0:46:57, wall=22:28 IST
=> training   49.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.155 Prec@5=93.698 rate=0.89 Hz, eta=0:47:00, total=0:46:57, wall=22:30 IST
=> training   49.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.161 Prec@5=93.692 rate=0.89 Hz, eta=0:47:00, total=0:46:57, wall=22:30 IST
=> training   51.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.161 Prec@5=93.692 rate=0.89 Hz, eta=0:45:08, total=0:48:49, wall=22:30 IST
=> training   51.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.161 Prec@5=93.692 rate=0.89 Hz, eta=0:45:08, total=0:48:49, wall=22:32 IST
=> training   51.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.153 Prec@5=93.694 rate=0.89 Hz, eta=0:45:08, total=0:48:49, wall=22:32 IST
=> training   53.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.153 Prec@5=93.694 rate=0.89 Hz, eta=0:43:15, total=0:50:42, wall=22:32 IST
=> training   53.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.153 Prec@5=93.694 rate=0.89 Hz, eta=0:43:15, total=0:50:42, wall=22:34 IST
=> training   53.97% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.150 Prec@5=93.688 rate=0.89 Hz, eta=0:43:15, total=0:50:42, wall=22:34 IST
=> training   55.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.150 Prec@5=93.688 rate=0.89 Hz, eta=0:41:22, total=0:52:34, wall=22:34 IST
=> training   55.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.150 Prec@5=93.688 rate=0.89 Hz, eta=0:41:22, total=0:52:34, wall=22:36 IST
=> training   55.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.150 Prec@5=93.690 rate=0.89 Hz, eta=0:41:22, total=0:52:34, wall=22:36 IST
=> training   57.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.150 Prec@5=93.690 rate=0.89 Hz, eta=0:39:29, total=0:54:27, wall=22:36 IST
=> training   57.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.129 DataTime=0.201 Loss=0.822 Prec@1=79.150 Prec@5=93.690 rate=0.89 Hz, eta=0:39:29, total=0:54:27, wall=22:38 IST
=> training   57.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.823 Prec@1=79.145 Prec@5=93.680 rate=0.89 Hz, eta=0:39:29, total=0:54:27, wall=22:38 IST
=> training   59.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.823 Prec@1=79.145 Prec@5=93.680 rate=0.89 Hz, eta=0:37:36, total=0:56:19, wall=22:38 IST
=> training   59.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.823 Prec@1=79.145 Prec@5=93.680 rate=0.89 Hz, eta=0:37:36, total=0:56:19, wall=22:39 IST
=> training   59.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.823 Prec@1=79.127 Prec@5=93.673 rate=0.89 Hz, eta=0:37:36, total=0:56:19, wall=22:39 IST
=> training   61.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.823 Prec@1=79.127 Prec@5=93.673 rate=0.89 Hz, eta=0:35:43, total=0:58:11, wall=22:39 IST
=> training   61.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.823 Prec@1=79.127 Prec@5=93.673 rate=0.89 Hz, eta=0:35:43, total=0:58:11, wall=22:41 IST
=> training   61.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.117 Prec@5=93.669 rate=0.89 Hz, eta=0:35:43, total=0:58:11, wall=22:41 IST
=> training   63.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.117 Prec@5=93.669 rate=0.89 Hz, eta=0:33:51, total=1:00:04, wall=22:41 IST
=> training   63.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.117 Prec@5=93.669 rate=0.89 Hz, eta=0:33:51, total=1:00:04, wall=22:43 IST
=> training   63.96% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.107 Prec@5=93.660 rate=0.89 Hz, eta=0:33:51, total=1:00:04, wall=22:43 IST
=> training   65.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.107 Prec@5=93.660 rate=0.89 Hz, eta=0:31:58, total=1:01:56, wall=22:43 IST
=> training   65.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.824 Prec@1=79.107 Prec@5=93.660 rate=0.89 Hz, eta=0:31:58, total=1:01:56, wall=22:45 IST
=> training   65.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.098 Prec@5=93.647 rate=0.89 Hz, eta=0:31:58, total=1:01:56, wall=22:45 IST
=> training   67.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.098 Prec@5=93.647 rate=0.89 Hz, eta=0:30:05, total=1:03:48, wall=22:45 IST
=> training   67.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.098 Prec@5=93.647 rate=0.89 Hz, eta=0:30:05, total=1:03:48, wall=22:47 IST
=> training   67.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.093 Prec@5=93.649 rate=0.89 Hz, eta=0:30:05, total=1:03:48, wall=22:47 IST
=> training   69.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.093 Prec@5=93.649 rate=0.89 Hz, eta=0:28:13, total=1:05:41, wall=22:47 IST
=> training   69.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.093 Prec@5=93.649 rate=0.89 Hz, eta=0:28:13, total=1:05:41, wall=22:49 IST
=> training   69.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.099 Prec@5=93.653 rate=0.89 Hz, eta=0:28:13, total=1:05:41, wall=22:49 IST
=> training   71.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.099 Prec@5=93.653 rate=0.89 Hz, eta=0:26:20, total=1:07:33, wall=22:49 IST
=> training   71.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.201 Loss=0.825 Prec@1=79.099 Prec@5=93.653 rate=0.89 Hz, eta=0:26:20, total=1:07:33, wall=22:51 IST
=> training   71.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.200 Loss=0.826 Prec@1=79.093 Prec@5=93.650 rate=0.89 Hz, eta=0:26:20, total=1:07:33, wall=22:51 IST
=> training   73.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.200 Loss=0.826 Prec@1=79.093 Prec@5=93.650 rate=0.89 Hz, eta=0:24:27, total=1:09:26, wall=22:51 IST
=> training   73.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.128 DataTime=0.200 Loss=0.826 Prec@1=79.093 Prec@5=93.650 rate=0.89 Hz, eta=0:24:27, total=1:09:26, wall=22:53 IST
=> training   73.95% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.652 rate=0.89 Hz, eta=0:24:27, total=1:09:26, wall=22:53 IST
=> training   75.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.652 rate=0.89 Hz, eta=0:22:35, total=1:11:18, wall=22:53 IST
=> training   75.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.825 Prec@1=79.097 Prec@5=93.652 rate=0.89 Hz, eta=0:22:35, total=1:11:18, wall=22:54 IST
=> training   75.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.100 Prec@5=93.642 rate=0.89 Hz, eta=0:22:35, total=1:11:18, wall=22:54 IST
=> training   77.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.100 Prec@5=93.642 rate=0.89 Hz, eta=0:20:42, total=1:13:10, wall=22:54 IST
=> training   77.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.100 Prec@5=93.642 rate=0.89 Hz, eta=0:20:42, total=1:13:10, wall=22:56 IST
=> training   77.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.084 Prec@5=93.637 rate=0.89 Hz, eta=0:20:42, total=1:13:10, wall=22:56 IST
=> training   79.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.084 Prec@5=93.637 rate=0.89 Hz, eta=0:18:50, total=1:15:03, wall=22:56 IST
=> training   79.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.084 Prec@5=93.637 rate=0.89 Hz, eta=0:18:50, total=1:15:03, wall=22:58 IST
=> training   79.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.071 Prec@5=93.634 rate=0.89 Hz, eta=0:18:50, total=1:15:03, wall=22:58 IST
=> training   81.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.071 Prec@5=93.634 rate=0.89 Hz, eta=0:16:57, total=1:16:55, wall=22:58 IST
=> training   81.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.071 Prec@5=93.634 rate=0.89 Hz, eta=0:16:57, total=1:16:55, wall=23:00 IST
=> training   81.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.072 Prec@5=93.638 rate=0.89 Hz, eta=0:16:57, total=1:16:55, wall=23:00 IST
=> training   83.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.072 Prec@5=93.638 rate=0.89 Hz, eta=0:15:04, total=1:18:48, wall=23:00 IST
=> training   83.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.072 Prec@5=93.638 rate=0.89 Hz, eta=0:15:04, total=1:18:48, wall=23:02 IST
=> training   83.94% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.074 Prec@5=93.638 rate=0.89 Hz, eta=0:15:04, total=1:18:48, wall=23:02 IST
=> training   85.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.074 Prec@5=93.638 rate=0.89 Hz, eta=0:13:12, total=1:20:41, wall=23:02 IST
=> training   85.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.074 Prec@5=93.638 rate=0.89 Hz, eta=0:13:12, total=1:20:41, wall=23:04 IST
=> training   85.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.076 Prec@5=93.639 rate=0.89 Hz, eta=0:13:12, total=1:20:41, wall=23:04 IST
=> training   87.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.076 Prec@5=93.639 rate=0.89 Hz, eta=0:11:19, total=1:22:33, wall=23:04 IST
=> training   87.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.076 Prec@5=93.639 rate=0.89 Hz, eta=0:11:19, total=1:22:33, wall=23:06 IST
=> training   87.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.078 Prec@5=93.641 rate=0.89 Hz, eta=0:11:19, total=1:22:33, wall=23:06 IST
=> training   89.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.078 Prec@5=93.641 rate=0.89 Hz, eta=0:09:27, total=1:24:25, wall=23:06 IST
=> training   89.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.078 Prec@5=93.641 rate=0.89 Hz, eta=0:09:27, total=1:24:25, wall=23:08 IST
=> training   89.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.071 Prec@5=93.641 rate=0.89 Hz, eta=0:09:27, total=1:24:25, wall=23:08 IST
=> training   91.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.071 Prec@5=93.641 rate=0.89 Hz, eta=0:07:34, total=1:26:18, wall=23:08 IST
=> training   91.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.071 Prec@5=93.641 rate=0.89 Hz, eta=0:07:34, total=1:26:18, wall=23:09 IST
=> training   91.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.074 Prec@5=93.642 rate=0.89 Hz, eta=0:07:34, total=1:26:18, wall=23:09 IST
=> training   93.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.074 Prec@5=93.642 rate=0.89 Hz, eta=0:05:42, total=1:28:10, wall=23:09 IST
=> training   93.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.074 Prec@5=93.642 rate=0.89 Hz, eta=0:05:42, total=1:28:10, wall=23:11 IST
=> training   93.93% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.072 Prec@5=93.638 rate=0.89 Hz, eta=0:05:42, total=1:28:10, wall=23:11 IST
=> training   95.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.072 Prec@5=93.638 rate=0.89 Hz, eta=0:03:49, total=1:30:03, wall=23:11 IST
=> training   95.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.072 Prec@5=93.638 rate=0.89 Hz, eta=0:03:49, total=1:30:03, wall=23:13 IST
=> training   95.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.070 Prec@5=93.638 rate=0.89 Hz, eta=0:03:49, total=1:30:03, wall=23:13 IST
=> training   97.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.070 Prec@5=93.638 rate=0.89 Hz, eta=0:01:57, total=1:31:55, wall=23:13 IST
=> training   97.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.070 Prec@5=93.638 rate=0.89 Hz, eta=0:01:57, total=1:31:55, wall=23:15 IST
=> training   97.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.062 Prec@5=93.639 rate=0.89 Hz, eta=0:01:57, total=1:31:55, wall=23:15 IST
=> training   99.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.062 Prec@5=93.639 rate=0.89 Hz, eta=0:00:04, total=1:33:46, wall=23:15 IST
=> training   99.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.127 DataTime=0.200 Loss=0.826 Prec@1=79.062 Prec@5=93.639 rate=0.89 Hz, eta=0:00:04, total=1:33:46, wall=23:15 IST
=> training   99.92% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.126 DataTime=0.200 Loss=0.826 Prec@1=79.061 Prec@5=93.639 rate=0.89 Hz, eta=0:00:04, total=1:33:46, wall=23:15 IST
=> training   100.00% of 1x5005...Epoch=4/10 LR=0.00006 Time=1.126 DataTime=0.200 Loss=0.826 Prec@1=79.061 Prec@5=93.639 rate=0.89 Hz, eta=0:00:00, total=1:33:50, wall=23:15 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 4.000 4.000 8.000 2.000 4.000 8.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 4.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=23:15 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=23:15 IST
=> validation 0.00% of 1x196...Epoch=4/10 LR=0.00006 Time=7.867 Loss=1.121 Prec@1=73.047 Prec@5=90.625 rate=0 Hz, eta=?, total=0:00:00, wall=23:15 IST
=> validation 0.51% of 1x196...Epoch=4/10 LR=0.00006 Time=7.867 Loss=1.121 Prec@1=73.047 Prec@5=90.625 rate=3794.70 Hz, eta=0:00:00, total=0:00:00, wall=23:15 IST
=> validation 0.51% of 1x196...Epoch=4/10 LR=0.00006 Time=7.867 Loss=1.121 Prec@1=73.047 Prec@5=90.625 rate=3794.70 Hz, eta=0:00:00, total=0:00:00, wall=23:16 IST
=> validation 0.51% of 1x196...Epoch=4/10 LR=0.00006 Time=0.717 Loss=1.175 Prec@1=71.020 Prec@5=90.068 rate=3794.70 Hz, eta=0:00:00, total=0:00:00, wall=23:16 IST
=> validation 51.53% of 1x196...Epoch=4/10 LR=0.00006 Time=0.717 Loss=1.175 Prec@1=71.020 Prec@5=90.068 rate=1.56 Hz, eta=0:01:00, total=0:01:04, wall=23:16 IST
** validation 51.53% of 1x196...Epoch=4/10 LR=0.00006 Time=0.717 Loss=1.175 Prec@1=71.020 Prec@5=90.068 rate=1.56 Hz, eta=0:01:00, total=0:01:04, wall=23:17 IST
** validation 51.53% of 1x196...Epoch=4/10 LR=0.00006 Time=0.657 Loss=1.169 Prec@1=71.250 Prec@5=90.134 rate=1.56 Hz, eta=0:01:00, total=0:01:04, wall=23:17 IST
** validation 100.00% of 1x196...Epoch=4/10 LR=0.00006 Time=0.657 Loss=1.169 Prec@1=71.250 Prec@5=90.134 rate=1.62 Hz, eta=0:00:00, total=0:02:00, wall=23:17 IST
[39mFreezing BN for subsequent epochs
[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=23:18 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=23:18 IST
=> training   0.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=6.955 DataTime=4.214 Loss=0.929 Prec@1=74.219 Prec@5=91.406 rate=0 Hz, eta=?, total=0:00:00, wall=23:18 IST
=> training   0.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=6.955 DataTime=4.214 Loss=0.929 Prec@1=74.219 Prec@5=91.406 rate=7604.73 Hz, eta=0:00:00, total=0:00:00, wall=23:18 IST
=> training   0.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=6.955 DataTime=4.214 Loss=0.929 Prec@1=74.219 Prec@5=91.406 rate=7604.73 Hz, eta=0:00:00, total=0:00:00, wall=23:19 IST
=> training   0.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.186 DataTime=0.236 Loss=0.828 Prec@1=78.972 Prec@5=93.588 rate=7604.73 Hz, eta=0:00:00, total=0:00:00, wall=23:19 IST
=> training   2.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.186 DataTime=0.236 Loss=0.828 Prec@1=78.972 Prec@5=93.588 rate=0.90 Hz, eta=1:31:16, total=0:01:52, wall=23:19 IST
=> training   2.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.186 DataTime=0.236 Loss=0.828 Prec@1=78.972 Prec@5=93.588 rate=0.90 Hz, eta=1:31:16, total=0:01:52, wall=23:21 IST
=> training   2.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.152 DataTime=0.216 Loss=0.812 Prec@1=79.452 Prec@5=93.633 rate=0.90 Hz, eta=1:31:16, total=0:01:52, wall=23:21 IST
=> training   4.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.152 DataTime=0.216 Loss=0.812 Prec@1=79.452 Prec@5=93.633 rate=0.90 Hz, eta=1:29:26, total=0:03:44, wall=23:21 IST
=> training   4.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.152 DataTime=0.216 Loss=0.812 Prec@1=79.452 Prec@5=93.633 rate=0.90 Hz, eta=1:29:26, total=0:03:44, wall=23:23 IST
=> training   4.02% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.141 DataTime=0.210 Loss=0.807 Prec@1=79.480 Prec@5=93.694 rate=0.90 Hz, eta=1:29:26, total=0:03:44, wall=23:23 IST
=> training   6.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.141 DataTime=0.210 Loss=0.807 Prec@1=79.480 Prec@5=93.694 rate=0.89 Hz, eta=1:27:36, total=0:05:36, wall=23:23 IST
=> training   6.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.141 DataTime=0.210 Loss=0.807 Prec@1=79.480 Prec@5=93.694 rate=0.89 Hz, eta=1:27:36, total=0:05:36, wall=23:25 IST
=> training   6.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.135 DataTime=0.206 Loss=0.803 Prec@1=79.624 Prec@5=93.694 rate=0.89 Hz, eta=1:27:36, total=0:05:36, wall=23:25 IST
=> training   8.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.135 DataTime=0.206 Loss=0.803 Prec@1=79.624 Prec@5=93.694 rate=0.89 Hz, eta=1:25:44, total=0:07:28, wall=23:25 IST
=> training   8.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.135 DataTime=0.206 Loss=0.803 Prec@1=79.624 Prec@5=93.694 rate=0.89 Hz, eta=1:25:44, total=0:07:28, wall=23:27 IST
=> training   8.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.131 DataTime=0.205 Loss=0.804 Prec@1=79.634 Prec@5=93.712 rate=0.89 Hz, eta=1:25:44, total=0:07:28, wall=23:27 IST
=> training   10.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.131 DataTime=0.205 Loss=0.804 Prec@1=79.634 Prec@5=93.712 rate=0.90 Hz, eta=1:23:50, total=0:09:19, wall=23:27 IST
=> training   10.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.131 DataTime=0.205 Loss=0.804 Prec@1=79.634 Prec@5=93.712 rate=0.90 Hz, eta=1:23:50, total=0:09:19, wall=23:29 IST
=> training   10.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.128 DataTime=0.203 Loss=0.805 Prec@1=79.593 Prec@5=93.716 rate=0.90 Hz, eta=1:23:50, total=0:09:19, wall=23:29 IST
=> training   12.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.128 DataTime=0.203 Loss=0.805 Prec@1=79.593 Prec@5=93.716 rate=0.90 Hz, eta=1:21:56, total=0:11:10, wall=23:29 IST
=> training   12.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.128 DataTime=0.203 Loss=0.805 Prec@1=79.593 Prec@5=93.716 rate=0.90 Hz, eta=1:21:56, total=0:11:10, wall=23:31 IST
=> training   12.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.127 DataTime=0.202 Loss=0.805 Prec@1=79.552 Prec@5=93.718 rate=0.90 Hz, eta=1:21:56, total=0:11:10, wall=23:31 IST
=> training   14.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.127 DataTime=0.202 Loss=0.805 Prec@1=79.552 Prec@5=93.718 rate=0.90 Hz, eta=1:20:06, total=0:13:02, wall=23:31 IST
=> training   14.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.127 DataTime=0.202 Loss=0.805 Prec@1=79.552 Prec@5=93.718 rate=0.90 Hz, eta=1:20:06, total=0:13:02, wall=23:32 IST
=> training   14.01% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.125 DataTime=0.201 Loss=0.810 Prec@1=79.435 Prec@5=93.662 rate=0.90 Hz, eta=1:20:06, total=0:13:02, wall=23:32 IST
=> training   16.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.125 DataTime=0.201 Loss=0.810 Prec@1=79.435 Prec@5=93.662 rate=0.90 Hz, eta=1:18:14, total=0:14:54, wall=23:32 IST
=> training   16.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.125 DataTime=0.201 Loss=0.810 Prec@1=79.435 Prec@5=93.662 rate=0.90 Hz, eta=1:18:14, total=0:14:54, wall=23:34 IST
=> training   16.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.124 DataTime=0.201 Loss=0.809 Prec@1=79.420 Prec@5=93.690 rate=0.90 Hz, eta=1:18:14, total=0:14:54, wall=23:34 IST
=> training   18.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.124 DataTime=0.201 Loss=0.809 Prec@1=79.420 Prec@5=93.690 rate=0.90 Hz, eta=1:16:22, total=0:16:46, wall=23:34 IST
=> training   18.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.124 DataTime=0.201 Loss=0.809 Prec@1=79.420 Prec@5=93.690 rate=0.90 Hz, eta=1:16:22, total=0:16:46, wall=23:36 IST
=> training   18.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.123 DataTime=0.200 Loss=0.809 Prec@1=79.404 Prec@5=93.696 rate=0.90 Hz, eta=1:16:22, total=0:16:46, wall=23:36 IST
=> training   20.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.123 DataTime=0.200 Loss=0.809 Prec@1=79.404 Prec@5=93.696 rate=0.90 Hz, eta=1:14:30, total=0:18:37, wall=23:36 IST
=> training   20.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.123 DataTime=0.200 Loss=0.809 Prec@1=79.404 Prec@5=93.696 rate=0.90 Hz, eta=1:14:30, total=0:18:37, wall=23:38 IST
=> training   20.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.123 DataTime=0.200 Loss=0.808 Prec@1=79.414 Prec@5=93.705 rate=0.90 Hz, eta=1:14:30, total=0:18:37, wall=23:38 IST
=> training   22.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.123 DataTime=0.200 Loss=0.808 Prec@1=79.414 Prec@5=93.705 rate=0.90 Hz, eta=1:12:38, total=0:20:29, wall=23:38 IST
=> training   22.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.123 DataTime=0.200 Loss=0.808 Prec@1=79.414 Prec@5=93.705 rate=0.90 Hz, eta=1:12:38, total=0:20:29, wall=23:40 IST
=> training   22.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.122 DataTime=0.200 Loss=0.809 Prec@1=79.404 Prec@5=93.694 rate=0.90 Hz, eta=1:12:38, total=0:20:29, wall=23:40 IST
=> training   24.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.122 DataTime=0.200 Loss=0.809 Prec@1=79.404 Prec@5=93.694 rate=0.90 Hz, eta=1:10:46, total=0:22:20, wall=23:40 IST
=> training   24.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.122 DataTime=0.200 Loss=0.809 Prec@1=79.404 Prec@5=93.694 rate=0.90 Hz, eta=1:10:46, total=0:22:20, wall=23:42 IST
=> training   24.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.122 DataTime=0.200 Loss=0.809 Prec@1=79.392 Prec@5=93.688 rate=0.90 Hz, eta=1:10:46, total=0:22:20, wall=23:42 IST
=> training   25.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.122 DataTime=0.200 Loss=0.809 Prec@1=79.392 Prec@5=93.688 rate=0.90 Hz, eta=1:08:55, total=0:24:12, wall=23:42 IST
=> training   25.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.122 DataTime=0.200 Loss=0.809 Prec@1=79.392 Prec@5=93.688 rate=0.90 Hz, eta=1:08:55, total=0:24:12, wall=23:44 IST
=> training   25.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.810 Prec@1=79.369 Prec@5=93.675 rate=0.90 Hz, eta=1:08:55, total=0:24:12, wall=23:44 IST
=> training   27.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.810 Prec@1=79.369 Prec@5=93.675 rate=0.90 Hz, eta=1:07:03, total=0:26:03, wall=23:44 IST
=> training   27.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.810 Prec@1=79.369 Prec@5=93.675 rate=0.90 Hz, eta=1:07:03, total=0:26:03, wall=23:45 IST
=> training   27.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.809 Prec@1=79.360 Prec@5=93.699 rate=0.90 Hz, eta=1:07:03, total=0:26:03, wall=23:45 IST
=> training   29.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.809 Prec@1=79.360 Prec@5=93.699 rate=0.90 Hz, eta=1:05:11, total=0:27:55, wall=23:45 IST
=> training   29.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.809 Prec@1=79.360 Prec@5=93.699 rate=0.90 Hz, eta=1:05:11, total=0:27:55, wall=23:47 IST
=> training   29.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.809 Prec@1=79.360 Prec@5=93.696 rate=0.90 Hz, eta=1:05:11, total=0:27:55, wall=23:47 IST
=> training   31.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.809 Prec@1=79.360 Prec@5=93.696 rate=0.90 Hz, eta=1:03:19, total=0:29:47, wall=23:47 IST
=> training   31.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.121 DataTime=0.199 Loss=0.809 Prec@1=79.360 Prec@5=93.696 rate=0.90 Hz, eta=1:03:19, total=0:29:47, wall=23:49 IST
=> training   31.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.809 Prec@1=79.336 Prec@5=93.687 rate=0.90 Hz, eta=1:03:19, total=0:29:47, wall=23:49 IST
=> training   33.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.809 Prec@1=79.336 Prec@5=93.687 rate=0.90 Hz, eta=1:01:28, total=0:31:39, wall=23:49 IST
=> training   33.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.809 Prec@1=79.336 Prec@5=93.687 rate=0.90 Hz, eta=1:01:28, total=0:31:39, wall=23:51 IST
=> training   33.99% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.808 Prec@1=79.365 Prec@5=93.705 rate=0.90 Hz, eta=1:01:28, total=0:31:39, wall=23:51 IST
=> training   35.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.808 Prec@1=79.365 Prec@5=93.705 rate=0.90 Hz, eta=0:59:37, total=0:33:30, wall=23:51 IST
=> training   35.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.808 Prec@1=79.365 Prec@5=93.705 rate=0.90 Hz, eta=0:59:37, total=0:33:30, wall=23:53 IST
=> training   35.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.807 Prec@1=79.397 Prec@5=93.720 rate=0.90 Hz, eta=0:59:37, total=0:33:30, wall=23:53 IST
=> training   37.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.807 Prec@1=79.397 Prec@5=93.720 rate=0.90 Hz, eta=0:57:45, total=0:35:22, wall=23:53 IST
=> training   37.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.199 Loss=0.807 Prec@1=79.397 Prec@5=93.720 rate=0.90 Hz, eta=0:57:45, total=0:35:22, wall=23:55 IST
=> training   37.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.806 Prec@1=79.406 Prec@5=93.719 rate=0.90 Hz, eta=0:57:45, total=0:35:22, wall=23:55 IST
=> training   39.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.806 Prec@1=79.406 Prec@5=93.719 rate=0.90 Hz, eta=0:55:53, total=0:37:13, wall=23:55 IST
=> training   39.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.806 Prec@1=79.406 Prec@5=93.719 rate=0.90 Hz, eta=0:55:53, total=0:37:13, wall=23:57 IST
=> training   39.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.806 Prec@1=79.393 Prec@5=93.712 rate=0.90 Hz, eta=0:55:53, total=0:37:13, wall=23:57 IST
=> training   41.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.806 Prec@1=79.393 Prec@5=93.712 rate=0.90 Hz, eta=0:54:01, total=0:39:05, wall=23:57 IST
=> training   41.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.806 Prec@1=79.393 Prec@5=93.712 rate=0.90 Hz, eta=0:54:01, total=0:39:05, wall=23:58 IST
=> training   41.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.805 Prec@1=79.430 Prec@5=93.726 rate=0.90 Hz, eta=0:54:01, total=0:39:05, wall=23:58 IST
=> training   43.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.805 Prec@1=79.430 Prec@5=93.726 rate=0.90 Hz, eta=0:52:09, total=0:40:56, wall=23:58 IST
=> training   43.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.805 Prec@1=79.430 Prec@5=93.726 rate=0.90 Hz, eta=0:52:09, total=0:40:56, wall=00:00 IST
=> training   43.98% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.804 Prec@1=79.435 Prec@5=93.740 rate=0.90 Hz, eta=0:52:09, total=0:40:56, wall=00:00 IST
=> training   45.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.804 Prec@1=79.435 Prec@5=93.740 rate=0.90 Hz, eta=0:50:19, total=0:42:49, wall=00:00 IST
=> training   45.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.804 Prec@1=79.435 Prec@5=93.740 rate=0.90 Hz, eta=0:50:19, total=0:42:49, wall=00:02 IST
=> training   45.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.804 Prec@1=79.437 Prec@5=93.735 rate=0.90 Hz, eta=0:50:19, total=0:42:49, wall=00:02 IST
=> training   47.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.804 Prec@1=79.437 Prec@5=93.735 rate=0.90 Hz, eta=0:48:27, total=0:44:41, wall=00:02 IST
=> training   47.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.120 DataTime=0.198 Loss=0.804 Prec@1=79.437 Prec@5=93.735 rate=0.90 Hz, eta=0:48:27, total=0:44:41, wall=00:04 IST
=> training   47.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.804 Prec@1=79.429 Prec@5=93.744 rate=0.90 Hz, eta=0:48:27, total=0:44:41, wall=00:04 IST
=> training   49.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.804 Prec@1=79.429 Prec@5=93.744 rate=0.90 Hz, eta=0:46:36, total=0:46:32, wall=00:04 IST
=> training   49.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.804 Prec@1=79.429 Prec@5=93.744 rate=0.90 Hz, eta=0:46:36, total=0:46:32, wall=00:06 IST
=> training   49.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.804 Prec@1=79.444 Prec@5=93.754 rate=0.90 Hz, eta=0:46:36, total=0:46:32, wall=00:06 IST
=> training   51.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.804 Prec@1=79.444 Prec@5=93.754 rate=0.90 Hz, eta=0:44:44, total=0:48:24, wall=00:06 IST
=> training   51.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.804 Prec@1=79.444 Prec@5=93.754 rate=0.90 Hz, eta=0:44:44, total=0:48:24, wall=00:08 IST
=> training   51.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.803 Prec@1=79.448 Prec@5=93.756 rate=0.90 Hz, eta=0:44:44, total=0:48:24, wall=00:08 IST
=> training   53.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.803 Prec@1=79.448 Prec@5=93.756 rate=0.90 Hz, eta=0:42:52, total=0:50:15, wall=00:08 IST
=> training   53.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.803 Prec@1=79.448 Prec@5=93.756 rate=0.90 Hz, eta=0:42:52, total=0:50:15, wall=00:10 IST
=> training   53.97% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.471 Prec@5=93.766 rate=0.90 Hz, eta=0:42:52, total=0:50:15, wall=00:10 IST
=> training   55.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.471 Prec@5=93.766 rate=0.90 Hz, eta=0:41:01, total=0:52:07, wall=00:10 IST
=> training   55.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.471 Prec@5=93.766 rate=0.90 Hz, eta=0:41:01, total=0:52:07, wall=00:12 IST
=> training   55.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.487 Prec@5=93.763 rate=0.90 Hz, eta=0:41:01, total=0:52:07, wall=00:12 IST
=> training   57.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.487 Prec@5=93.763 rate=0.90 Hz, eta=0:39:09, total=0:53:59, wall=00:12 IST
=> training   57.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.487 Prec@5=93.763 rate=0.90 Hz, eta=0:39:09, total=0:53:59, wall=00:13 IST
=> training   57.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.803 Prec@1=79.468 Prec@5=93.755 rate=0.90 Hz, eta=0:39:09, total=0:53:59, wall=00:13 IST
=> training   59.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.803 Prec@1=79.468 Prec@5=93.755 rate=0.90 Hz, eta=0:37:18, total=0:55:51, wall=00:13 IST
=> training   59.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.803 Prec@1=79.468 Prec@5=93.755 rate=0.90 Hz, eta=0:37:18, total=0:55:51, wall=00:15 IST
=> training   59.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.478 Prec@5=93.759 rate=0.90 Hz, eta=0:37:18, total=0:55:51, wall=00:15 IST
=> training   61.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.478 Prec@5=93.759 rate=0.90 Hz, eta=0:35:26, total=0:57:44, wall=00:15 IST
=> training   61.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.478 Prec@5=93.759 rate=0.90 Hz, eta=0:35:26, total=0:57:44, wall=00:17 IST
=> training   61.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.801 Prec@1=79.493 Prec@5=93.772 rate=0.90 Hz, eta=0:35:26, total=0:57:44, wall=00:17 IST
=> training   63.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.801 Prec@1=79.493 Prec@5=93.772 rate=0.90 Hz, eta=0:33:35, total=0:59:35, wall=00:17 IST
=> training   63.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.801 Prec@1=79.493 Prec@5=93.772 rate=0.90 Hz, eta=0:33:35, total=0:59:35, wall=00:19 IST
=> training   63.96% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.801 Prec@1=79.486 Prec@5=93.776 rate=0.90 Hz, eta=0:33:35, total=0:59:35, wall=00:19 IST
=> training   65.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.801 Prec@1=79.486 Prec@5=93.776 rate=0.90 Hz, eta=0:31:43, total=1:01:27, wall=00:19 IST
=> training   65.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.801 Prec@1=79.486 Prec@5=93.776 rate=0.90 Hz, eta=0:31:43, total=1:01:27, wall=00:21 IST
=> training   65.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.479 Prec@5=93.771 rate=0.90 Hz, eta=0:31:43, total=1:01:27, wall=00:21 IST
=> training   67.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.479 Prec@5=93.771 rate=0.90 Hz, eta=0:29:51, total=1:03:19, wall=00:21 IST
=> training   67.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.479 Prec@5=93.771 rate=0.90 Hz, eta=0:29:51, total=1:03:19, wall=00:23 IST
=> training   67.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.480 Prec@5=93.775 rate=0.90 Hz, eta=0:29:51, total=1:03:19, wall=00:23 IST
=> training   69.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.480 Prec@5=93.775 rate=0.90 Hz, eta=0:28:00, total=1:05:10, wall=00:23 IST
=> training   69.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.480 Prec@5=93.775 rate=0.90 Hz, eta=0:28:00, total=1:05:10, wall=00:25 IST
=> training   69.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.461 Prec@5=93.769 rate=0.90 Hz, eta=0:28:00, total=1:05:10, wall=00:25 IST
=> training   71.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.461 Prec@5=93.769 rate=0.90 Hz, eta=0:26:08, total=1:07:02, wall=00:25 IST
=> training   71.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.461 Prec@5=93.769 rate=0.90 Hz, eta=0:26:08, total=1:07:02, wall=00:26 IST
=> training   71.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.480 Prec@5=93.777 rate=0.90 Hz, eta=0:26:08, total=1:07:02, wall=00:26 IST
=> training   73.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.480 Prec@5=93.777 rate=0.90 Hz, eta=0:24:16, total=1:08:53, wall=00:26 IST
=> training   73.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.480 Prec@5=93.777 rate=0.90 Hz, eta=0:24:16, total=1:08:53, wall=00:28 IST
=> training   73.95% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.477 Prec@5=93.775 rate=0.90 Hz, eta=0:24:16, total=1:08:53, wall=00:28 IST
=> training   75.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.477 Prec@5=93.775 rate=0.90 Hz, eta=0:22:24, total=1:10:45, wall=00:28 IST
=> training   75.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.477 Prec@5=93.775 rate=0.90 Hz, eta=0:22:24, total=1:10:45, wall=00:30 IST
=> training   75.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.467 Prec@5=93.775 rate=0.90 Hz, eta=0:22:24, total=1:10:45, wall=00:30 IST
=> training   77.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.467 Prec@5=93.775 rate=0.90 Hz, eta=0:20:33, total=1:12:37, wall=00:30 IST
=> training   77.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.198 Loss=0.802 Prec@1=79.467 Prec@5=93.775 rate=0.90 Hz, eta=0:20:33, total=1:12:37, wall=00:32 IST
=> training   77.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.466 Prec@5=93.771 rate=0.90 Hz, eta=0:20:33, total=1:12:37, wall=00:32 IST
=> training   79.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.466 Prec@5=93.771 rate=0.90 Hz, eta=0:18:41, total=1:14:29, wall=00:32 IST
=> training   79.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.466 Prec@5=93.771 rate=0.90 Hz, eta=0:18:41, total=1:14:29, wall=00:34 IST
=> training   79.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.456 Prec@5=93.760 rate=0.90 Hz, eta=0:18:41, total=1:14:29, wall=00:34 IST
=> training   81.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.456 Prec@5=93.760 rate=0.90 Hz, eta=0:16:49, total=1:16:20, wall=00:34 IST
=> training   81.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.456 Prec@5=93.760 rate=0.90 Hz, eta=0:16:49, total=1:16:20, wall=00:36 IST
=> training   81.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.459 Prec@5=93.763 rate=0.90 Hz, eta=0:16:49, total=1:16:20, wall=00:36 IST
=> training   83.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.459 Prec@5=93.763 rate=0.90 Hz, eta=0:14:58, total=1:18:12, wall=00:36 IST
=> training   83.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.459 Prec@5=93.763 rate=0.90 Hz, eta=0:14:58, total=1:18:12, wall=00:38 IST
=> training   83.94% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.468 Prec@5=93.768 rate=0.90 Hz, eta=0:14:58, total=1:18:12, wall=00:38 IST
=> training   85.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.468 Prec@5=93.768 rate=0.90 Hz, eta=0:13:06, total=1:20:04, wall=00:38 IST
=> training   85.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.802 Prec@1=79.468 Prec@5=93.768 rate=0.90 Hz, eta=0:13:06, total=1:20:04, wall=00:39 IST
=> training   85.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.801 Prec@1=79.472 Prec@5=93.773 rate=0.90 Hz, eta=0:13:06, total=1:20:04, wall=00:39 IST
=> training   87.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.801 Prec@1=79.472 Prec@5=93.773 rate=0.90 Hz, eta=0:11:14, total=1:21:55, wall=00:39 IST
=> training   87.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.801 Prec@1=79.472 Prec@5=93.773 rate=0.90 Hz, eta=0:11:14, total=1:21:55, wall=00:41 IST
=> training   87.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.801 Prec@1=79.474 Prec@5=93.780 rate=0.90 Hz, eta=0:11:14, total=1:21:55, wall=00:41 IST
=> training   89.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.801 Prec@1=79.474 Prec@5=93.780 rate=0.90 Hz, eta=0:09:22, total=1:23:47, wall=00:41 IST
=> training   89.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.119 DataTime=0.197 Loss=0.801 Prec@1=79.474 Prec@5=93.780 rate=0.90 Hz, eta=0:09:22, total=1:23:47, wall=00:43 IST
=> training   89.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.484 Prec@5=93.789 rate=0.90 Hz, eta=0:09:22, total=1:23:47, wall=00:43 IST
=> training   91.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.484 Prec@5=93.789 rate=0.90 Hz, eta=0:07:31, total=1:25:39, wall=00:43 IST
=> training   91.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.484 Prec@5=93.789 rate=0.90 Hz, eta=0:07:31, total=1:25:39, wall=00:45 IST
=> training   91.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.489 Prec@5=93.785 rate=0.90 Hz, eta=0:07:31, total=1:25:39, wall=00:45 IST
=> training   93.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.489 Prec@5=93.785 rate=0.90 Hz, eta=0:05:39, total=1:27:30, wall=00:45 IST
=> training   93.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.489 Prec@5=93.785 rate=0.90 Hz, eta=0:05:39, total=1:27:30, wall=00:47 IST
=> training   93.93% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.490 Prec@5=93.786 rate=0.90 Hz, eta=0:05:39, total=1:27:30, wall=00:47 IST
=> training   95.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.490 Prec@5=93.786 rate=0.90 Hz, eta=0:03:47, total=1:29:22, wall=00:47 IST
=> training   95.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.490 Prec@5=93.786 rate=0.90 Hz, eta=0:03:47, total=1:29:22, wall=00:49 IST
=> training   95.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.488 Prec@5=93.784 rate=0.90 Hz, eta=0:03:47, total=1:29:22, wall=00:49 IST
=> training   97.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.488 Prec@5=93.784 rate=0.90 Hz, eta=0:01:56, total=1:31:14, wall=00:49 IST
=> training   97.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.488 Prec@5=93.784 rate=0.90 Hz, eta=0:01:56, total=1:31:14, wall=00:51 IST
=> training   97.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.493 Prec@5=93.786 rate=0.90 Hz, eta=0:01:56, total=1:31:14, wall=00:51 IST
=> training   99.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.493 Prec@5=93.786 rate=0.90 Hz, eta=0:00:04, total=1:33:04, wall=00:51 IST
=> training   99.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.493 Prec@5=93.786 rate=0.90 Hz, eta=0:00:04, total=1:33:04, wall=00:51 IST
=> training   99.92% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.493 Prec@5=93.786 rate=0.90 Hz, eta=0:00:04, total=1:33:04, wall=00:51 IST
=> training   100.00% of 1x5005...Epoch=5/10 LR=0.00008 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.493 Prec@5=93.786 rate=0.90 Hz, eta=0:00:00, total=1:33:08, wall=00:51 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 8.000 4.000 8.000 2.000 4.000 8.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 4.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=00:51 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=00:51 IST
=> validation 0.00% of 1x196...Epoch=5/10 LR=0.00008 Time=7.557 Loss=1.317 Prec@1=69.141 Prec@5=87.891 rate=0 Hz, eta=?, total=0:00:00, wall=00:51 IST
=> validation 0.51% of 1x196...Epoch=5/10 LR=0.00008 Time=7.557 Loss=1.317 Prec@1=69.141 Prec@5=87.891 rate=5903.74 Hz, eta=0:00:00, total=0:00:00, wall=00:51 IST
=> validation 0.51% of 1x196...Epoch=5/10 LR=0.00008 Time=7.557 Loss=1.317 Prec@1=69.141 Prec@5=87.891 rate=5903.74 Hz, eta=0:00:00, total=0:00:00, wall=00:52 IST
=> validation 0.51% of 1x196...Epoch=5/10 LR=0.00008 Time=0.718 Loss=1.169 Prec@1=71.705 Prec@5=90.319 rate=5903.74 Hz, eta=0:00:00, total=0:00:00, wall=00:52 IST
=> validation 51.53% of 1x196...Epoch=5/10 LR=0.00008 Time=0.718 Loss=1.169 Prec@1=71.705 Prec@5=90.319 rate=1.55 Hz, eta=0:01:01, total=0:01:04, wall=00:52 IST
** validation 51.53% of 1x196...Epoch=5/10 LR=0.00008 Time=0.718 Loss=1.169 Prec@1=71.705 Prec@5=90.319 rate=1.55 Hz, eta=0:01:01, total=0:01:04, wall=00:53 IST
** validation 51.53% of 1x196...Epoch=5/10 LR=0.00008 Time=0.656 Loss=1.171 Prec@1=71.572 Prec@5=90.308 rate=1.55 Hz, eta=0:01:01, total=0:01:04, wall=00:53 IST
** validation 100.00% of 1x196...Epoch=5/10 LR=0.00008 Time=0.656 Loss=1.171 Prec@1=71.572 Prec@5=90.308 rate=1.62 Hz, eta=0:00:00, total=0:02:01, wall=00:53 IST
[39m[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=00:53 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=00:53 IST
=> training   0.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=6.569 DataTime=4.242 Loss=0.645 Prec@1=83.594 Prec@5=95.703 rate=0 Hz, eta=?, total=0:00:00, wall=00:53 IST
=> training   0.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=6.569 DataTime=4.242 Loss=0.645 Prec@1=83.594 Prec@5=95.703 rate=7123.42 Hz, eta=0:00:00, total=0:00:00, wall=00:53 IST
=> training   0.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=6.569 DataTime=4.242 Loss=0.645 Prec@1=83.594 Prec@5=95.703 rate=7123.42 Hz, eta=0:00:00, total=0:00:00, wall=00:55 IST
=> training   0.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.184 DataTime=0.236 Loss=0.810 Prec@1=79.165 Prec@5=93.669 rate=7123.42 Hz, eta=0:00:00, total=0:00:00, wall=00:55 IST
=> training   2.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.184 DataTime=0.236 Loss=0.810 Prec@1=79.165 Prec@5=93.669 rate=0.89 Hz, eta=1:31:25, total=0:01:52, wall=00:55 IST
=> training   2.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.184 DataTime=0.236 Loss=0.810 Prec@1=79.165 Prec@5=93.669 rate=0.89 Hz, eta=1:31:25, total=0:01:52, wall=00:57 IST
=> training   2.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.150 DataTime=0.216 Loss=0.799 Prec@1=79.307 Prec@5=93.781 rate=0.89 Hz, eta=1:31:25, total=0:01:52, wall=00:57 IST
=> training   4.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.150 DataTime=0.216 Loss=0.799 Prec@1=79.307 Prec@5=93.781 rate=0.90 Hz, eta=1:29:27, total=0:03:44, wall=00:57 IST
=> training   4.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.150 DataTime=0.216 Loss=0.799 Prec@1=79.307 Prec@5=93.781 rate=0.90 Hz, eta=1:29:27, total=0:03:44, wall=00:59 IST
=> training   4.02% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.139 DataTime=0.210 Loss=0.799 Prec@1=79.355 Prec@5=93.790 rate=0.90 Hz, eta=1:29:27, total=0:03:44, wall=00:59 IST
=> training   6.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.139 DataTime=0.210 Loss=0.799 Prec@1=79.355 Prec@5=93.790 rate=0.90 Hz, eta=1:27:33, total=0:05:36, wall=00:59 IST
=> training   6.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.139 DataTime=0.210 Loss=0.799 Prec@1=79.355 Prec@5=93.790 rate=0.90 Hz, eta=1:27:33, total=0:05:36, wall=01:00 IST
=> training   6.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.133 DataTime=0.206 Loss=0.800 Prec@1=79.366 Prec@5=93.784 rate=0.90 Hz, eta=1:27:33, total=0:05:36, wall=01:00 IST
=> training   8.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.133 DataTime=0.206 Loss=0.800 Prec@1=79.366 Prec@5=93.784 rate=0.90 Hz, eta=1:25:40, total=0:07:27, wall=01:00 IST
=> training   8.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.133 DataTime=0.206 Loss=0.800 Prec@1=79.366 Prec@5=93.784 rate=0.90 Hz, eta=1:25:40, total=0:07:27, wall=01:02 IST
=> training   8.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.129 DataTime=0.204 Loss=0.800 Prec@1=79.382 Prec@5=93.787 rate=0.90 Hz, eta=1:25:40, total=0:07:27, wall=01:02 IST
=> training   10.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.129 DataTime=0.204 Loss=0.800 Prec@1=79.382 Prec@5=93.787 rate=0.90 Hz, eta=1:23:45, total=0:09:19, wall=01:02 IST
=> training   10.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.129 DataTime=0.204 Loss=0.800 Prec@1=79.382 Prec@5=93.787 rate=0.90 Hz, eta=1:23:45, total=0:09:19, wall=01:04 IST
=> training   10.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.127 DataTime=0.203 Loss=0.796 Prec@1=79.493 Prec@5=93.828 rate=0.90 Hz, eta=1:23:45, total=0:09:19, wall=01:04 IST
=> training   12.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.127 DataTime=0.203 Loss=0.796 Prec@1=79.493 Prec@5=93.828 rate=0.90 Hz, eta=1:21:55, total=0:11:10, wall=01:04 IST
=> training   12.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.127 DataTime=0.203 Loss=0.796 Prec@1=79.493 Prec@5=93.828 rate=0.90 Hz, eta=1:21:55, total=0:11:10, wall=01:06 IST
=> training   12.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.125 DataTime=0.202 Loss=0.794 Prec@1=79.543 Prec@5=93.854 rate=0.90 Hz, eta=1:21:55, total=0:11:10, wall=01:06 IST
=> training   14.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.125 DataTime=0.202 Loss=0.794 Prec@1=79.543 Prec@5=93.854 rate=0.90 Hz, eta=1:20:03, total=0:13:02, wall=01:06 IST
=> training   14.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.125 DataTime=0.202 Loss=0.794 Prec@1=79.543 Prec@5=93.854 rate=0.90 Hz, eta=1:20:03, total=0:13:02, wall=01:08 IST
=> training   14.01% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.124 DataTime=0.201 Loss=0.792 Prec@1=79.629 Prec@5=93.891 rate=0.90 Hz, eta=1:20:03, total=0:13:02, wall=01:08 IST
=> training   16.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.124 DataTime=0.201 Loss=0.792 Prec@1=79.629 Prec@5=93.891 rate=0.90 Hz, eta=1:18:12, total=0:14:54, wall=01:08 IST
=> training   16.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.124 DataTime=0.201 Loss=0.792 Prec@1=79.629 Prec@5=93.891 rate=0.90 Hz, eta=1:18:12, total=0:14:54, wall=01:10 IST
=> training   16.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.123 DataTime=0.201 Loss=0.794 Prec@1=79.598 Prec@5=93.871 rate=0.90 Hz, eta=1:18:12, total=0:14:54, wall=01:10 IST
=> training   18.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.123 DataTime=0.201 Loss=0.794 Prec@1=79.598 Prec@5=93.871 rate=0.90 Hz, eta=1:16:20, total=0:16:45, wall=01:10 IST
=> training   18.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.123 DataTime=0.201 Loss=0.794 Prec@1=79.598 Prec@5=93.871 rate=0.90 Hz, eta=1:16:20, total=0:16:45, wall=01:12 IST
=> training   18.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.123 DataTime=0.200 Loss=0.794 Prec@1=79.600 Prec@5=93.853 rate=0.90 Hz, eta=1:16:20, total=0:16:45, wall=01:12 IST
=> training   20.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.123 DataTime=0.200 Loss=0.794 Prec@1=79.600 Prec@5=93.853 rate=0.90 Hz, eta=1:14:28, total=0:18:37, wall=01:12 IST
=> training   20.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.123 DataTime=0.200 Loss=0.794 Prec@1=79.600 Prec@5=93.853 rate=0.90 Hz, eta=1:14:28, total=0:18:37, wall=01:13 IST
=> training   20.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.122 DataTime=0.200 Loss=0.795 Prec@1=79.575 Prec@5=93.830 rate=0.90 Hz, eta=1:14:28, total=0:18:37, wall=01:13 IST
=> training   22.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.122 DataTime=0.200 Loss=0.795 Prec@1=79.575 Prec@5=93.830 rate=0.90 Hz, eta=1:12:37, total=0:20:28, wall=01:13 IST
=> training   22.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.122 DataTime=0.200 Loss=0.795 Prec@1=79.575 Prec@5=93.830 rate=0.90 Hz, eta=1:12:37, total=0:20:28, wall=01:15 IST
=> training   22.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.121 DataTime=0.200 Loss=0.797 Prec@1=79.540 Prec@5=93.797 rate=0.90 Hz, eta=1:12:37, total=0:20:28, wall=01:15 IST
=> training   24.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.121 DataTime=0.200 Loss=0.797 Prec@1=79.540 Prec@5=93.797 rate=0.90 Hz, eta=1:10:45, total=0:22:20, wall=01:15 IST
=> training   24.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.121 DataTime=0.200 Loss=0.797 Prec@1=79.540 Prec@5=93.797 rate=0.90 Hz, eta=1:10:45, total=0:22:20, wall=01:17 IST
=> training   24.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.121 DataTime=0.200 Loss=0.797 Prec@1=79.533 Prec@5=93.797 rate=0.90 Hz, eta=1:10:45, total=0:22:20, wall=01:17 IST
=> training   25.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.121 DataTime=0.200 Loss=0.797 Prec@1=79.533 Prec@5=93.797 rate=0.90 Hz, eta=1:08:53, total=0:24:11, wall=01:17 IST
=> training   25.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.121 DataTime=0.200 Loss=0.797 Prec@1=79.533 Prec@5=93.797 rate=0.90 Hz, eta=1:08:53, total=0:24:11, wall=01:19 IST
=> training   25.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.560 Prec@5=93.796 rate=0.90 Hz, eta=1:08:53, total=0:24:11, wall=01:19 IST
=> training   27.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.560 Prec@5=93.796 rate=0.90 Hz, eta=1:07:01, total=0:26:03, wall=01:19 IST
=> training   27.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.560 Prec@5=93.796 rate=0.90 Hz, eta=1:07:01, total=0:26:03, wall=01:21 IST
=> training   27.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.529 Prec@5=93.808 rate=0.90 Hz, eta=1:07:01, total=0:26:03, wall=01:21 IST
=> training   29.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.529 Prec@5=93.808 rate=0.90 Hz, eta=1:05:09, total=0:27:54, wall=01:21 IST
=> training   29.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.529 Prec@5=93.808 rate=0.90 Hz, eta=1:05:09, total=0:27:54, wall=01:23 IST
=> training   29.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.553 Prec@5=93.818 rate=0.90 Hz, eta=1:05:09, total=0:27:54, wall=01:23 IST
=> training   31.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.553 Prec@5=93.818 rate=0.90 Hz, eta=1:03:17, total=0:29:46, wall=01:23 IST
=> training   31.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.553 Prec@5=93.818 rate=0.90 Hz, eta=1:03:17, total=0:29:46, wall=01:25 IST
=> training   31.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.567 Prec@5=93.812 rate=0.90 Hz, eta=1:03:17, total=0:29:46, wall=01:25 IST
=> training   33.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.567 Prec@5=93.812 rate=0.90 Hz, eta=1:01:26, total=0:31:37, wall=01:25 IST
=> training   33.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.120 DataTime=0.199 Loss=0.797 Prec@1=79.567 Prec@5=93.812 rate=0.90 Hz, eta=1:01:26, total=0:31:37, wall=01:27 IST
=> training   33.99% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.199 Loss=0.796 Prec@1=79.572 Prec@5=93.824 rate=0.90 Hz, eta=1:01:26, total=0:31:37, wall=01:27 IST
=> training   35.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.199 Loss=0.796 Prec@1=79.572 Prec@5=93.824 rate=0.90 Hz, eta=0:59:35, total=0:33:29, wall=01:27 IST
=> training   35.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.199 Loss=0.796 Prec@1=79.572 Prec@5=93.824 rate=0.90 Hz, eta=0:59:35, total=0:33:29, wall=01:28 IST
=> training   35.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.199 Loss=0.797 Prec@1=79.550 Prec@5=93.819 rate=0.90 Hz, eta=0:59:35, total=0:33:29, wall=01:28 IST
=> training   37.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.199 Loss=0.797 Prec@1=79.550 Prec@5=93.819 rate=0.90 Hz, eta=0:57:43, total=0:35:21, wall=01:28 IST
=> training   37.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.199 Loss=0.797 Prec@1=79.550 Prec@5=93.819 rate=0.90 Hz, eta=0:57:43, total=0:35:21, wall=01:30 IST
=> training   37.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.797 Prec@1=79.530 Prec@5=93.820 rate=0.90 Hz, eta=0:57:43, total=0:35:21, wall=01:30 IST
=> training   39.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.797 Prec@1=79.530 Prec@5=93.820 rate=0.90 Hz, eta=0:55:52, total=0:37:12, wall=01:30 IST
=> training   39.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.797 Prec@1=79.530 Prec@5=93.820 rate=0.90 Hz, eta=0:55:52, total=0:37:12, wall=01:32 IST
=> training   39.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.797 Prec@1=79.529 Prec@5=93.812 rate=0.90 Hz, eta=0:55:52, total=0:37:12, wall=01:32 IST
=> training   41.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.797 Prec@1=79.529 Prec@5=93.812 rate=0.90 Hz, eta=0:54:00, total=0:39:04, wall=01:32 IST
=> training   41.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.797 Prec@1=79.529 Prec@5=93.812 rate=0.90 Hz, eta=0:54:00, total=0:39:04, wall=01:34 IST
=> training   41.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.515 Prec@5=93.808 rate=0.90 Hz, eta=0:54:00, total=0:39:04, wall=01:34 IST
=> training   43.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.515 Prec@5=93.808 rate=0.90 Hz, eta=0:52:09, total=0:40:56, wall=01:34 IST
=> training   43.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.515 Prec@5=93.808 rate=0.90 Hz, eta=0:52:09, total=0:40:56, wall=01:36 IST
=> training   43.98% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.513 Prec@5=93.804 rate=0.90 Hz, eta=0:52:09, total=0:40:56, wall=01:36 IST
=> training   45.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.513 Prec@5=93.804 rate=0.90 Hz, eta=0:50:17, total=0:42:48, wall=01:36 IST
=> training   45.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.513 Prec@5=93.804 rate=0.90 Hz, eta=0:50:17, total=0:42:48, wall=01:38 IST
=> training   45.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.512 Prec@5=93.802 rate=0.90 Hz, eta=0:50:17, total=0:42:48, wall=01:38 IST
=> training   47.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.512 Prec@5=93.802 rate=0.90 Hz, eta=0:48:26, total=0:44:39, wall=01:38 IST
=> training   47.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.512 Prec@5=93.802 rate=0.90 Hz, eta=0:48:26, total=0:44:39, wall=01:40 IST
=> training   47.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.492 Prec@5=93.790 rate=0.90 Hz, eta=0:48:26, total=0:44:39, wall=01:40 IST
=> training   49.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.492 Prec@5=93.790 rate=0.90 Hz, eta=0:46:34, total=0:46:31, wall=01:40 IST
=> training   49.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.492 Prec@5=93.790 rate=0.90 Hz, eta=0:46:34, total=0:46:31, wall=01:41 IST
=> training   49.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.495 Prec@5=93.792 rate=0.90 Hz, eta=0:46:34, total=0:46:31, wall=01:41 IST
=> training   51.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.495 Prec@5=93.792 rate=0.90 Hz, eta=0:44:42, total=0:48:22, wall=01:41 IST
=> training   51.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.495 Prec@5=93.792 rate=0.90 Hz, eta=0:44:42, total=0:48:22, wall=01:43 IST
=> training   51.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.511 Prec@5=93.798 rate=0.90 Hz, eta=0:44:42, total=0:48:22, wall=01:43 IST
=> training   53.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.511 Prec@5=93.798 rate=0.90 Hz, eta=0:42:51, total=0:50:14, wall=01:43 IST
=> training   53.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.798 Prec@1=79.511 Prec@5=93.798 rate=0.90 Hz, eta=0:42:51, total=0:50:14, wall=01:45 IST
=> training   53.97% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.493 Prec@5=93.795 rate=0.90 Hz, eta=0:42:51, total=0:50:14, wall=01:45 IST
=> training   55.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.493 Prec@5=93.795 rate=0.90 Hz, eta=0:41:00, total=0:52:06, wall=01:45 IST
=> training   55.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.493 Prec@5=93.795 rate=0.90 Hz, eta=0:41:00, total=0:52:06, wall=01:47 IST
=> training   55.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.488 Prec@5=93.789 rate=0.90 Hz, eta=0:41:00, total=0:52:06, wall=01:47 IST
=> training   57.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.488 Prec@5=93.789 rate=0.90 Hz, eta=0:39:08, total=0:53:58, wall=01:47 IST
=> training   57.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.119 DataTime=0.198 Loss=0.799 Prec@1=79.488 Prec@5=93.789 rate=0.90 Hz, eta=0:39:08, total=0:53:58, wall=01:49 IST
=> training   57.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.799 Prec@1=79.491 Prec@5=93.793 rate=0.90 Hz, eta=0:39:08, total=0:53:58, wall=01:49 IST
=> training   59.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.799 Prec@1=79.491 Prec@5=93.793 rate=0.90 Hz, eta=0:37:17, total=0:55:49, wall=01:49 IST
=> training   59.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.799 Prec@1=79.491 Prec@5=93.793 rate=0.90 Hz, eta=0:37:17, total=0:55:49, wall=01:51 IST
=> training   59.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.487 Prec@5=93.801 rate=0.90 Hz, eta=0:37:17, total=0:55:49, wall=01:51 IST
=> training   61.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.487 Prec@5=93.801 rate=0.90 Hz, eta=0:35:25, total=0:57:41, wall=01:51 IST
=> training   61.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.487 Prec@5=93.801 rate=0.90 Hz, eta=0:35:25, total=0:57:41, wall=01:53 IST
=> training   61.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.799 Prec@1=79.488 Prec@5=93.800 rate=0.90 Hz, eta=0:35:25, total=0:57:41, wall=01:53 IST
=> training   63.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.799 Prec@1=79.488 Prec@5=93.800 rate=0.90 Hz, eta=0:33:33, total=0:59:33, wall=01:53 IST
=> training   63.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.799 Prec@1=79.488 Prec@5=93.800 rate=0.90 Hz, eta=0:33:33, total=0:59:33, wall=01:54 IST
=> training   63.96% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.498 Prec@5=93.798 rate=0.90 Hz, eta=0:33:33, total=0:59:33, wall=01:54 IST
=> training   65.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.498 Prec@5=93.798 rate=0.90 Hz, eta=0:31:42, total=1:01:24, wall=01:54 IST
=> training   65.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.498 Prec@5=93.798 rate=0.90 Hz, eta=0:31:42, total=1:01:24, wall=01:56 IST
=> training   65.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.511 Prec@5=93.810 rate=0.90 Hz, eta=0:31:42, total=1:01:24, wall=01:56 IST
=> training   67.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.511 Prec@5=93.810 rate=0.90 Hz, eta=0:29:50, total=1:03:16, wall=01:56 IST
=> training   67.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.511 Prec@5=93.810 rate=0.90 Hz, eta=0:29:50, total=1:03:16, wall=01:58 IST
=> training   67.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.501 Prec@5=93.808 rate=0.90 Hz, eta=0:29:50, total=1:03:16, wall=01:58 IST
=> training   69.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.501 Prec@5=93.808 rate=0.90 Hz, eta=0:27:58, total=1:05:08, wall=01:58 IST
=> training   69.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.501 Prec@5=93.808 rate=0.90 Hz, eta=0:27:58, total=1:05:08, wall=02:00 IST
=> training   69.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.495 Prec@5=93.806 rate=0.90 Hz, eta=0:27:58, total=1:05:08, wall=02:00 IST
=> training   71.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.495 Prec@5=93.806 rate=0.90 Hz, eta=0:26:07, total=1:06:59, wall=02:00 IST
=> training   71.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.198 Loss=0.798 Prec@1=79.495 Prec@5=93.806 rate=0.90 Hz, eta=0:26:07, total=1:06:59, wall=02:02 IST
=> training   71.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.487 Prec@5=93.801 rate=0.90 Hz, eta=0:26:07, total=1:06:59, wall=02:02 IST
=> training   73.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.487 Prec@5=93.801 rate=0.90 Hz, eta=0:24:15, total=1:08:51, wall=02:02 IST
=> training   73.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.487 Prec@5=93.801 rate=0.90 Hz, eta=0:24:15, total=1:08:51, wall=02:04 IST
=> training   73.95% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.478 Prec@5=93.799 rate=0.90 Hz, eta=0:24:15, total=1:08:51, wall=02:04 IST
=> training   75.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.478 Prec@5=93.799 rate=0.90 Hz, eta=0:22:24, total=1:10:43, wall=02:04 IST
=> training   75.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.478 Prec@5=93.799 rate=0.90 Hz, eta=0:22:24, total=1:10:43, wall=02:06 IST
=> training   75.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.483 Prec@5=93.796 rate=0.90 Hz, eta=0:22:24, total=1:10:43, wall=02:06 IST
=> training   77.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.483 Prec@5=93.796 rate=0.90 Hz, eta=0:20:32, total=1:12:34, wall=02:06 IST
=> training   77.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.799 Prec@1=79.483 Prec@5=93.796 rate=0.90 Hz, eta=0:20:32, total=1:12:34, wall=02:07 IST
=> training   77.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.471 Prec@5=93.789 rate=0.90 Hz, eta=0:20:32, total=1:12:34, wall=02:07 IST
=> training   79.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.471 Prec@5=93.789 rate=0.90 Hz, eta=0:18:40, total=1:14:26, wall=02:07 IST
=> training   79.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.471 Prec@5=93.789 rate=0.90 Hz, eta=0:18:40, total=1:14:26, wall=02:09 IST
=> training   79.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.465 Prec@5=93.786 rate=0.90 Hz, eta=0:18:40, total=1:14:26, wall=02:09 IST
=> training   81.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.465 Prec@5=93.786 rate=0.90 Hz, eta=0:16:49, total=1:16:18, wall=02:09 IST
=> training   81.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.465 Prec@5=93.786 rate=0.90 Hz, eta=0:16:49, total=1:16:18, wall=02:11 IST
=> training   81.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.457 Prec@5=93.786 rate=0.90 Hz, eta=0:16:49, total=1:16:18, wall=02:11 IST
=> training   83.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.457 Prec@5=93.786 rate=0.90 Hz, eta=0:14:57, total=1:18:09, wall=02:11 IST
=> training   83.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.457 Prec@5=93.786 rate=0.90 Hz, eta=0:14:57, total=1:18:09, wall=02:13 IST
=> training   83.94% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.455 Prec@5=93.792 rate=0.90 Hz, eta=0:14:57, total=1:18:09, wall=02:13 IST
=> training   85.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.455 Prec@5=93.792 rate=0.90 Hz, eta=0:13:05, total=1:20:01, wall=02:13 IST
=> training   85.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.455 Prec@5=93.792 rate=0.90 Hz, eta=0:13:05, total=1:20:01, wall=02:15 IST
=> training   85.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.456 Prec@5=93.789 rate=0.90 Hz, eta=0:13:05, total=1:20:01, wall=02:15 IST
=> training   87.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.456 Prec@5=93.789 rate=0.90 Hz, eta=0:11:14, total=1:21:53, wall=02:15 IST
=> training   87.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.456 Prec@5=93.789 rate=0.90 Hz, eta=0:11:14, total=1:21:53, wall=02:17 IST
=> training   87.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.455 Prec@5=93.787 rate=0.90 Hz, eta=0:11:14, total=1:21:53, wall=02:17 IST
=> training   89.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.455 Prec@5=93.787 rate=0.90 Hz, eta=0:09:22, total=1:23:45, wall=02:17 IST
=> training   89.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.455 Prec@5=93.787 rate=0.90 Hz, eta=0:09:22, total=1:23:45, wall=02:19 IST
=> training   89.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.442 Prec@5=93.783 rate=0.90 Hz, eta=0:09:22, total=1:23:45, wall=02:19 IST
=> training   91.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.442 Prec@5=93.783 rate=0.90 Hz, eta=0:07:31, total=1:25:36, wall=02:19 IST
=> training   91.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.442 Prec@5=93.783 rate=0.90 Hz, eta=0:07:31, total=1:25:36, wall=02:20 IST
=> training   91.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.438 Prec@5=93.781 rate=0.90 Hz, eta=0:07:31, total=1:25:36, wall=02:20 IST
=> training   93.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.438 Prec@5=93.781 rate=0.90 Hz, eta=0:05:39, total=1:27:28, wall=02:20 IST
=> training   93.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.800 Prec@1=79.438 Prec@5=93.781 rate=0.90 Hz, eta=0:05:39, total=1:27:28, wall=02:22 IST
=> training   93.93% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.439 Prec@5=93.782 rate=0.90 Hz, eta=0:05:39, total=1:27:28, wall=02:22 IST
=> training   95.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.439 Prec@5=93.782 rate=0.90 Hz, eta=0:03:47, total=1:29:19, wall=02:22 IST
=> training   95.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.439 Prec@5=93.782 rate=0.90 Hz, eta=0:03:47, total=1:29:19, wall=02:24 IST
=> training   95.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.431 Prec@5=93.784 rate=0.90 Hz, eta=0:03:47, total=1:29:19, wall=02:24 IST
=> training   97.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.431 Prec@5=93.784 rate=0.90 Hz, eta=0:01:56, total=1:31:11, wall=02:24 IST
=> training   97.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.118 DataTime=0.197 Loss=0.801 Prec@1=79.431 Prec@5=93.784 rate=0.90 Hz, eta=0:01:56, total=1:31:11, wall=02:26 IST
=> training   97.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.117 DataTime=0.197 Loss=0.801 Prec@1=79.425 Prec@5=93.785 rate=0.90 Hz, eta=0:01:56, total=1:31:11, wall=02:26 IST
=> training   99.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.117 DataTime=0.197 Loss=0.801 Prec@1=79.425 Prec@5=93.785 rate=0.90 Hz, eta=0:00:04, total=1:33:02, wall=02:26 IST
=> training   99.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.117 DataTime=0.197 Loss=0.801 Prec@1=79.425 Prec@5=93.785 rate=0.90 Hz, eta=0:00:04, total=1:33:02, wall=02:26 IST
=> training   99.92% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.117 DataTime=0.197 Loss=0.801 Prec@1=79.425 Prec@5=93.785 rate=0.90 Hz, eta=0:00:04, total=1:33:02, wall=02:26 IST
=> training   100.00% of 1x5005...Epoch=6/10 LR=0.00010 Time=1.117 DataTime=0.197 Loss=0.801 Prec@1=79.425 Prec@5=93.785 rate=0.90 Hz, eta=0:00:00, total=1:33:05, wall=02:26 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 8.000 8.000 8.000 2.000 4.000 8.000 8.000 4.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=02:26 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=02:26 IST
=> validation 0.00% of 1x196...Epoch=6/10 LR=0.00010 Time=7.564 Loss=1.030 Prec@1=74.609 Prec@5=91.797 rate=0 Hz, eta=?, total=0:00:00, wall=02:26 IST
=> validation 0.51% of 1x196...Epoch=6/10 LR=0.00010 Time=7.564 Loss=1.030 Prec@1=74.609 Prec@5=91.797 rate=6676.29 Hz, eta=0:00:00, total=0:00:00, wall=02:26 IST
=> validation 0.51% of 1x196...Epoch=6/10 LR=0.00010 Time=7.564 Loss=1.030 Prec@1=74.609 Prec@5=91.797 rate=6676.29 Hz, eta=0:00:00, total=0:00:00, wall=02:27 IST
=> validation 0.51% of 1x196...Epoch=6/10 LR=0.00010 Time=0.716 Loss=1.168 Prec@1=71.728 Prec@5=90.381 rate=6676.29 Hz, eta=0:00:00, total=0:00:00, wall=02:27 IST
=> validation 51.53% of 1x196...Epoch=6/10 LR=0.00010 Time=0.716 Loss=1.168 Prec@1=71.728 Prec@5=90.381 rate=1.56 Hz, eta=0:01:00, total=0:01:04, wall=02:27 IST
** validation 51.53% of 1x196...Epoch=6/10 LR=0.00010 Time=0.716 Loss=1.168 Prec@1=71.728 Prec@5=90.381 rate=1.56 Hz, eta=0:01:00, total=0:01:04, wall=02:28 IST
** validation 51.53% of 1x196...Epoch=6/10 LR=0.00010 Time=0.654 Loss=1.181 Prec@1=71.388 Prec@5=90.274 rate=1.56 Hz, eta=0:01:00, total=0:01:04, wall=02:28 IST
** validation 100.00% of 1x196...Epoch=6/10 LR=0.00010 Time=0.654 Loss=1.181 Prec@1=71.388 Prec@5=90.274 rate=1.62 Hz, eta=0:00:00, total=0:02:00, wall=02:28 IST
[39mFreezing ranges for subsequent epochs
[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=02:28 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=02:28 IST
=> training   0.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=6.233 DataTime=4.767 Loss=0.653 Prec@1=84.375 Prec@5=96.094 rate=0 Hz, eta=?, total=0:00:00, wall=02:28 IST
=> training   0.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=6.233 DataTime=4.767 Loss=0.653 Prec@1=84.375 Prec@5=96.094 rate=3400.96 Hz, eta=0:00:01, total=0:00:00, wall=02:28 IST
=> training   0.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=6.233 DataTime=4.767 Loss=0.653 Prec@1=84.375 Prec@5=96.094 rate=3400.96 Hz, eta=0:00:01, total=0:00:00, wall=02:30 IST
=> training   0.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.993 DataTime=0.241 Loss=0.796 Prec@1=79.761 Prec@5=93.843 rate=3400.96 Hz, eta=0:00:01, total=0:00:00, wall=02:30 IST
=> training   2.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.993 DataTime=0.241 Loss=0.796 Prec@1=79.761 Prec@5=93.843 rate=1.07 Hz, eta=1:16:05, total=0:01:34, wall=02:30 IST
=> training   2.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.993 DataTime=0.241 Loss=0.796 Prec@1=79.761 Prec@5=93.843 rate=1.07 Hz, eta=1:16:05, total=0:01:34, wall=02:32 IST
=> training   2.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.962 DataTime=0.219 Loss=0.804 Prec@1=79.437 Prec@5=93.791 rate=1.07 Hz, eta=1:16:05, total=0:01:34, wall=02:32 IST
=> training   4.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.962 DataTime=0.219 Loss=0.804 Prec@1=79.437 Prec@5=93.791 rate=1.07 Hz, eta=1:14:34, total=0:03:07, wall=02:32 IST
=> training   4.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.962 DataTime=0.219 Loss=0.804 Prec@1=79.437 Prec@5=93.791 rate=1.07 Hz, eta=1:14:34, total=0:03:07, wall=02:33 IST
=> training   4.02% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.951 DataTime=0.211 Loss=0.802 Prec@1=79.499 Prec@5=93.794 rate=1.07 Hz, eta=1:14:34, total=0:03:07, wall=02:33 IST
=> training   6.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.951 DataTime=0.211 Loss=0.802 Prec@1=79.499 Prec@5=93.794 rate=1.07 Hz, eta=1:12:56, total=0:04:40, wall=02:33 IST
=> training   6.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.951 DataTime=0.211 Loss=0.802 Prec@1=79.499 Prec@5=93.794 rate=1.07 Hz, eta=1:12:56, total=0:04:40, wall=02:35 IST
=> training   6.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.945 DataTime=0.208 Loss=0.800 Prec@1=79.544 Prec@5=93.794 rate=1.07 Hz, eta=1:12:56, total=0:04:40, wall=02:35 IST
=> training   8.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.945 DataTime=0.208 Loss=0.800 Prec@1=79.544 Prec@5=93.794 rate=1.08 Hz, eta=1:11:19, total=0:06:12, wall=02:35 IST
=> training   8.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.945 DataTime=0.208 Loss=0.800 Prec@1=79.544 Prec@5=93.794 rate=1.08 Hz, eta=1:11:19, total=0:06:12, wall=02:36 IST
=> training   8.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.942 DataTime=0.205 Loss=0.800 Prec@1=79.500 Prec@5=93.793 rate=1.08 Hz, eta=1:11:19, total=0:06:12, wall=02:36 IST
=> training   10.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.942 DataTime=0.205 Loss=0.800 Prec@1=79.500 Prec@5=93.793 rate=1.08 Hz, eta=1:09:46, total=0:07:45, wall=02:36 IST
=> training   10.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.942 DataTime=0.205 Loss=0.800 Prec@1=79.500 Prec@5=93.793 rate=1.08 Hz, eta=1:09:46, total=0:07:45, wall=02:38 IST
=> training   10.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.940 DataTime=0.204 Loss=0.801 Prec@1=79.493 Prec@5=93.773 rate=1.08 Hz, eta=1:09:46, total=0:07:45, wall=02:38 IST
=> training   12.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.940 DataTime=0.204 Loss=0.801 Prec@1=79.493 Prec@5=93.773 rate=1.08 Hz, eta=1:08:13, total=0:09:18, wall=02:38 IST
=> training   12.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.940 DataTime=0.204 Loss=0.801 Prec@1=79.493 Prec@5=93.773 rate=1.08 Hz, eta=1:08:13, total=0:09:18, wall=02:39 IST
=> training   12.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.938 DataTime=0.203 Loss=0.799 Prec@1=79.489 Prec@5=93.799 rate=1.08 Hz, eta=1:08:13, total=0:09:18, wall=02:39 IST
=> training   14.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.938 DataTime=0.203 Loss=0.799 Prec@1=79.489 Prec@5=93.799 rate=1.08 Hz, eta=1:06:39, total=0:10:51, wall=02:39 IST
=> training   14.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.938 DataTime=0.203 Loss=0.799 Prec@1=79.489 Prec@5=93.799 rate=1.08 Hz, eta=1:06:39, total=0:10:51, wall=02:41 IST
=> training   14.01% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.937 DataTime=0.202 Loss=0.798 Prec@1=79.507 Prec@5=93.814 rate=1.08 Hz, eta=1:06:39, total=0:10:51, wall=02:41 IST
=> training   16.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.937 DataTime=0.202 Loss=0.798 Prec@1=79.507 Prec@5=93.814 rate=1.08 Hz, eta=1:05:07, total=0:12:24, wall=02:41 IST
=> training   16.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.937 DataTime=0.202 Loss=0.798 Prec@1=79.507 Prec@5=93.814 rate=1.08 Hz, eta=1:05:07, total=0:12:24, wall=02:42 IST
=> training   16.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.937 DataTime=0.201 Loss=0.797 Prec@1=79.534 Prec@5=93.827 rate=1.08 Hz, eta=1:05:07, total=0:12:24, wall=02:42 IST
=> training   18.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.937 DataTime=0.201 Loss=0.797 Prec@1=79.534 Prec@5=93.827 rate=1.08 Hz, eta=1:03:35, total=0:13:57, wall=02:42 IST
=> training   18.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.937 DataTime=0.201 Loss=0.797 Prec@1=79.534 Prec@5=93.827 rate=1.08 Hz, eta=1:03:35, total=0:13:57, wall=02:44 IST
=> training   18.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.936 DataTime=0.201 Loss=0.797 Prec@1=79.549 Prec@5=93.840 rate=1.08 Hz, eta=1:03:35, total=0:13:57, wall=02:44 IST
=> training   20.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.936 DataTime=0.201 Loss=0.797 Prec@1=79.549 Prec@5=93.840 rate=1.08 Hz, eta=1:02:02, total=0:15:30, wall=02:44 IST
=> training   20.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.936 DataTime=0.201 Loss=0.797 Prec@1=79.549 Prec@5=93.840 rate=1.08 Hz, eta=1:02:02, total=0:15:30, wall=02:45 IST
=> training   20.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.935 DataTime=0.200 Loss=0.795 Prec@1=79.614 Prec@5=93.859 rate=1.08 Hz, eta=1:02:02, total=0:15:30, wall=02:45 IST
=> training   22.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.935 DataTime=0.200 Loss=0.795 Prec@1=79.614 Prec@5=93.859 rate=1.08 Hz, eta=1:00:29, total=0:17:03, wall=02:45 IST
=> training   22.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.935 DataTime=0.200 Loss=0.795 Prec@1=79.614 Prec@5=93.859 rate=1.08 Hz, eta=1:00:29, total=0:17:03, wall=02:47 IST
=> training   22.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.935 DataTime=0.200 Loss=0.794 Prec@1=79.628 Prec@5=93.879 rate=1.08 Hz, eta=1:00:29, total=0:17:03, wall=02:47 IST
=> training   24.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.935 DataTime=0.200 Loss=0.794 Prec@1=79.628 Prec@5=93.879 rate=1.08 Hz, eta=0:58:57, total=0:18:36, wall=02:47 IST
=> training   24.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.935 DataTime=0.200 Loss=0.794 Prec@1=79.628 Prec@5=93.879 rate=1.08 Hz, eta=0:58:57, total=0:18:36, wall=02:49 IST
=> training   24.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.200 Loss=0.793 Prec@1=79.642 Prec@5=93.893 rate=1.08 Hz, eta=0:58:57, total=0:18:36, wall=02:49 IST
=> training   25.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.200 Loss=0.793 Prec@1=79.642 Prec@5=93.893 rate=1.08 Hz, eta=0:57:22, total=0:20:09, wall=02:49 IST
=> training   25.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.200 Loss=0.793 Prec@1=79.642 Prec@5=93.893 rate=1.08 Hz, eta=0:57:22, total=0:20:09, wall=02:50 IST
=> training   25.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.200 Loss=0.792 Prec@1=79.640 Prec@5=93.901 rate=1.08 Hz, eta=0:57:22, total=0:20:09, wall=02:50 IST
=> training   27.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.200 Loss=0.792 Prec@1=79.640 Prec@5=93.901 rate=1.08 Hz, eta=0:55:50, total=0:21:42, wall=02:50 IST
=> training   27.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.200 Loss=0.792 Prec@1=79.640 Prec@5=93.901 rate=1.08 Hz, eta=0:55:50, total=0:21:42, wall=02:52 IST
=> training   27.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.199 Loss=0.792 Prec@1=79.637 Prec@5=93.906 rate=1.08 Hz, eta=0:55:50, total=0:21:42, wall=02:52 IST
=> training   29.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.199 Loss=0.792 Prec@1=79.637 Prec@5=93.906 rate=1.08 Hz, eta=0:54:17, total=0:23:15, wall=02:52 IST
=> training   29.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.934 DataTime=0.199 Loss=0.792 Prec@1=79.637 Prec@5=93.906 rate=1.08 Hz, eta=0:54:17, total=0:23:15, wall=02:53 IST
=> training   29.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.646 Prec@5=93.911 rate=1.08 Hz, eta=0:54:17, total=0:23:15, wall=02:53 IST
=> training   31.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.646 Prec@5=93.911 rate=1.08 Hz, eta=0:52:44, total=0:24:48, wall=02:53 IST
=> training   31.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.646 Prec@5=93.911 rate=1.08 Hz, eta=0:52:44, total=0:24:48, wall=02:55 IST
=> training   31.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.791 Prec@1=79.670 Prec@5=93.921 rate=1.08 Hz, eta=0:52:44, total=0:24:48, wall=02:55 IST
=> training   33.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.791 Prec@1=79.670 Prec@5=93.921 rate=1.08 Hz, eta=0:51:11, total=0:26:21, wall=02:55 IST
=> training   33.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.791 Prec@1=79.670 Prec@5=93.921 rate=1.08 Hz, eta=0:51:11, total=0:26:21, wall=02:56 IST
=> training   33.99% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.791 Prec@1=79.666 Prec@5=93.912 rate=1.08 Hz, eta=0:51:11, total=0:26:21, wall=02:56 IST
=> training   35.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.791 Prec@1=79.666 Prec@5=93.912 rate=1.08 Hz, eta=0:49:37, total=0:27:53, wall=02:56 IST
=> training   35.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.791 Prec@1=79.666 Prec@5=93.912 rate=1.08 Hz, eta=0:49:37, total=0:27:53, wall=02:58 IST
=> training   35.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.649 Prec@5=93.895 rate=1.08 Hz, eta=0:49:37, total=0:27:53, wall=02:58 IST
=> training   37.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.649 Prec@5=93.895 rate=1.08 Hz, eta=0:48:05, total=0:29:26, wall=02:58 IST
=> training   37.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.649 Prec@5=93.895 rate=1.08 Hz, eta=0:48:05, total=0:29:26, wall=02:59 IST
=> training   37.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.646 Prec@5=93.890 rate=1.08 Hz, eta=0:48:05, total=0:29:26, wall=02:59 IST
=> training   39.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.646 Prec@5=93.890 rate=1.08 Hz, eta=0:46:31, total=0:30:59, wall=02:59 IST
=> training   39.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.933 DataTime=0.199 Loss=0.792 Prec@1=79.646 Prec@5=93.890 rate=1.08 Hz, eta=0:46:31, total=0:30:59, wall=03:01 IST
=> training   39.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.660 Prec@5=93.883 rate=1.08 Hz, eta=0:46:31, total=0:30:59, wall=03:01 IST
=> training   41.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.660 Prec@5=93.883 rate=1.08 Hz, eta=0:44:58, total=0:32:32, wall=03:01 IST
=> training   41.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.660 Prec@5=93.883 rate=1.08 Hz, eta=0:44:58, total=0:32:32, wall=03:03 IST
=> training   41.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.663 Prec@5=93.890 rate=1.08 Hz, eta=0:44:58, total=0:32:32, wall=03:03 IST
=> training   43.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.663 Prec@5=93.890 rate=1.08 Hz, eta=0:43:25, total=0:34:05, wall=03:03 IST
=> training   43.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.663 Prec@5=93.890 rate=1.08 Hz, eta=0:43:25, total=0:34:05, wall=03:04 IST
=> training   43.98% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.667 Prec@5=93.892 rate=1.08 Hz, eta=0:43:25, total=0:34:05, wall=03:04 IST
=> training   45.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.667 Prec@5=93.892 rate=1.08 Hz, eta=0:41:52, total=0:35:38, wall=03:04 IST
=> training   45.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.667 Prec@5=93.892 rate=1.08 Hz, eta=0:41:52, total=0:35:38, wall=03:06 IST
=> training   45.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.669 Prec@5=93.884 rate=1.08 Hz, eta=0:41:52, total=0:35:38, wall=03:06 IST
=> training   47.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.669 Prec@5=93.884 rate=1.08 Hz, eta=0:40:19, total=0:37:11, wall=03:06 IST
=> training   47.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.669 Prec@5=93.884 rate=1.08 Hz, eta=0:40:19, total=0:37:11, wall=03:07 IST
=> training   47.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.676 Prec@5=93.879 rate=1.08 Hz, eta=0:40:19, total=0:37:11, wall=03:07 IST
=> training   49.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.676 Prec@5=93.879 rate=1.08 Hz, eta=0:38:46, total=0:38:43, wall=03:07 IST
=> training   49.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.676 Prec@5=93.879 rate=1.08 Hz, eta=0:38:46, total=0:38:43, wall=03:09 IST
=> training   49.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.687 Prec@5=93.876 rate=1.08 Hz, eta=0:38:46, total=0:38:43, wall=03:09 IST
=> training   51.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.687 Prec@5=93.876 rate=1.08 Hz, eta=0:37:13, total=0:40:16, wall=03:09 IST
=> training   51.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.932 DataTime=0.198 Loss=0.792 Prec@1=79.687 Prec@5=93.876 rate=1.08 Hz, eta=0:37:13, total=0:40:16, wall=03:10 IST
=> training   51.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.792 Prec@1=79.680 Prec@5=93.872 rate=1.08 Hz, eta=0:37:13, total=0:40:16, wall=03:10 IST
=> training   53.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.792 Prec@1=79.680 Prec@5=93.872 rate=1.08 Hz, eta=0:35:40, total=0:41:49, wall=03:10 IST
=> training   53.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.792 Prec@1=79.680 Prec@5=93.872 rate=1.08 Hz, eta=0:35:40, total=0:41:49, wall=03:12 IST
=> training   53.97% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.679 Prec@5=93.870 rate=1.08 Hz, eta=0:35:40, total=0:41:49, wall=03:12 IST
=> training   55.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.679 Prec@5=93.870 rate=1.08 Hz, eta=0:34:07, total=0:43:22, wall=03:12 IST
=> training   55.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.679 Prec@5=93.870 rate=1.08 Hz, eta=0:34:07, total=0:43:22, wall=03:13 IST
=> training   55.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.686 Prec@5=93.874 rate=1.08 Hz, eta=0:34:07, total=0:43:22, wall=03:13 IST
=> training   57.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.686 Prec@5=93.874 rate=1.08 Hz, eta=0:32:34, total=0:44:55, wall=03:13 IST
=> training   57.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.686 Prec@5=93.874 rate=1.08 Hz, eta=0:32:34, total=0:44:55, wall=03:15 IST
=> training   57.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.690 Prec@5=93.869 rate=1.08 Hz, eta=0:32:34, total=0:44:55, wall=03:15 IST
=> training   59.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.690 Prec@5=93.869 rate=1.08 Hz, eta=0:31:01, total=0:46:27, wall=03:15 IST
=> training   59.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.690 Prec@5=93.869 rate=1.08 Hz, eta=0:31:01, total=0:46:27, wall=03:16 IST
=> training   59.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.708 Prec@5=93.872 rate=1.08 Hz, eta=0:31:01, total=0:46:27, wall=03:16 IST
=> training   61.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.708 Prec@5=93.872 rate=1.08 Hz, eta=0:29:28, total=0:48:00, wall=03:16 IST
=> training   61.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.708 Prec@5=93.872 rate=1.08 Hz, eta=0:29:28, total=0:48:00, wall=03:18 IST
=> training   61.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.713 Prec@5=93.874 rate=1.08 Hz, eta=0:29:28, total=0:48:00, wall=03:18 IST
=> training   63.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.713 Prec@5=93.874 rate=1.08 Hz, eta=0:27:55, total=0:49:33, wall=03:18 IST
=> training   63.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.713 Prec@5=93.874 rate=1.08 Hz, eta=0:27:55, total=0:49:33, wall=03:20 IST
=> training   63.96% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.725 Prec@5=93.882 rate=1.08 Hz, eta=0:27:55, total=0:49:33, wall=03:20 IST
=> training   65.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.725 Prec@5=93.882 rate=1.08 Hz, eta=0:26:23, total=0:51:06, wall=03:20 IST
=> training   65.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.725 Prec@5=93.882 rate=1.08 Hz, eta=0:26:23, total=0:51:06, wall=03:21 IST
=> training   65.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.713 Prec@5=93.877 rate=1.08 Hz, eta=0:26:23, total=0:51:06, wall=03:21 IST
=> training   67.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.713 Prec@5=93.877 rate=1.08 Hz, eta=0:24:50, total=0:52:39, wall=03:21 IST
=> training   67.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.713 Prec@5=93.877 rate=1.08 Hz, eta=0:24:50, total=0:52:39, wall=03:23 IST
=> training   67.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.716 Prec@5=93.874 rate=1.08 Hz, eta=0:24:50, total=0:52:39, wall=03:23 IST
=> training   69.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.716 Prec@5=93.874 rate=1.08 Hz, eta=0:23:17, total=0:54:12, wall=03:23 IST
=> training   69.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.716 Prec@5=93.874 rate=1.08 Hz, eta=0:23:17, total=0:54:12, wall=03:24 IST
=> training   69.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.715 Prec@5=93.871 rate=1.08 Hz, eta=0:23:17, total=0:54:12, wall=03:24 IST
=> training   71.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.715 Prec@5=93.871 rate=1.08 Hz, eta=0:21:44, total=0:55:45, wall=03:24 IST
=> training   71.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.715 Prec@5=93.871 rate=1.08 Hz, eta=0:21:44, total=0:55:45, wall=03:26 IST
=> training   71.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.714 Prec@5=93.871 rate=1.08 Hz, eta=0:21:44, total=0:55:45, wall=03:26 IST
=> training   73.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.714 Prec@5=93.871 rate=1.08 Hz, eta=0:20:11, total=0:57:18, wall=03:26 IST
=> training   73.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.714 Prec@5=93.871 rate=1.08 Hz, eta=0:20:11, total=0:57:18, wall=03:27 IST
=> training   73.95% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.724 Prec@5=93.875 rate=1.08 Hz, eta=0:20:11, total=0:57:18, wall=03:27 IST
=> training   75.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.724 Prec@5=93.875 rate=1.08 Hz, eta=0:18:38, total=0:58:51, wall=03:27 IST
=> training   75.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.790 Prec@1=79.724 Prec@5=93.875 rate=1.08 Hz, eta=0:18:38, total=0:58:51, wall=03:29 IST
=> training   75.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.722 Prec@5=93.873 rate=1.08 Hz, eta=0:18:38, total=0:58:51, wall=03:29 IST
=> training   77.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.722 Prec@5=93.873 rate=1.08 Hz, eta=0:17:05, total=1:00:23, wall=03:29 IST
=> training   77.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.198 Loss=0.791 Prec@1=79.722 Prec@5=93.873 rate=1.08 Hz, eta=0:17:05, total=1:00:23, wall=03:30 IST
=> training   77.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.197 Loss=0.791 Prec@1=79.708 Prec@5=93.873 rate=1.08 Hz, eta=0:17:05, total=1:00:23, wall=03:30 IST
=> training   79.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.197 Loss=0.791 Prec@1=79.708 Prec@5=93.873 rate=1.08 Hz, eta=0:15:32, total=1:01:56, wall=03:30 IST
=> training   79.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.197 Loss=0.791 Prec@1=79.708 Prec@5=93.873 rate=1.08 Hz, eta=0:15:32, total=1:01:56, wall=03:32 IST
=> training   79.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.197 Loss=0.791 Prec@1=79.694 Prec@5=93.872 rate=1.08 Hz, eta=0:15:32, total=1:01:56, wall=03:32 IST
=> training   81.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.197 Loss=0.791 Prec@1=79.694 Prec@5=93.872 rate=1.08 Hz, eta=0:13:59, total=1:03:30, wall=03:32 IST
=> training   81.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.931 DataTime=0.197 Loss=0.791 Prec@1=79.694 Prec@5=93.872 rate=1.08 Hz, eta=0:13:59, total=1:03:30, wall=03:33 IST
=> training   81.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.685 Prec@5=93.869 rate=1.08 Hz, eta=0:13:59, total=1:03:30, wall=03:33 IST
=> training   83.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.685 Prec@5=93.869 rate=1.08 Hz, eta=0:12:26, total=1:05:02, wall=03:33 IST
=> training   83.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.685 Prec@5=93.869 rate=1.08 Hz, eta=0:12:26, total=1:05:02, wall=03:35 IST
=> training   83.94% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.866 rate=1.08 Hz, eta=0:12:26, total=1:05:02, wall=03:35 IST
=> training   85.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.866 rate=1.08 Hz, eta=0:10:54, total=1:06:35, wall=03:35 IST
=> training   85.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.866 rate=1.08 Hz, eta=0:10:54, total=1:06:35, wall=03:37 IST
=> training   85.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.678 Prec@5=93.862 rate=1.08 Hz, eta=0:10:54, total=1:06:35, wall=03:37 IST
=> training   87.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.678 Prec@5=93.862 rate=1.08 Hz, eta=0:09:21, total=1:08:08, wall=03:37 IST
=> training   87.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.678 Prec@5=93.862 rate=1.08 Hz, eta=0:09:21, total=1:08:08, wall=03:38 IST
=> training   87.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.680 Prec@5=93.866 rate=1.08 Hz, eta=0:09:21, total=1:08:08, wall=03:38 IST
=> training   89.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.680 Prec@5=93.866 rate=1.08 Hz, eta=0:07:48, total=1:09:41, wall=03:38 IST
=> training   89.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.680 Prec@5=93.866 rate=1.08 Hz, eta=0:07:48, total=1:09:41, wall=03:40 IST
=> training   89.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.867 rate=1.08 Hz, eta=0:07:48, total=1:09:41, wall=03:40 IST
=> training   91.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.867 rate=1.08 Hz, eta=0:06:15, total=1:11:14, wall=03:40 IST
=> training   91.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.867 rate=1.08 Hz, eta=0:06:15, total=1:11:14, wall=03:41 IST
=> training   91.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.865 rate=1.08 Hz, eta=0:06:15, total=1:11:14, wall=03:41 IST
=> training   93.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.865 rate=1.08 Hz, eta=0:04:42, total=1:12:47, wall=03:41 IST
=> training   93.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.679 Prec@5=93.865 rate=1.08 Hz, eta=0:04:42, total=1:12:47, wall=03:43 IST
=> training   93.93% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.683 Prec@5=93.865 rate=1.08 Hz, eta=0:04:42, total=1:12:47, wall=03:43 IST
=> training   95.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.683 Prec@5=93.865 rate=1.08 Hz, eta=0:03:09, total=1:14:20, wall=03:43 IST
=> training   95.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.683 Prec@5=93.865 rate=1.08 Hz, eta=0:03:09, total=1:14:20, wall=03:44 IST
=> training   95.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.676 Prec@5=93.863 rate=1.08 Hz, eta=0:03:09, total=1:14:20, wall=03:44 IST
=> training   97.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.676 Prec@5=93.863 rate=1.08 Hz, eta=0:01:36, total=1:15:53, wall=03:44 IST
=> training   97.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.676 Prec@5=93.863 rate=1.08 Hz, eta=0:01:36, total=1:15:53, wall=03:46 IST
=> training   97.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.675 Prec@5=93.863 rate=1.08 Hz, eta=0:01:36, total=1:15:53, wall=03:46 IST
=> training   99.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.675 Prec@5=93.863 rate=1.08 Hz, eta=0:00:03, total=1:17:25, wall=03:46 IST
=> training   99.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.675 Prec@5=93.863 rate=1.08 Hz, eta=0:00:03, total=1:17:25, wall=03:46 IST
=> training   99.92% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.676 Prec@5=93.864 rate=1.08 Hz, eta=0:00:03, total=1:17:25, wall=03:46 IST
=> training   100.00% of 1x5005...Epoch=7/10 LR=0.00003 Time=0.930 DataTime=0.197 Loss=0.792 Prec@1=79.676 Prec@5=93.864 rate=1.08 Hz, eta=0:00:00, total=1:17:28, wall=03:46 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 8.000 8.000 8.000 2.000 4.000 8.000 8.000 4.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=03:46 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=03:46 IST
=> validation 0.00% of 1x196...Epoch=7/10 LR=0.00003 Time=7.606 Loss=1.032 Prec@1=75.391 Prec@5=91.797 rate=0 Hz, eta=?, total=0:00:00, wall=03:46 IST
=> validation 0.51% of 1x196...Epoch=7/10 LR=0.00003 Time=7.606 Loss=1.032 Prec@1=75.391 Prec@5=91.797 rate=9581.85 Hz, eta=0:00:00, total=0:00:00, wall=03:46 IST
=> validation 0.51% of 1x196...Epoch=7/10 LR=0.00003 Time=7.606 Loss=1.032 Prec@1=75.391 Prec@5=91.797 rate=9581.85 Hz, eta=0:00:00, total=0:00:00, wall=03:47 IST
=> validation 0.51% of 1x196...Epoch=7/10 LR=0.00003 Time=0.709 Loss=1.187 Prec@1=71.345 Prec@5=90.184 rate=9581.85 Hz, eta=0:00:00, total=0:00:00, wall=03:47 IST
=> validation 51.53% of 1x196...Epoch=7/10 LR=0.00003 Time=0.709 Loss=1.187 Prec@1=71.345 Prec@5=90.184 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=03:47 IST
** validation 51.53% of 1x196...Epoch=7/10 LR=0.00003 Time=0.709 Loss=1.187 Prec@1=71.345 Prec@5=90.184 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=03:48 IST
** validation 51.53% of 1x196...Epoch=7/10 LR=0.00003 Time=0.648 Loss=1.184 Prec@1=71.462 Prec@5=90.304 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=03:48 IST
** validation 100.00% of 1x196...Epoch=7/10 LR=0.00003 Time=0.648 Loss=1.184 Prec@1=71.462 Prec@5=90.304 rate=1.64 Hz, eta=0:00:00, total=0:01:59, wall=03:48 IST
[39m[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=03:48 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=03:48 IST
=> training   0.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=6.494 DataTime=5.005 Loss=0.635 Prec@1=80.078 Prec@5=97.656 rate=0 Hz, eta=?, total=0:00:00, wall=03:48 IST
=> training   0.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=6.494 DataTime=5.005 Loss=0.635 Prec@1=80.078 Prec@5=97.656 rate=2027.26 Hz, eta=0:00:02, total=0:00:00, wall=03:48 IST
=> training   0.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=6.494 DataTime=5.005 Loss=0.635 Prec@1=80.078 Prec@5=97.656 rate=2027.26 Hz, eta=0:00:02, total=0:00:00, wall=03:50 IST
=> training   0.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.996 DataTime=0.243 Loss=0.797 Prec@1=79.591 Prec@5=93.963 rate=2027.26 Hz, eta=0:00:02, total=0:00:00, wall=03:50 IST
=> training   2.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.996 DataTime=0.243 Loss=0.797 Prec@1=79.591 Prec@5=93.963 rate=1.07 Hz, eta=1:16:07, total=0:01:34, wall=03:50 IST
=> training   2.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.996 DataTime=0.243 Loss=0.797 Prec@1=79.591 Prec@5=93.963 rate=1.07 Hz, eta=1:16:07, total=0:01:34, wall=03:51 IST
=> training   2.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.961 DataTime=0.220 Loss=0.793 Prec@1=79.680 Prec@5=93.917 rate=1.07 Hz, eta=1:16:07, total=0:01:34, wall=03:51 IST
=> training   4.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.961 DataTime=0.220 Loss=0.793 Prec@1=79.680 Prec@5=93.917 rate=1.08 Hz, eta=1:14:19, total=0:03:06, wall=03:51 IST
=> training   4.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.961 DataTime=0.220 Loss=0.793 Prec@1=79.680 Prec@5=93.917 rate=1.08 Hz, eta=1:14:19, total=0:03:06, wall=03:53 IST
=> training   4.02% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.951 DataTime=0.212 Loss=0.790 Prec@1=79.671 Prec@5=93.947 rate=1.08 Hz, eta=1:14:19, total=0:03:06, wall=03:53 IST
=> training   6.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.951 DataTime=0.212 Loss=0.790 Prec@1=79.671 Prec@5=93.947 rate=1.08 Hz, eta=1:12:50, total=0:04:39, wall=03:53 IST
=> training   6.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.951 DataTime=0.212 Loss=0.790 Prec@1=79.671 Prec@5=93.947 rate=1.08 Hz, eta=1:12:50, total=0:04:39, wall=03:54 IST
=> training   6.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.945 DataTime=0.208 Loss=0.789 Prec@1=79.686 Prec@5=93.963 rate=1.08 Hz, eta=1:12:50, total=0:04:39, wall=03:54 IST
=> training   8.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.945 DataTime=0.208 Loss=0.789 Prec@1=79.686 Prec@5=93.963 rate=1.08 Hz, eta=1:11:16, total=0:06:12, wall=03:54 IST
=> training   8.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.945 DataTime=0.208 Loss=0.789 Prec@1=79.686 Prec@5=93.963 rate=1.08 Hz, eta=1:11:16, total=0:06:12, wall=03:56 IST
=> training   8.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.942 DataTime=0.206 Loss=0.785 Prec@1=79.724 Prec@5=93.974 rate=1.08 Hz, eta=1:11:16, total=0:06:12, wall=03:56 IST
=> training   10.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.942 DataTime=0.206 Loss=0.785 Prec@1=79.724 Prec@5=93.974 rate=1.08 Hz, eta=1:09:42, total=0:07:45, wall=03:56 IST
=> training   10.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.942 DataTime=0.206 Loss=0.785 Prec@1=79.724 Prec@5=93.974 rate=1.08 Hz, eta=1:09:42, total=0:07:45, wall=03:58 IST
=> training   10.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.939 DataTime=0.204 Loss=0.789 Prec@1=79.692 Prec@5=93.920 rate=1.08 Hz, eta=1:09:42, total=0:07:45, wall=03:58 IST
=> training   12.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.939 DataTime=0.204 Loss=0.789 Prec@1=79.692 Prec@5=93.920 rate=1.08 Hz, eta=1:08:08, total=0:09:17, wall=03:58 IST
=> training   12.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.939 DataTime=0.204 Loss=0.789 Prec@1=79.692 Prec@5=93.920 rate=1.08 Hz, eta=1:08:08, total=0:09:17, wall=03:59 IST
=> training   12.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.938 DataTime=0.203 Loss=0.789 Prec@1=79.733 Prec@5=93.914 rate=1.08 Hz, eta=1:08:08, total=0:09:17, wall=03:59 IST
=> training   14.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.938 DataTime=0.203 Loss=0.789 Prec@1=79.733 Prec@5=93.914 rate=1.08 Hz, eta=1:06:35, total=0:10:50, wall=03:59 IST
=> training   14.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.938 DataTime=0.203 Loss=0.789 Prec@1=79.733 Prec@5=93.914 rate=1.08 Hz, eta=1:06:35, total=0:10:50, wall=04:01 IST
=> training   14.01% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.937 DataTime=0.202 Loss=0.787 Prec@1=79.775 Prec@5=93.948 rate=1.08 Hz, eta=1:06:35, total=0:10:50, wall=04:01 IST
=> training   16.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.937 DataTime=0.202 Loss=0.787 Prec@1=79.775 Prec@5=93.948 rate=1.08 Hz, eta=1:05:05, total=0:12:24, wall=04:01 IST
=> training   16.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.937 DataTime=0.202 Loss=0.787 Prec@1=79.775 Prec@5=93.948 rate=1.08 Hz, eta=1:05:05, total=0:12:24, wall=04:02 IST
=> training   16.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.936 DataTime=0.202 Loss=0.786 Prec@1=79.795 Prec@5=93.926 rate=1.08 Hz, eta=1:05:05, total=0:12:24, wall=04:02 IST
=> training   18.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.936 DataTime=0.202 Loss=0.786 Prec@1=79.795 Prec@5=93.926 rate=1.08 Hz, eta=1:03:32, total=0:13:56, wall=04:02 IST
=> training   18.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.936 DataTime=0.202 Loss=0.786 Prec@1=79.795 Prec@5=93.926 rate=1.08 Hz, eta=1:03:32, total=0:13:56, wall=04:04 IST
=> training   18.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.935 DataTime=0.201 Loss=0.786 Prec@1=79.777 Prec@5=93.955 rate=1.08 Hz, eta=1:03:32, total=0:13:56, wall=04:04 IST
=> training   20.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.935 DataTime=0.201 Loss=0.786 Prec@1=79.777 Prec@5=93.955 rate=1.08 Hz, eta=1:01:59, total=0:15:29, wall=04:04 IST
=> training   20.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.935 DataTime=0.201 Loss=0.786 Prec@1=79.777 Prec@5=93.955 rate=1.08 Hz, eta=1:01:59, total=0:15:29, wall=04:05 IST
=> training   20.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.935 DataTime=0.201 Loss=0.786 Prec@1=79.787 Prec@5=93.942 rate=1.08 Hz, eta=1:01:59, total=0:15:29, wall=04:05 IST
=> training   22.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.935 DataTime=0.201 Loss=0.786 Prec@1=79.787 Prec@5=93.942 rate=1.08 Hz, eta=1:00:26, total=0:17:02, wall=04:05 IST
=> training   22.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.935 DataTime=0.201 Loss=0.786 Prec@1=79.787 Prec@5=93.942 rate=1.08 Hz, eta=1:00:26, total=0:17:02, wall=04:07 IST
=> training   22.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.785 Prec@1=79.809 Prec@5=93.935 rate=1.08 Hz, eta=1:00:26, total=0:17:02, wall=04:07 IST
=> training   24.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.785 Prec@1=79.809 Prec@5=93.935 rate=1.08 Hz, eta=0:58:53, total=0:18:35, wall=04:07 IST
=> training   24.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.785 Prec@1=79.809 Prec@5=93.935 rate=1.08 Hz, eta=0:58:53, total=0:18:35, wall=04:08 IST
=> training   24.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.785 Prec@1=79.816 Prec@5=93.943 rate=1.08 Hz, eta=0:58:53, total=0:18:35, wall=04:08 IST
=> training   25.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.785 Prec@1=79.816 Prec@5=93.943 rate=1.08 Hz, eta=0:57:20, total=0:20:08, wall=04:08 IST
=> training   25.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.785 Prec@1=79.816 Prec@5=93.943 rate=1.08 Hz, eta=0:57:20, total=0:20:08, wall=04:10 IST
=> training   25.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.783 Prec@1=79.847 Prec@5=93.961 rate=1.08 Hz, eta=0:57:20, total=0:20:08, wall=04:10 IST
=> training   27.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.783 Prec@1=79.847 Prec@5=93.961 rate=1.08 Hz, eta=0:55:47, total=0:21:41, wall=04:10 IST
=> training   27.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.934 DataTime=0.200 Loss=0.783 Prec@1=79.847 Prec@5=93.961 rate=1.08 Hz, eta=0:55:47, total=0:21:41, wall=04:11 IST
=> training   27.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.933 DataTime=0.200 Loss=0.784 Prec@1=79.822 Prec@5=93.956 rate=1.08 Hz, eta=0:55:47, total=0:21:41, wall=04:11 IST
=> training   29.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.933 DataTime=0.200 Loss=0.784 Prec@1=79.822 Prec@5=93.956 rate=1.08 Hz, eta=0:54:13, total=0:23:13, wall=04:11 IST
=> training   29.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.933 DataTime=0.200 Loss=0.784 Prec@1=79.822 Prec@5=93.956 rate=1.08 Hz, eta=0:54:13, total=0:23:13, wall=04:13 IST
=> training   29.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.933 DataTime=0.199 Loss=0.785 Prec@1=79.801 Prec@5=93.948 rate=1.08 Hz, eta=0:54:13, total=0:23:13, wall=04:13 IST
=> training   31.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.933 DataTime=0.199 Loss=0.785 Prec@1=79.801 Prec@5=93.948 rate=1.08 Hz, eta=0:52:41, total=0:24:47, wall=04:13 IST
=> training   31.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.933 DataTime=0.199 Loss=0.785 Prec@1=79.801 Prec@5=93.948 rate=1.08 Hz, eta=0:52:41, total=0:24:47, wall=04:15 IST
=> training   31.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.788 Prec@5=93.941 rate=1.08 Hz, eta=0:52:41, total=0:24:47, wall=04:15 IST
=> training   33.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.788 Prec@5=93.941 rate=1.08 Hz, eta=0:51:08, total=0:26:19, wall=04:15 IST
=> training   33.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.788 Prec@5=93.941 rate=1.08 Hz, eta=0:51:08, total=0:26:19, wall=04:16 IST
=> training   33.99% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.773 Prec@5=93.943 rate=1.08 Hz, eta=0:51:08, total=0:26:19, wall=04:16 IST
=> training   35.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.773 Prec@5=93.943 rate=1.08 Hz, eta=0:49:35, total=0:27:52, wall=04:16 IST
=> training   35.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.773 Prec@5=93.943 rate=1.08 Hz, eta=0:49:35, total=0:27:52, wall=04:18 IST
=> training   35.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.787 Prec@1=79.756 Prec@5=93.937 rate=1.08 Hz, eta=0:49:35, total=0:27:52, wall=04:18 IST
=> training   37.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.787 Prec@1=79.756 Prec@5=93.937 rate=1.08 Hz, eta=0:48:03, total=0:29:25, wall=04:18 IST
=> training   37.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.787 Prec@1=79.756 Prec@5=93.937 rate=1.08 Hz, eta=0:48:03, total=0:29:25, wall=04:19 IST
=> training   37.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.768 Prec@5=93.942 rate=1.08 Hz, eta=0:48:03, total=0:29:25, wall=04:19 IST
=> training   39.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.768 Prec@5=93.942 rate=1.08 Hz, eta=0:46:30, total=0:30:58, wall=04:19 IST
=> training   39.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.768 Prec@5=93.942 rate=1.08 Hz, eta=0:46:30, total=0:30:58, wall=04:21 IST
=> training   39.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.787 Prec@1=79.755 Prec@5=93.939 rate=1.08 Hz, eta=0:46:30, total=0:30:58, wall=04:21 IST
=> training   41.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.787 Prec@1=79.755 Prec@5=93.939 rate=1.08 Hz, eta=0:44:57, total=0:32:31, wall=04:21 IST
=> training   41.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.787 Prec@1=79.755 Prec@5=93.939 rate=1.08 Hz, eta=0:44:57, total=0:32:31, wall=04:22 IST
=> training   41.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.764 Prec@5=93.946 rate=1.08 Hz, eta=0:44:57, total=0:32:31, wall=04:22 IST
=> training   43.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.764 Prec@5=93.946 rate=1.08 Hz, eta=0:43:24, total=0:34:04, wall=04:22 IST
=> training   43.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.199 Loss=0.786 Prec@1=79.764 Prec@5=93.946 rate=1.08 Hz, eta=0:43:24, total=0:34:04, wall=04:24 IST
=> training   43.98% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.786 Prec@1=79.758 Prec@5=93.951 rate=1.08 Hz, eta=0:43:24, total=0:34:04, wall=04:24 IST
=> training   45.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.786 Prec@1=79.758 Prec@5=93.951 rate=1.08 Hz, eta=0:41:51, total=0:35:37, wall=04:24 IST
=> training   45.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.786 Prec@1=79.758 Prec@5=93.951 rate=1.08 Hz, eta=0:41:51, total=0:35:37, wall=04:25 IST
=> training   45.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.762 Prec@5=93.954 rate=1.08 Hz, eta=0:41:51, total=0:35:37, wall=04:25 IST
=> training   47.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.762 Prec@5=93.954 rate=1.08 Hz, eta=0:40:18, total=0:37:10, wall=04:25 IST
=> training   47.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.762 Prec@5=93.954 rate=1.08 Hz, eta=0:40:18, total=0:37:10, wall=04:27 IST
=> training   47.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.773 Prec@5=93.957 rate=1.08 Hz, eta=0:40:18, total=0:37:10, wall=04:27 IST
=> training   49.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.773 Prec@5=93.957 rate=1.08 Hz, eta=0:38:46, total=0:38:43, wall=04:27 IST
=> training   49.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.773 Prec@5=93.957 rate=1.08 Hz, eta=0:38:46, total=0:38:43, wall=04:28 IST
=> training   49.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.785 Prec@5=93.962 rate=1.08 Hz, eta=0:38:46, total=0:38:43, wall=04:28 IST
=> training   51.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.785 Prec@5=93.962 rate=1.08 Hz, eta=0:37:13, total=0:40:16, wall=04:28 IST
=> training   51.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.932 DataTime=0.198 Loss=0.785 Prec@1=79.785 Prec@5=93.962 rate=1.08 Hz, eta=0:37:13, total=0:40:16, wall=04:30 IST
=> training   51.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.788 Prec@5=93.955 rate=1.08 Hz, eta=0:37:13, total=0:40:16, wall=04:30 IST
=> training   53.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.788 Prec@5=93.955 rate=1.08 Hz, eta=0:35:40, total=0:41:49, wall=04:30 IST
=> training   53.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.788 Prec@5=93.955 rate=1.08 Hz, eta=0:35:40, total=0:41:49, wall=04:32 IST
=> training   53.97% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.785 Prec@5=93.948 rate=1.08 Hz, eta=0:35:40, total=0:41:49, wall=04:32 IST
=> training   55.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.785 Prec@5=93.948 rate=1.08 Hz, eta=0:34:07, total=0:43:21, wall=04:32 IST
=> training   55.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.785 Prec@5=93.948 rate=1.08 Hz, eta=0:34:07, total=0:43:21, wall=04:33 IST
=> training   55.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.790 Prec@5=93.938 rate=1.08 Hz, eta=0:34:07, total=0:43:21, wall=04:33 IST
=> training   57.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.790 Prec@5=93.938 rate=1.08 Hz, eta=0:32:34, total=0:44:55, wall=04:33 IST
=> training   57.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.790 Prec@5=93.938 rate=1.08 Hz, eta=0:32:34, total=0:44:55, wall=04:35 IST
=> training   57.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.788 Prec@5=93.931 rate=1.08 Hz, eta=0:32:34, total=0:44:55, wall=04:35 IST
=> training   59.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.788 Prec@5=93.931 rate=1.08 Hz, eta=0:31:01, total=0:46:27, wall=04:35 IST
=> training   59.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.788 Prec@5=93.931 rate=1.08 Hz, eta=0:31:01, total=0:46:27, wall=04:36 IST
=> training   59.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.782 Prec@5=93.929 rate=1.08 Hz, eta=0:31:01, total=0:46:27, wall=04:36 IST
=> training   61.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.782 Prec@5=93.929 rate=1.08 Hz, eta=0:29:28, total=0:48:00, wall=04:36 IST
=> training   61.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.782 Prec@5=93.929 rate=1.08 Hz, eta=0:29:28, total=0:48:00, wall=04:38 IST
=> training   61.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.790 Prec@5=93.933 rate=1.08 Hz, eta=0:29:28, total=0:48:00, wall=04:38 IST
=> training   63.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.790 Prec@5=93.933 rate=1.08 Hz, eta=0:27:55, total=0:49:33, wall=04:38 IST
=> training   63.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.790 Prec@5=93.933 rate=1.08 Hz, eta=0:27:55, total=0:49:33, wall=04:39 IST
=> training   63.96% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.798 Prec@5=93.929 rate=1.08 Hz, eta=0:27:55, total=0:49:33, wall=04:39 IST
=> training   65.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.798 Prec@5=93.929 rate=1.08 Hz, eta=0:26:23, total=0:51:06, wall=04:39 IST
=> training   65.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.798 Prec@5=93.929 rate=1.08 Hz, eta=0:26:23, total=0:51:06, wall=04:41 IST
=> training   65.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.800 Prec@5=93.931 rate=1.08 Hz, eta=0:26:23, total=0:51:06, wall=04:41 IST
=> training   67.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.800 Prec@5=93.931 rate=1.08 Hz, eta=0:24:50, total=0:52:39, wall=04:41 IST
=> training   67.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.800 Prec@5=93.931 rate=1.08 Hz, eta=0:24:50, total=0:52:39, wall=04:42 IST
=> training   67.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.801 Prec@5=93.930 rate=1.08 Hz, eta=0:24:50, total=0:52:39, wall=04:42 IST
=> training   69.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.801 Prec@5=93.930 rate=1.08 Hz, eta=0:23:17, total=0:54:12, wall=04:42 IST
=> training   69.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.801 Prec@5=93.930 rate=1.08 Hz, eta=0:23:17, total=0:54:12, wall=04:44 IST
=> training   69.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.796 Prec@5=93.928 rate=1.08 Hz, eta=0:23:17, total=0:54:12, wall=04:44 IST
=> training   71.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.796 Prec@5=93.928 rate=1.08 Hz, eta=0:21:44, total=0:55:45, wall=04:44 IST
=> training   71.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.796 Prec@5=93.928 rate=1.08 Hz, eta=0:21:44, total=0:55:45, wall=04:46 IST
=> training   71.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.805 Prec@5=93.930 rate=1.08 Hz, eta=0:21:44, total=0:55:45, wall=04:46 IST
=> training   73.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.805 Prec@5=93.930 rate=1.08 Hz, eta=0:20:11, total=0:57:18, wall=04:46 IST
=> training   73.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.805 Prec@5=93.930 rate=1.08 Hz, eta=0:20:11, total=0:57:18, wall=04:47 IST
=> training   73.95% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.803 Prec@5=93.934 rate=1.08 Hz, eta=0:20:11, total=0:57:18, wall=04:47 IST
=> training   75.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.803 Prec@5=93.934 rate=1.08 Hz, eta=0:18:38, total=0:58:51, wall=04:47 IST
=> training   75.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.803 Prec@5=93.934 rate=1.08 Hz, eta=0:18:38, total=0:58:51, wall=04:49 IST
=> training   75.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.803 Prec@5=93.937 rate=1.08 Hz, eta=0:18:38, total=0:58:51, wall=04:49 IST
=> training   77.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.803 Prec@5=93.937 rate=1.08 Hz, eta=0:17:05, total=1:00:24, wall=04:49 IST
=> training   77.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.785 Prec@1=79.803 Prec@5=93.937 rate=1.08 Hz, eta=0:17:05, total=1:00:24, wall=04:50 IST
=> training   77.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.791 Prec@5=93.925 rate=1.08 Hz, eta=0:17:05, total=1:00:24, wall=04:50 IST
=> training   79.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.791 Prec@5=93.925 rate=1.08 Hz, eta=0:15:32, total=1:01:56, wall=04:50 IST
=> training   79.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.791 Prec@5=93.925 rate=1.08 Hz, eta=0:15:32, total=1:01:56, wall=04:52 IST
=> training   79.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.798 Prec@5=93.931 rate=1.08 Hz, eta=0:15:32, total=1:01:56, wall=04:52 IST
=> training   81.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.798 Prec@5=93.931 rate=1.08 Hz, eta=0:13:59, total=1:03:30, wall=04:52 IST
=> training   81.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.198 Loss=0.786 Prec@1=79.798 Prec@5=93.931 rate=1.08 Hz, eta=0:13:59, total=1:03:30, wall=04:53 IST
=> training   81.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.796 Prec@5=93.933 rate=1.08 Hz, eta=0:13:59, total=1:03:30, wall=04:53 IST
=> training   83.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.796 Prec@5=93.933 rate=1.08 Hz, eta=0:12:27, total=1:05:03, wall=04:53 IST
=> training   83.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.796 Prec@5=93.933 rate=1.08 Hz, eta=0:12:27, total=1:05:03, wall=04:55 IST
=> training   83.94% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.799 Prec@5=93.929 rate=1.08 Hz, eta=0:12:27, total=1:05:03, wall=04:55 IST
=> training   85.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.799 Prec@5=93.929 rate=1.08 Hz, eta=0:10:54, total=1:06:36, wall=04:55 IST
=> training   85.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.799 Prec@5=93.929 rate=1.08 Hz, eta=0:10:54, total=1:06:36, wall=04:56 IST
=> training   85.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.791 Prec@5=93.928 rate=1.08 Hz, eta=0:10:54, total=1:06:36, wall=04:56 IST
=> training   87.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.791 Prec@5=93.928 rate=1.08 Hz, eta=0:09:21, total=1:08:09, wall=04:56 IST
=> training   87.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.791 Prec@5=93.928 rate=1.08 Hz, eta=0:09:21, total=1:08:09, wall=04:58 IST
=> training   87.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.799 Prec@5=93.929 rate=1.08 Hz, eta=0:09:21, total=1:08:09, wall=04:58 IST
=> training   89.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.799 Prec@5=93.929 rate=1.08 Hz, eta=0:07:48, total=1:09:42, wall=04:58 IST
=> training   89.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.799 Prec@5=93.929 rate=1.08 Hz, eta=0:07:48, total=1:09:42, wall=04:59 IST
=> training   89.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.793 Prec@5=93.927 rate=1.08 Hz, eta=0:07:48, total=1:09:42, wall=04:59 IST
=> training   91.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.793 Prec@5=93.927 rate=1.08 Hz, eta=0:06:15, total=1:11:15, wall=04:59 IST
=> training   91.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.785 Prec@1=79.793 Prec@5=93.927 rate=1.08 Hz, eta=0:06:15, total=1:11:15, wall=05:01 IST
=> training   91.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.786 Prec@5=93.920 rate=1.08 Hz, eta=0:06:15, total=1:11:15, wall=05:01 IST
=> training   93.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.786 Prec@5=93.920 rate=1.08 Hz, eta=0:04:42, total=1:12:48, wall=05:01 IST
=> training   93.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.786 Prec@5=93.920 rate=1.08 Hz, eta=0:04:42, total=1:12:48, wall=05:03 IST
=> training   93.93% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.782 Prec@5=93.915 rate=1.08 Hz, eta=0:04:42, total=1:12:48, wall=05:03 IST
=> training   95.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.782 Prec@5=93.915 rate=1.08 Hz, eta=0:03:09, total=1:14:20, wall=05:03 IST
=> training   95.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.782 Prec@5=93.915 rate=1.08 Hz, eta=0:03:09, total=1:14:20, wall=05:04 IST
=> training   95.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.786 Prec@5=93.915 rate=1.08 Hz, eta=0:03:09, total=1:14:20, wall=05:04 IST
=> training   97.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.786 Prec@5=93.915 rate=1.08 Hz, eta=0:01:36, total=1:15:53, wall=05:04 IST
=> training   97.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.931 DataTime=0.197 Loss=0.786 Prec@1=79.786 Prec@5=93.915 rate=1.08 Hz, eta=0:01:36, total=1:15:53, wall=05:06 IST
=> training   97.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.930 DataTime=0.197 Loss=0.786 Prec@1=79.785 Prec@5=93.907 rate=1.08 Hz, eta=0:01:36, total=1:15:53, wall=05:06 IST
=> training   99.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.930 DataTime=0.197 Loss=0.786 Prec@1=79.785 Prec@5=93.907 rate=1.08 Hz, eta=0:00:03, total=1:17:26, wall=05:06 IST
=> training   99.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.930 DataTime=0.197 Loss=0.786 Prec@1=79.785 Prec@5=93.907 rate=1.08 Hz, eta=0:00:03, total=1:17:26, wall=05:06 IST
=> training   99.92% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.930 DataTime=0.197 Loss=0.786 Prec@1=79.786 Prec@5=93.907 rate=1.08 Hz, eta=0:00:03, total=1:17:26, wall=05:06 IST
=> training   100.00% of 1x5005...Epoch=8/10 LR=0.00002 Time=0.930 DataTime=0.197 Loss=0.786 Prec@1=79.786 Prec@5=93.907 rate=1.08 Hz, eta=0:00:00, total=1:17:29, wall=05:06 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 8.000 8.000 8.000 2.000 4.000 8.000 8.000 4.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=05:06 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=05:06 IST
=> validation 0.00% of 1x196...Epoch=8/10 LR=0.00002 Time=7.544 Loss=1.055 Prec@1=73.828 Prec@5=91.016 rate=0 Hz, eta=?, total=0:00:00, wall=05:06 IST
=> validation 0.51% of 1x196...Epoch=8/10 LR=0.00002 Time=7.544 Loss=1.055 Prec@1=73.828 Prec@5=91.016 rate=7647.46 Hz, eta=0:00:00, total=0:00:00, wall=05:06 IST
=> validation 0.51% of 1x196...Epoch=8/10 LR=0.00002 Time=7.544 Loss=1.055 Prec@1=73.828 Prec@5=91.016 rate=7647.46 Hz, eta=0:00:00, total=0:00:00, wall=05:07 IST
=> validation 0.51% of 1x196...Epoch=8/10 LR=0.00002 Time=0.711 Loss=1.178 Prec@1=71.527 Prec@5=90.250 rate=7647.46 Hz, eta=0:00:00, total=0:00:00, wall=05:07 IST
=> validation 51.53% of 1x196...Epoch=8/10 LR=0.00002 Time=0.711 Loss=1.178 Prec@1=71.527 Prec@5=90.250 rate=1.57 Hz, eta=0:01:00, total=0:01:04, wall=05:07 IST
** validation 51.53% of 1x196...Epoch=8/10 LR=0.00002 Time=0.711 Loss=1.178 Prec@1=71.527 Prec@5=90.250 rate=1.57 Hz, eta=0:01:00, total=0:01:04, wall=05:08 IST
** validation 51.53% of 1x196...Epoch=8/10 LR=0.00002 Time=0.652 Loss=1.170 Prec@1=71.576 Prec@5=90.342 rate=1.57 Hz, eta=0:01:00, total=0:01:04, wall=05:08 IST
** validation 100.00% of 1x196...Epoch=8/10 LR=0.00002 Time=0.652 Loss=1.170 Prec@1=71.576 Prec@5=90.342 rate=1.63 Hz, eta=0:00:00, total=0:02:00, wall=05:08 IST
[39m[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=05:08 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=05:08 IST
=> training   0.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=6.257 DataTime=4.424 Loss=0.958 Prec@1=76.562 Prec@5=89.844 rate=0 Hz, eta=?, total=0:00:00, wall=05:08 IST
=> training   0.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=6.257 DataTime=4.424 Loss=0.958 Prec@1=76.562 Prec@5=89.844 rate=3627.78 Hz, eta=0:00:01, total=0:00:00, wall=05:08 IST
=> training   0.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=6.257 DataTime=4.424 Loss=0.958 Prec@1=76.562 Prec@5=89.844 rate=3627.78 Hz, eta=0:00:01, total=0:00:00, wall=05:10 IST
=> training   0.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.995 DataTime=0.238 Loss=0.790 Prec@1=79.633 Prec@5=93.862 rate=3627.78 Hz, eta=0:00:01, total=0:00:00, wall=05:10 IST
=> training   2.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.995 DataTime=0.238 Loss=0.790 Prec@1=79.633 Prec@5=93.862 rate=1.07 Hz, eta=1:16:15, total=0:01:34, wall=05:10 IST
=> training   2.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.995 DataTime=0.238 Loss=0.790 Prec@1=79.633 Prec@5=93.862 rate=1.07 Hz, eta=1:16:15, total=0:01:34, wall=05:11 IST
=> training   2.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.964 DataTime=0.217 Loss=0.782 Prec@1=79.923 Prec@5=93.942 rate=1.07 Hz, eta=1:16:15, total=0:01:34, wall=05:11 IST
=> training   4.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.964 DataTime=0.217 Loss=0.782 Prec@1=79.923 Prec@5=93.942 rate=1.07 Hz, eta=1:14:39, total=0:03:07, wall=05:11 IST
=> training   4.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.964 DataTime=0.217 Loss=0.782 Prec@1=79.923 Prec@5=93.942 rate=1.07 Hz, eta=1:14:39, total=0:03:07, wall=05:13 IST
=> training   4.02% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.952 DataTime=0.210 Loss=0.790 Prec@1=79.704 Prec@5=93.908 rate=1.07 Hz, eta=1:14:39, total=0:03:07, wall=05:13 IST
=> training   6.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.952 DataTime=0.210 Loss=0.790 Prec@1=79.704 Prec@5=93.908 rate=1.07 Hz, eta=1:13:01, total=0:04:40, wall=05:13 IST
=> training   6.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.952 DataTime=0.210 Loss=0.790 Prec@1=79.704 Prec@5=93.908 rate=1.07 Hz, eta=1:13:01, total=0:04:40, wall=05:14 IST
=> training   6.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.952 DataTime=0.207 Loss=0.786 Prec@1=79.737 Prec@5=93.933 rate=1.07 Hz, eta=1:13:01, total=0:04:40, wall=05:14 IST
=> training   8.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.952 DataTime=0.207 Loss=0.786 Prec@1=79.737 Prec@5=93.933 rate=1.07 Hz, eta=1:11:49, total=0:06:15, wall=05:14 IST
=> training   8.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.952 DataTime=0.207 Loss=0.786 Prec@1=79.737 Prec@5=93.933 rate=1.07 Hz, eta=1:11:49, total=0:06:15, wall=05:16 IST
=> training   8.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.948 DataTime=0.205 Loss=0.785 Prec@1=79.768 Prec@5=93.970 rate=1.07 Hz, eta=1:11:49, total=0:06:15, wall=05:16 IST
=> training   10.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.948 DataTime=0.205 Loss=0.785 Prec@1=79.768 Prec@5=93.970 rate=1.07 Hz, eta=1:10:12, total=0:07:48, wall=05:16 IST
=> training   10.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.948 DataTime=0.205 Loss=0.785 Prec@1=79.768 Prec@5=93.970 rate=1.07 Hz, eta=1:10:12, total=0:07:48, wall=05:17 IST
=> training   10.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.945 DataTime=0.203 Loss=0.782 Prec@1=79.829 Prec@5=93.989 rate=1.07 Hz, eta=1:10:12, total=0:07:48, wall=05:17 IST
=> training   12.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.945 DataTime=0.203 Loss=0.782 Prec@1=79.829 Prec@5=93.989 rate=1.07 Hz, eta=1:08:36, total=0:09:21, wall=05:17 IST
=> training   12.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.945 DataTime=0.203 Loss=0.782 Prec@1=79.829 Prec@5=93.989 rate=1.07 Hz, eta=1:08:36, total=0:09:21, wall=05:19 IST
=> training   12.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.944 DataTime=0.202 Loss=0.781 Prec@1=79.846 Prec@5=94.008 rate=1.07 Hz, eta=1:08:36, total=0:09:21, wall=05:19 IST
=> training   14.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.944 DataTime=0.202 Loss=0.781 Prec@1=79.846 Prec@5=94.008 rate=1.07 Hz, eta=1:07:03, total=0:10:55, wall=05:19 IST
=> training   14.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.944 DataTime=0.202 Loss=0.781 Prec@1=79.846 Prec@5=94.008 rate=1.07 Hz, eta=1:07:03, total=0:10:55, wall=05:21 IST
=> training   14.01% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.942 DataTime=0.202 Loss=0.781 Prec@1=79.877 Prec@5=93.996 rate=1.07 Hz, eta=1:07:03, total=0:10:55, wall=05:21 IST
=> training   16.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.942 DataTime=0.202 Loss=0.781 Prec@1=79.877 Prec@5=93.996 rate=1.07 Hz, eta=1:05:26, total=0:12:28, wall=05:21 IST
=> training   16.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.942 DataTime=0.202 Loss=0.781 Prec@1=79.877 Prec@5=93.996 rate=1.07 Hz, eta=1:05:26, total=0:12:28, wall=05:22 IST
=> training   16.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.940 DataTime=0.201 Loss=0.779 Prec@1=79.907 Prec@5=94.014 rate=1.07 Hz, eta=1:05:26, total=0:12:28, wall=05:22 IST
=> training   18.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.940 DataTime=0.201 Loss=0.779 Prec@1=79.907 Prec@5=94.014 rate=1.07 Hz, eta=1:03:51, total=0:14:01, wall=05:22 IST
=> training   18.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.940 DataTime=0.201 Loss=0.779 Prec@1=79.907 Prec@5=94.014 rate=1.07 Hz, eta=1:03:51, total=0:14:01, wall=05:24 IST
=> training   18.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.939 DataTime=0.201 Loss=0.780 Prec@1=79.874 Prec@5=93.998 rate=1.07 Hz, eta=1:03:51, total=0:14:01, wall=05:24 IST
=> training   20.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.939 DataTime=0.201 Loss=0.780 Prec@1=79.874 Prec@5=93.998 rate=1.07 Hz, eta=1:02:16, total=0:15:34, wall=05:24 IST
=> training   20.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.939 DataTime=0.201 Loss=0.780 Prec@1=79.874 Prec@5=93.998 rate=1.07 Hz, eta=1:02:16, total=0:15:34, wall=05:25 IST
=> training   20.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.939 DataTime=0.200 Loss=0.781 Prec@1=79.837 Prec@5=93.995 rate=1.07 Hz, eta=1:02:16, total=0:15:34, wall=05:25 IST
=> training   22.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.939 DataTime=0.200 Loss=0.781 Prec@1=79.837 Prec@5=93.995 rate=1.07 Hz, eta=1:00:41, total=0:17:07, wall=05:25 IST
=> training   22.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.939 DataTime=0.200 Loss=0.781 Prec@1=79.837 Prec@5=93.995 rate=1.07 Hz, eta=1:00:41, total=0:17:07, wall=05:27 IST
=> training   22.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.938 DataTime=0.200 Loss=0.780 Prec@1=79.846 Prec@5=94.016 rate=1.07 Hz, eta=1:00:41, total=0:17:07, wall=05:27 IST
=> training   24.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.938 DataTime=0.200 Loss=0.780 Prec@1=79.846 Prec@5=94.016 rate=1.07 Hz, eta=0:59:08, total=0:18:40, wall=05:27 IST
=> training   24.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.938 DataTime=0.200 Loss=0.780 Prec@1=79.846 Prec@5=94.016 rate=1.07 Hz, eta=0:59:08, total=0:18:40, wall=05:28 IST
=> training   24.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.200 Loss=0.781 Prec@1=79.826 Prec@5=94.001 rate=1.07 Hz, eta=0:59:08, total=0:18:40, wall=05:28 IST
=> training   25.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.200 Loss=0.781 Prec@1=79.826 Prec@5=94.001 rate=1.07 Hz, eta=0:57:34, total=0:20:13, wall=05:28 IST
=> training   25.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.200 Loss=0.781 Prec@1=79.826 Prec@5=94.001 rate=1.07 Hz, eta=0:57:34, total=0:20:13, wall=05:30 IST
=> training   25.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.199 Loss=0.781 Prec@1=79.848 Prec@5=94.001 rate=1.07 Hz, eta=0:57:34, total=0:20:13, wall=05:30 IST
=> training   27.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.199 Loss=0.781 Prec@1=79.848 Prec@5=94.001 rate=1.07 Hz, eta=0:56:00, total=0:21:46, wall=05:30 IST
=> training   27.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.199 Loss=0.781 Prec@1=79.848 Prec@5=94.001 rate=1.07 Hz, eta=0:56:00, total=0:21:46, wall=05:31 IST
=> training   27.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.199 Loss=0.781 Prec@1=79.867 Prec@5=94.007 rate=1.07 Hz, eta=0:56:00, total=0:21:46, wall=05:31 IST
=> training   29.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.199 Loss=0.781 Prec@1=79.867 Prec@5=94.007 rate=1.07 Hz, eta=0:54:27, total=0:23:19, wall=05:31 IST
=> training   29.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.937 DataTime=0.199 Loss=0.781 Prec@1=79.867 Prec@5=94.007 rate=1.07 Hz, eta=0:54:27, total=0:23:19, wall=05:33 IST
=> training   29.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.782 Prec@1=79.830 Prec@5=93.983 rate=1.07 Hz, eta=0:54:27, total=0:23:19, wall=05:33 IST
=> training   31.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.782 Prec@1=79.830 Prec@5=93.983 rate=1.07 Hz, eta=0:52:53, total=0:24:52, wall=05:33 IST
=> training   31.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.782 Prec@1=79.830 Prec@5=93.983 rate=1.07 Hz, eta=0:52:53, total=0:24:52, wall=05:34 IST
=> training   31.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.829 Prec@5=93.992 rate=1.07 Hz, eta=0:52:53, total=0:24:52, wall=05:34 IST
=> training   33.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.829 Prec@5=93.992 rate=1.07 Hz, eta=0:51:20, total=0:26:25, wall=05:34 IST
=> training   33.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.829 Prec@5=93.992 rate=1.07 Hz, eta=0:51:20, total=0:26:25, wall=05:36 IST
=> training   33.99% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.836 Prec@5=93.995 rate=1.07 Hz, eta=0:51:20, total=0:26:25, wall=05:36 IST
=> training   35.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.836 Prec@5=93.995 rate=1.07 Hz, eta=0:49:47, total=0:27:59, wall=05:36 IST
=> training   35.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.836 Prec@5=93.995 rate=1.07 Hz, eta=0:49:47, total=0:27:59, wall=05:38 IST
=> training   35.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.843 Prec@5=93.991 rate=1.07 Hz, eta=0:49:47, total=0:27:59, wall=05:38 IST
=> training   37.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.843 Prec@5=93.991 rate=1.07 Hz, eta=0:48:14, total=0:29:32, wall=05:38 IST
=> training   37.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.199 Loss=0.781 Prec@1=79.843 Prec@5=93.991 rate=1.07 Hz, eta=0:48:14, total=0:29:32, wall=05:39 IST
=> training   37.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.198 Loss=0.781 Prec@1=79.850 Prec@5=93.992 rate=1.07 Hz, eta=0:48:14, total=0:29:32, wall=05:39 IST
=> training   39.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.198 Loss=0.781 Prec@1=79.850 Prec@5=93.992 rate=1.07 Hz, eta=0:46:41, total=0:31:05, wall=05:39 IST
=> training   39.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.198 Loss=0.781 Prec@1=79.850 Prec@5=93.992 rate=1.07 Hz, eta=0:46:41, total=0:31:05, wall=05:41 IST
=> training   39.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.198 Loss=0.781 Prec@1=79.858 Prec@5=93.993 rate=1.07 Hz, eta=0:46:41, total=0:31:05, wall=05:41 IST
=> training   41.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.198 Loss=0.781 Prec@1=79.858 Prec@5=93.993 rate=1.07 Hz, eta=0:45:08, total=0:32:39, wall=05:41 IST
=> training   41.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.936 DataTime=0.198 Loss=0.781 Prec@1=79.858 Prec@5=93.993 rate=1.07 Hz, eta=0:45:08, total=0:32:39, wall=05:42 IST
=> training   41.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.780 Prec@1=79.888 Prec@5=94.005 rate=1.07 Hz, eta=0:45:08, total=0:32:39, wall=05:42 IST
=> training   43.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.780 Prec@1=79.888 Prec@5=94.005 rate=1.07 Hz, eta=0:43:34, total=0:34:12, wall=05:42 IST
=> training   43.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.780 Prec@1=79.888 Prec@5=94.005 rate=1.07 Hz, eta=0:43:34, total=0:34:12, wall=05:44 IST
=> training   43.98% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.869 Prec@5=93.986 rate=1.07 Hz, eta=0:43:34, total=0:34:12, wall=05:44 IST
=> training   45.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.869 Prec@5=93.986 rate=1.07 Hz, eta=0:42:01, total=0:35:45, wall=05:44 IST
=> training   45.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.869 Prec@5=93.986 rate=1.07 Hz, eta=0:42:01, total=0:35:45, wall=05:45 IST
=> training   45.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.871 Prec@5=93.996 rate=1.07 Hz, eta=0:42:01, total=0:35:45, wall=05:45 IST
=> training   47.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.871 Prec@5=93.996 rate=1.07 Hz, eta=0:40:28, total=0:37:18, wall=05:45 IST
=> training   47.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.871 Prec@5=93.996 rate=1.07 Hz, eta=0:40:28, total=0:37:18, wall=05:47 IST
=> training   47.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.872 Prec@5=93.989 rate=1.07 Hz, eta=0:40:28, total=0:37:18, wall=05:47 IST
=> training   49.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.872 Prec@5=93.989 rate=1.07 Hz, eta=0:38:54, total=0:38:51, wall=05:47 IST
=> training   49.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.872 Prec@5=93.989 rate=1.07 Hz, eta=0:38:54, total=0:38:51, wall=05:48 IST
=> training   49.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.878 Prec@5=93.990 rate=1.07 Hz, eta=0:38:54, total=0:38:51, wall=05:48 IST
=> training   51.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.878 Prec@5=93.990 rate=1.07 Hz, eta=0:37:21, total=0:40:24, wall=05:48 IST
=> training   51.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.878 Prec@5=93.990 rate=1.07 Hz, eta=0:37:21, total=0:40:24, wall=05:50 IST
=> training   51.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.879 Prec@5=93.980 rate=1.07 Hz, eta=0:37:21, total=0:40:24, wall=05:50 IST
=> training   53.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.879 Prec@5=93.980 rate=1.07 Hz, eta=0:35:47, total=0:41:58, wall=05:50 IST
=> training   53.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.935 DataTime=0.198 Loss=0.781 Prec@1=79.879 Prec@5=93.980 rate=1.07 Hz, eta=0:35:47, total=0:41:58, wall=05:52 IST
=> training   53.97% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.887 Prec@5=93.976 rate=1.07 Hz, eta=0:35:47, total=0:41:58, wall=05:52 IST
=> training   55.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.887 Prec@5=93.976 rate=1.07 Hz, eta=0:34:14, total=0:43:30, wall=05:52 IST
=> training   55.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.887 Prec@5=93.976 rate=1.07 Hz, eta=0:34:14, total=0:43:30, wall=05:53 IST
=> training   55.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.890 Prec@5=93.983 rate=1.07 Hz, eta=0:34:14, total=0:43:30, wall=05:53 IST
=> training   57.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.890 Prec@5=93.983 rate=1.07 Hz, eta=0:32:41, total=0:45:03, wall=05:53 IST
=> training   57.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.890 Prec@5=93.983 rate=1.07 Hz, eta=0:32:41, total=0:45:03, wall=05:55 IST
=> training   57.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.887 Prec@5=93.981 rate=1.07 Hz, eta=0:32:41, total=0:45:03, wall=05:55 IST
=> training   59.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.887 Prec@5=93.981 rate=1.07 Hz, eta=0:31:07, total=0:46:37, wall=05:55 IST
=> training   59.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.887 Prec@5=93.981 rate=1.07 Hz, eta=0:31:07, total=0:46:37, wall=05:56 IST
=> training   59.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.878 Prec@5=93.970 rate=1.07 Hz, eta=0:31:07, total=0:46:37, wall=05:56 IST
=> training   61.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.878 Prec@5=93.970 rate=1.07 Hz, eta=0:29:34, total=0:48:10, wall=05:56 IST
=> training   61.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.878 Prec@5=93.970 rate=1.07 Hz, eta=0:29:34, total=0:48:10, wall=05:58 IST
=> training   61.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.872 Prec@5=93.974 rate=1.07 Hz, eta=0:29:34, total=0:48:10, wall=05:58 IST
=> training   63.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.872 Prec@5=93.974 rate=1.07 Hz, eta=0:28:01, total=0:49:43, wall=05:58 IST
=> training   63.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.872 Prec@5=93.974 rate=1.07 Hz, eta=0:28:01, total=0:49:43, wall=05:59 IST
=> training   63.96% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.882 Prec@5=93.978 rate=1.07 Hz, eta=0:28:01, total=0:49:43, wall=05:59 IST
=> training   65.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.882 Prec@5=93.978 rate=1.07 Hz, eta=0:26:28, total=0:51:16, wall=05:59 IST
=> training   65.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.882 Prec@5=93.978 rate=1.07 Hz, eta=0:26:28, total=0:51:16, wall=06:01 IST
=> training   65.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.886 Prec@5=93.978 rate=1.07 Hz, eta=0:26:28, total=0:51:16, wall=06:01 IST
=> training   67.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.886 Prec@5=93.978 rate=1.07 Hz, eta=0:24:54, total=0:52:49, wall=06:01 IST
=> training   67.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.886 Prec@5=93.978 rate=1.07 Hz, eta=0:24:54, total=0:52:49, wall=06:02 IST
=> training   67.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.885 Prec@5=93.977 rate=1.07 Hz, eta=0:24:54, total=0:52:49, wall=06:02 IST
=> training   69.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.885 Prec@5=93.977 rate=1.07 Hz, eta=0:23:21, total=0:54:22, wall=06:02 IST
=> training   69.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.885 Prec@5=93.977 rate=1.07 Hz, eta=0:23:21, total=0:54:22, wall=06:04 IST
=> training   69.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.882 Prec@5=93.974 rate=1.07 Hz, eta=0:23:21, total=0:54:22, wall=06:04 IST
=> training   71.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.882 Prec@5=93.974 rate=1.07 Hz, eta=0:21:48, total=0:55:55, wall=06:04 IST
=> training   71.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.882 Prec@5=93.974 rate=1.07 Hz, eta=0:21:48, total=0:55:55, wall=06:06 IST
=> training   71.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.888 Prec@5=93.970 rate=1.07 Hz, eta=0:21:48, total=0:55:55, wall=06:06 IST
=> training   73.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.888 Prec@5=93.970 rate=1.07 Hz, eta=0:20:15, total=0:57:29, wall=06:06 IST
=> training   73.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.198 Loss=0.781 Prec@1=79.888 Prec@5=93.970 rate=1.07 Hz, eta=0:20:15, total=0:57:29, wall=06:07 IST
=> training   73.95% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.197 Loss=0.782 Prec@1=79.880 Prec@5=93.968 rate=1.07 Hz, eta=0:20:15, total=0:57:29, wall=06:07 IST
=> training   75.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.197 Loss=0.782 Prec@1=79.880 Prec@5=93.968 rate=1.07 Hz, eta=0:18:42, total=0:59:02, wall=06:07 IST
=> training   75.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.197 Loss=0.782 Prec@1=79.880 Prec@5=93.968 rate=1.07 Hz, eta=0:18:42, total=0:59:02, wall=06:09 IST
=> training   75.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.197 Loss=0.782 Prec@1=79.884 Prec@5=93.969 rate=1.07 Hz, eta=0:18:42, total=0:59:02, wall=06:09 IST
=> training   77.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.197 Loss=0.782 Prec@1=79.884 Prec@5=93.969 rate=1.07 Hz, eta=0:17:08, total=1:00:35, wall=06:09 IST
=> training   77.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.934 DataTime=0.197 Loss=0.782 Prec@1=79.884 Prec@5=93.969 rate=1.07 Hz, eta=0:17:08, total=1:00:35, wall=06:10 IST
=> training   77.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.886 Prec@5=93.967 rate=1.07 Hz, eta=0:17:08, total=1:00:35, wall=06:10 IST
=> training   79.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.886 Prec@5=93.967 rate=1.07 Hz, eta=0:15:35, total=1:02:08, wall=06:10 IST
=> training   79.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.886 Prec@5=93.967 rate=1.07 Hz, eta=0:15:35, total=1:02:08, wall=06:12 IST
=> training   79.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.963 rate=1.07 Hz, eta=0:15:35, total=1:02:08, wall=06:12 IST
=> training   81.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.963 rate=1.07 Hz, eta=0:14:02, total=1:03:41, wall=06:12 IST
=> training   81.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.963 rate=1.07 Hz, eta=0:14:02, total=1:03:41, wall=06:13 IST
=> training   81.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.891 Prec@5=93.966 rate=1.07 Hz, eta=0:14:02, total=1:03:41, wall=06:13 IST
=> training   83.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.891 Prec@5=93.966 rate=1.07 Hz, eta=0:12:29, total=1:05:14, wall=06:13 IST
=> training   83.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.891 Prec@5=93.966 rate=1.07 Hz, eta=0:12:29, total=1:05:14, wall=06:15 IST
=> training   83.94% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.781 Prec@1=79.898 Prec@5=93.970 rate=1.07 Hz, eta=0:12:29, total=1:05:14, wall=06:15 IST
=> training   85.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.781 Prec@1=79.898 Prec@5=93.970 rate=1.07 Hz, eta=0:10:55, total=1:06:47, wall=06:15 IST
=> training   85.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.781 Prec@1=79.898 Prec@5=93.970 rate=1.07 Hz, eta=0:10:55, total=1:06:47, wall=06:16 IST
=> training   85.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.966 rate=1.07 Hz, eta=0:10:55, total=1:06:47, wall=06:16 IST
=> training   87.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.966 rate=1.07 Hz, eta=0:09:22, total=1:08:20, wall=06:16 IST
=> training   87.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.966 rate=1.07 Hz, eta=0:09:22, total=1:08:20, wall=06:18 IST
=> training   87.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.892 Prec@5=93.968 rate=1.07 Hz, eta=0:09:22, total=1:08:20, wall=06:18 IST
=> training   89.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.892 Prec@5=93.968 rate=1.07 Hz, eta=0:07:49, total=1:09:54, wall=06:18 IST
=> training   89.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.892 Prec@5=93.968 rate=1.07 Hz, eta=0:07:49, total=1:09:54, wall=06:20 IST
=> training   89.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.897 Prec@5=93.968 rate=1.07 Hz, eta=0:07:49, total=1:09:54, wall=06:20 IST
=> training   91.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.897 Prec@5=93.968 rate=1.07 Hz, eta=0:06:16, total=1:11:26, wall=06:20 IST
=> training   91.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.897 Prec@5=93.968 rate=1.07 Hz, eta=0:06:16, total=1:11:26, wall=06:21 IST
=> training   91.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.895 Prec@5=93.964 rate=1.07 Hz, eta=0:06:16, total=1:11:26, wall=06:21 IST
=> training   93.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.895 Prec@5=93.964 rate=1.07 Hz, eta=0:04:43, total=1:13:00, wall=06:21 IST
=> training   93.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.895 Prec@5=93.964 rate=1.07 Hz, eta=0:04:43, total=1:13:00, wall=06:23 IST
=> training   93.93% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.963 rate=1.07 Hz, eta=0:04:43, total=1:13:00, wall=06:23 IST
=> training   95.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.963 rate=1.07 Hz, eta=0:03:10, total=1:14:33, wall=06:23 IST
=> training   95.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.890 Prec@5=93.963 rate=1.07 Hz, eta=0:03:10, total=1:14:33, wall=06:24 IST
=> training   95.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.900 Prec@5=93.966 rate=1.07 Hz, eta=0:03:10, total=1:14:33, wall=06:24 IST
=> training   97.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.900 Prec@5=93.966 rate=1.07 Hz, eta=0:01:36, total=1:16:06, wall=06:24 IST
=> training   97.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.900 Prec@5=93.966 rate=1.07 Hz, eta=0:01:36, total=1:16:06, wall=06:26 IST
=> training   97.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.899 Prec@5=93.964 rate=1.07 Hz, eta=0:01:36, total=1:16:06, wall=06:26 IST
=> training   99.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.899 Prec@5=93.964 rate=1.07 Hz, eta=0:00:03, total=1:17:38, wall=06:26 IST
=> training   99.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.899 Prec@5=93.964 rate=1.07 Hz, eta=0:00:03, total=1:17:38, wall=06:26 IST
=> training   99.92% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.901 Prec@5=93.965 rate=1.07 Hz, eta=0:00:03, total=1:17:38, wall=06:26 IST
=> training   100.00% of 1x5005...Epoch=9/10 LR=0.00001 Time=0.933 DataTime=0.197 Loss=0.782 Prec@1=79.901 Prec@5=93.965 rate=1.07 Hz, eta=0:00:00, total=1:17:41, wall=06:26 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 8.000 8.000 8.000 2.000 4.000 8.000 8.000 4.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=06:26 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=06:26 IST
=> validation 0.00% of 1x196...Epoch=9/10 LR=0.00001 Time=7.659 Loss=1.114 Prec@1=71.875 Prec@5=92.969 rate=0 Hz, eta=?, total=0:00:00, wall=06:26 IST
=> validation 0.51% of 1x196...Epoch=9/10 LR=0.00001 Time=7.659 Loss=1.114 Prec@1=71.875 Prec@5=92.969 rate=7784.52 Hz, eta=0:00:00, total=0:00:00, wall=06:26 IST
=> validation 0.51% of 1x196...Epoch=9/10 LR=0.00001 Time=7.659 Loss=1.114 Prec@1=71.875 Prec@5=92.969 rate=7784.52 Hz, eta=0:00:00, total=0:00:00, wall=06:27 IST
=> validation 0.51% of 1x196...Epoch=9/10 LR=0.00001 Time=0.712 Loss=1.181 Prec@1=71.554 Prec@5=90.258 rate=7784.52 Hz, eta=0:00:00, total=0:00:00, wall=06:27 IST
=> validation 51.53% of 1x196...Epoch=9/10 LR=0.00001 Time=0.712 Loss=1.181 Prec@1=71.554 Prec@5=90.258 rate=1.57 Hz, eta=0:01:00, total=0:01:04, wall=06:27 IST
** validation 51.53% of 1x196...Epoch=9/10 LR=0.00001 Time=0.712 Loss=1.181 Prec@1=71.554 Prec@5=90.258 rate=1.57 Hz, eta=0:01:00, total=0:01:04, wall=06:28 IST
** validation 51.53% of 1x196...Epoch=9/10 LR=0.00001 Time=0.650 Loss=1.175 Prec@1=71.658 Prec@5=90.396 rate=1.57 Hz, eta=0:01:00, total=0:01:04, wall=06:28 IST
** validation 100.00% of 1x196...Epoch=9/10 LR=0.00001 Time=0.650 Loss=1.175 Prec@1=71.658 Prec@5=90.396 rate=1.64 Hz, eta=0:00:00, total=0:01:59, wall=06:28 IST
[39m[33m
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=06:28 IST
=> training   0.00% of 1x5005... rate=0 Hz, eta=?, total=0:00:00, wall=06:28 IST
=> training   0.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=6.273 DataTime=4.866 Loss=0.769 Prec@1=82.031 Prec@5=95.703 rate=0 Hz, eta=?, total=0:00:00, wall=06:28 IST
=> training   0.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=6.273 DataTime=4.866 Loss=0.769 Prec@1=82.031 Prec@5=95.703 rate=3719.09 Hz, eta=0:00:01, total=0:00:00, wall=06:28 IST
=> training   0.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=6.273 DataTime=4.866 Loss=0.769 Prec@1=82.031 Prec@5=95.703 rate=3719.09 Hz, eta=0:00:01, total=0:00:00, wall=06:30 IST
=> training   0.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.994 DataTime=0.243 Loss=0.775 Prec@1=80.016 Prec@5=94.086 rate=3719.09 Hz, eta=0:00:01, total=0:00:00, wall=06:30 IST
=> training   2.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.994 DataTime=0.243 Loss=0.775 Prec@1=80.016 Prec@5=94.086 rate=1.07 Hz, eta=1:16:10, total=0:01:34, wall=06:30 IST
=> training   2.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.994 DataTime=0.243 Loss=0.775 Prec@1=80.016 Prec@5=94.086 rate=1.07 Hz, eta=1:16:10, total=0:01:34, wall=06:31 IST
=> training   2.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.963 DataTime=0.219 Loss=0.782 Prec@1=79.892 Prec@5=94.010 rate=1.07 Hz, eta=1:16:10, total=0:01:34, wall=06:31 IST
=> training   4.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.963 DataTime=0.219 Loss=0.782 Prec@1=79.892 Prec@5=94.010 rate=1.07 Hz, eta=1:14:37, total=0:03:07, wall=06:31 IST
=> training   4.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.963 DataTime=0.219 Loss=0.782 Prec@1=79.892 Prec@5=94.010 rate=1.07 Hz, eta=1:14:37, total=0:03:07, wall=06:33 IST
=> training   4.02% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.951 DataTime=0.212 Loss=0.783 Prec@1=79.931 Prec@5=94.037 rate=1.07 Hz, eta=1:14:37, total=0:03:07, wall=06:33 IST
=> training   6.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.951 DataTime=0.212 Loss=0.783 Prec@1=79.931 Prec@5=94.037 rate=1.07 Hz, eta=1:12:56, total=0:04:40, wall=06:33 IST
=> training   6.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.951 DataTime=0.212 Loss=0.783 Prec@1=79.931 Prec@5=94.037 rate=1.07 Hz, eta=1:12:56, total=0:04:40, wall=06:34 IST
=> training   6.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.946 DataTime=0.208 Loss=0.780 Prec@1=79.976 Prec@5=94.077 rate=1.07 Hz, eta=1:12:56, total=0:04:40, wall=06:34 IST
=> training   8.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.946 DataTime=0.208 Loss=0.780 Prec@1=79.976 Prec@5=94.077 rate=1.07 Hz, eta=1:11:24, total=0:06:13, wall=06:34 IST
=> training   8.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.946 DataTime=0.208 Loss=0.780 Prec@1=79.976 Prec@5=94.077 rate=1.07 Hz, eta=1:11:24, total=0:06:13, wall=06:36 IST
=> training   8.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.943 DataTime=0.206 Loss=0.777 Prec@1=80.024 Prec@5=94.099 rate=1.07 Hz, eta=1:11:24, total=0:06:13, wall=06:36 IST
=> training   10.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.943 DataTime=0.206 Loss=0.777 Prec@1=80.024 Prec@5=94.099 rate=1.07 Hz, eta=1:09:51, total=0:07:46, wall=06:36 IST
=> training   10.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.943 DataTime=0.206 Loss=0.777 Prec@1=80.024 Prec@5=94.099 rate=1.07 Hz, eta=1:09:51, total=0:07:46, wall=06:37 IST
=> training   10.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.204 Loss=0.775 Prec@1=80.078 Prec@5=94.089 rate=1.07 Hz, eta=1:09:51, total=0:07:46, wall=06:37 IST
=> training   12.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.204 Loss=0.775 Prec@1=80.078 Prec@5=94.089 rate=1.07 Hz, eta=1:08:19, total=0:09:19, wall=06:37 IST
=> training   12.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.204 Loss=0.775 Prec@1=80.078 Prec@5=94.089 rate=1.07 Hz, eta=1:08:19, total=0:09:19, wall=06:39 IST
=> training   12.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.203 Loss=0.776 Prec@1=80.062 Prec@5=94.078 rate=1.07 Hz, eta=1:08:19, total=0:09:19, wall=06:39 IST
=> training   14.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.203 Loss=0.776 Prec@1=80.062 Prec@5=94.078 rate=1.07 Hz, eta=1:06:46, total=0:10:52, wall=06:39 IST
=> training   14.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.203 Loss=0.776 Prec@1=80.062 Prec@5=94.078 rate=1.07 Hz, eta=1:06:46, total=0:10:52, wall=06:41 IST
=> training   14.01% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.202 Loss=0.776 Prec@1=80.003 Prec@5=94.073 rate=1.07 Hz, eta=1:06:46, total=0:10:52, wall=06:41 IST
=> training   16.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.202 Loss=0.776 Prec@1=80.003 Prec@5=94.073 rate=1.07 Hz, eta=1:05:12, total=0:12:25, wall=06:41 IST
=> training   16.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.202 Loss=0.776 Prec@1=80.003 Prec@5=94.073 rate=1.07 Hz, eta=1:05:12, total=0:12:25, wall=06:42 IST
=> training   16.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.202 Loss=0.779 Prec@1=79.922 Prec@5=94.040 rate=1.07 Hz, eta=1:05:12, total=0:12:25, wall=06:42 IST
=> training   18.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.202 Loss=0.779 Prec@1=79.922 Prec@5=94.040 rate=1.07 Hz, eta=1:03:38, total=0:13:58, wall=06:42 IST
=> training   18.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.202 Loss=0.779 Prec@1=79.922 Prec@5=94.040 rate=1.07 Hz, eta=1:03:38, total=0:13:58, wall=06:44 IST
=> training   18.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.201 Loss=0.779 Prec@1=79.915 Prec@5=94.045 rate=1.07 Hz, eta=1:03:38, total=0:13:58, wall=06:44 IST
=> training   20.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.201 Loss=0.779 Prec@1=79.915 Prec@5=94.045 rate=1.07 Hz, eta=1:02:06, total=0:15:31, wall=06:44 IST
=> training   20.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.201 Loss=0.779 Prec@1=79.915 Prec@5=94.045 rate=1.07 Hz, eta=1:02:06, total=0:15:31, wall=06:45 IST
=> training   20.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.201 Loss=0.779 Prec@1=79.905 Prec@5=94.052 rate=1.07 Hz, eta=1:02:06, total=0:15:31, wall=06:45 IST
=> training   22.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.201 Loss=0.779 Prec@1=79.905 Prec@5=94.052 rate=1.07 Hz, eta=1:00:33, total=0:17:04, wall=06:45 IST
=> training   22.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.201 Loss=0.779 Prec@1=79.905 Prec@5=94.052 rate=1.07 Hz, eta=1:00:33, total=0:17:04, wall=06:47 IST
=> training   22.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.200 Loss=0.779 Prec@1=79.892 Prec@5=94.044 rate=1.07 Hz, eta=1:00:33, total=0:17:04, wall=06:47 IST
=> training   24.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.200 Loss=0.779 Prec@1=79.892 Prec@5=94.044 rate=1.07 Hz, eta=0:59:00, total=0:18:37, wall=06:47 IST
=> training   24.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.200 Loss=0.779 Prec@1=79.892 Prec@5=94.044 rate=1.07 Hz, eta=0:59:00, total=0:18:37, wall=06:48 IST
=> training   24.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.200 Loss=0.778 Prec@1=79.911 Prec@5=94.044 rate=1.07 Hz, eta=0:59:00, total=0:18:37, wall=06:48 IST
=> training   25.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.200 Loss=0.778 Prec@1=79.911 Prec@5=94.044 rate=1.07 Hz, eta=0:57:30, total=0:20:11, wall=06:48 IST
=> training   25.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.200 Loss=0.778 Prec@1=79.911 Prec@5=94.044 rate=1.07 Hz, eta=0:57:30, total=0:20:11, wall=06:50 IST
=> training   25.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.945 DataTime=0.200 Loss=0.778 Prec@1=79.898 Prec@5=94.053 rate=1.07 Hz, eta=0:57:30, total=0:20:11, wall=06:50 IST
=> training   27.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.945 DataTime=0.200 Loss=0.778 Prec@1=79.898 Prec@5=94.053 rate=1.06 Hz, eta=0:56:28, total=0:21:57, wall=06:50 IST
=> training   27.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.945 DataTime=0.200 Loss=0.778 Prec@1=79.898 Prec@5=94.053 rate=1.06 Hz, eta=0:56:28, total=0:21:57, wall=06:52 IST
=> training   27.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.944 DataTime=0.199 Loss=0.778 Prec@1=79.902 Prec@5=94.069 rate=1.06 Hz, eta=0:56:28, total=0:21:57, wall=06:52 IST
=> training   29.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.944 DataTime=0.199 Loss=0.778 Prec@1=79.902 Prec@5=94.069 rate=1.06 Hz, eta=0:54:52, total=0:23:30, wall=06:52 IST
=> training   29.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.944 DataTime=0.199 Loss=0.778 Prec@1=79.902 Prec@5=94.069 rate=1.06 Hz, eta=0:54:52, total=0:23:30, wall=06:53 IST
=> training   29.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.943 DataTime=0.199 Loss=0.778 Prec@1=79.922 Prec@5=94.072 rate=1.06 Hz, eta=0:54:52, total=0:23:30, wall=06:53 IST
=> training   31.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.943 DataTime=0.199 Loss=0.778 Prec@1=79.922 Prec@5=94.072 rate=1.06 Hz, eta=0:53:16, total=0:25:03, wall=06:53 IST
=> training   31.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.943 DataTime=0.199 Loss=0.778 Prec@1=79.922 Prec@5=94.072 rate=1.06 Hz, eta=0:53:16, total=0:25:03, wall=06:55 IST
=> training   31.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.942 DataTime=0.199 Loss=0.778 Prec@1=79.917 Prec@5=94.059 rate=1.06 Hz, eta=0:53:16, total=0:25:03, wall=06:55 IST
=> training   33.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.942 DataTime=0.199 Loss=0.778 Prec@1=79.917 Prec@5=94.059 rate=1.07 Hz, eta=0:51:40, total=0:26:36, wall=06:55 IST
=> training   33.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.942 DataTime=0.199 Loss=0.778 Prec@1=79.917 Prec@5=94.059 rate=1.07 Hz, eta=0:51:40, total=0:26:36, wall=06:56 IST
=> training   33.99% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.942 DataTime=0.199 Loss=0.778 Prec@1=79.911 Prec@5=94.042 rate=1.07 Hz, eta=0:51:40, total=0:26:36, wall=06:56 IST
=> training   35.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.942 DataTime=0.199 Loss=0.778 Prec@1=79.911 Prec@5=94.042 rate=1.07 Hz, eta=0:50:05, total=0:28:09, wall=06:56 IST
=> training   35.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.942 DataTime=0.199 Loss=0.778 Prec@1=79.911 Prec@5=94.042 rate=1.07 Hz, eta=0:50:05, total=0:28:09, wall=06:58 IST
=> training   35.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.199 Loss=0.778 Prec@1=79.931 Prec@5=94.049 rate=1.07 Hz, eta=0:50:05, total=0:28:09, wall=06:58 IST
=> training   37.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.199 Loss=0.778 Prec@1=79.931 Prec@5=94.049 rate=1.07 Hz, eta=0:48:31, total=0:29:42, wall=06:58 IST
=> training   37.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.199 Loss=0.778 Prec@1=79.931 Prec@5=94.049 rate=1.07 Hz, eta=0:48:31, total=0:29:42, wall=06:59 IST
=> training   37.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.199 Loss=0.777 Prec@1=79.940 Prec@5=94.053 rate=1.07 Hz, eta=0:48:31, total=0:29:42, wall=06:59 IST
=> training   39.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.199 Loss=0.777 Prec@1=79.940 Prec@5=94.053 rate=1.07 Hz, eta=0:46:56, total=0:31:16, wall=06:59 IST
=> training   39.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.941 DataTime=0.199 Loss=0.777 Prec@1=79.940 Prec@5=94.053 rate=1.07 Hz, eta=0:46:56, total=0:31:16, wall=07:01 IST
=> training   39.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.199 Loss=0.777 Prec@1=79.944 Prec@5=94.046 rate=1.07 Hz, eta=0:46:56, total=0:31:16, wall=07:01 IST
=> training   41.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.199 Loss=0.777 Prec@1=79.944 Prec@5=94.046 rate=1.07 Hz, eta=0:45:21, total=0:32:49, wall=07:01 IST
=> training   41.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.199 Loss=0.777 Prec@1=79.944 Prec@5=94.046 rate=1.07 Hz, eta=0:45:21, total=0:32:49, wall=07:02 IST
=> training   41.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.198 Loss=0.777 Prec@1=79.952 Prec@5=94.039 rate=1.07 Hz, eta=0:45:21, total=0:32:49, wall=07:02 IST
=> training   43.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.198 Loss=0.777 Prec@1=79.952 Prec@5=94.039 rate=1.07 Hz, eta=0:43:47, total=0:34:22, wall=07:02 IST
=> training   43.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.198 Loss=0.777 Prec@1=79.952 Prec@5=94.039 rate=1.07 Hz, eta=0:43:47, total=0:34:22, wall=07:04 IST
=> training   43.98% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.198 Loss=0.778 Prec@1=79.936 Prec@5=94.035 rate=1.07 Hz, eta=0:43:47, total=0:34:22, wall=07:04 IST
=> training   45.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.198 Loss=0.778 Prec@1=79.936 Prec@5=94.035 rate=1.07 Hz, eta=0:42:13, total=0:35:55, wall=07:04 IST
=> training   45.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.940 DataTime=0.198 Loss=0.778 Prec@1=79.936 Prec@5=94.035 rate=1.07 Hz, eta=0:42:13, total=0:35:55, wall=07:06 IST
=> training   45.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.939 DataTime=0.198 Loss=0.778 Prec@1=79.926 Prec@5=94.035 rate=1.07 Hz, eta=0:42:13, total=0:35:55, wall=07:06 IST
=> training   47.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.939 DataTime=0.198 Loss=0.778 Prec@1=79.926 Prec@5=94.035 rate=1.07 Hz, eta=0:40:38, total=0:37:28, wall=07:06 IST
=> training   47.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.939 DataTime=0.198 Loss=0.778 Prec@1=79.926 Prec@5=94.035 rate=1.07 Hz, eta=0:40:38, total=0:37:28, wall=07:07 IST
=> training   47.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.939 DataTime=0.198 Loss=0.779 Prec@1=79.910 Prec@5=94.024 rate=1.07 Hz, eta=0:40:38, total=0:37:28, wall=07:07 IST
=> training   49.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.939 DataTime=0.198 Loss=0.779 Prec@1=79.910 Prec@5=94.024 rate=1.07 Hz, eta=0:39:04, total=0:39:01, wall=07:07 IST
=> training   49.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.939 DataTime=0.198 Loss=0.779 Prec@1=79.910 Prec@5=94.024 rate=1.07 Hz, eta=0:39:04, total=0:39:01, wall=07:09 IST
=> training   49.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.019 rate=1.07 Hz, eta=0:39:04, total=0:39:01, wall=07:09 IST
=> training   51.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.019 rate=1.07 Hz, eta=0:37:30, total=0:40:34, wall=07:09 IST
=> training   51.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.019 rate=1.07 Hz, eta=0:37:30, total=0:40:34, wall=07:10 IST
=> training   51.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.008 rate=1.07 Hz, eta=0:37:30, total=0:40:34, wall=07:10 IST
=> training   53.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.008 rate=1.07 Hz, eta=0:35:56, total=0:42:07, wall=07:10 IST
=> training   53.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.008 rate=1.07 Hz, eta=0:35:56, total=0:42:07, wall=07:12 IST
=> training   53.97% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.004 rate=1.07 Hz, eta=0:35:56, total=0:42:07, wall=07:12 IST
=> training   55.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.004 rate=1.07 Hz, eta=0:34:22, total=0:43:40, wall=07:12 IST
=> training   55.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.898 Prec@5=94.004 rate=1.07 Hz, eta=0:34:22, total=0:43:40, wall=07:13 IST
=> training   55.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.909 Prec@5=94.006 rate=1.07 Hz, eta=0:34:22, total=0:43:40, wall=07:13 IST
=> training   57.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.909 Prec@5=94.006 rate=1.07 Hz, eta=0:32:48, total=0:45:13, wall=07:13 IST
=> training   57.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.938 DataTime=0.198 Loss=0.779 Prec@1=79.909 Prec@5=94.006 rate=1.07 Hz, eta=0:32:48, total=0:45:13, wall=07:15 IST
=> training   57.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.916 Prec@5=94.007 rate=1.07 Hz, eta=0:32:48, total=0:45:13, wall=07:15 IST
=> training   59.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.916 Prec@5=94.007 rate=1.07 Hz, eta=0:31:14, total=0:46:46, wall=07:15 IST
=> training   59.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.916 Prec@5=94.007 rate=1.07 Hz, eta=0:31:14, total=0:46:46, wall=07:16 IST
=> training   59.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.915 Prec@5=94.007 rate=1.07 Hz, eta=0:31:14, total=0:46:46, wall=07:16 IST
=> training   61.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.915 Prec@5=94.007 rate=1.07 Hz, eta=0:29:40, total=0:48:19, wall=07:16 IST
=> training   61.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.915 Prec@5=94.007 rate=1.07 Hz, eta=0:29:40, total=0:48:19, wall=07:18 IST
=> training   61.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.924 Prec@5=94.005 rate=1.07 Hz, eta=0:29:40, total=0:48:19, wall=07:18 IST
=> training   63.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.924 Prec@5=94.005 rate=1.07 Hz, eta=0:28:06, total=0:49:52, wall=07:18 IST
=> training   63.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.924 Prec@5=94.005 rate=1.07 Hz, eta=0:28:06, total=0:49:52, wall=07:20 IST
=> training   63.96% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.934 Prec@5=94.003 rate=1.07 Hz, eta=0:28:06, total=0:49:52, wall=07:20 IST
=> training   65.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.934 Prec@5=94.003 rate=1.07 Hz, eta=0:26:32, total=0:51:25, wall=07:20 IST
=> training   65.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.937 DataTime=0.198 Loss=0.779 Prec@1=79.934 Prec@5=94.003 rate=1.07 Hz, eta=0:26:32, total=0:51:25, wall=07:21 IST
=> training   65.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.935 Prec@5=94.002 rate=1.07 Hz, eta=0:26:32, total=0:51:25, wall=07:21 IST
=> training   67.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.935 Prec@5=94.002 rate=1.07 Hz, eta=0:24:58, total=0:52:58, wall=07:21 IST
=> training   67.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.935 Prec@5=94.002 rate=1.07 Hz, eta=0:24:58, total=0:52:58, wall=07:23 IST
=> training   67.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.927 Prec@5=94.002 rate=1.07 Hz, eta=0:24:58, total=0:52:58, wall=07:23 IST
=> training   69.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.927 Prec@5=94.002 rate=1.07 Hz, eta=0:23:25, total=0:54:31, wall=07:23 IST
=> training   69.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.927 Prec@5=94.002 rate=1.07 Hz, eta=0:23:25, total=0:54:31, wall=07:24 IST
=> training   69.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.936 Prec@5=94.009 rate=1.07 Hz, eta=0:23:25, total=0:54:31, wall=07:24 IST
=> training   71.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.936 Prec@5=94.009 rate=1.07 Hz, eta=0:21:51, total=0:56:04, wall=07:24 IST
=> training   71.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.936 Prec@5=94.009 rate=1.07 Hz, eta=0:21:51, total=0:56:04, wall=07:26 IST
=> training   71.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.942 Prec@5=94.014 rate=1.07 Hz, eta=0:21:51, total=0:56:04, wall=07:26 IST
=> training   73.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.942 Prec@5=94.014 rate=1.07 Hz, eta=0:20:18, total=0:57:37, wall=07:26 IST
=> training   73.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.942 Prec@5=94.014 rate=1.07 Hz, eta=0:20:18, total=0:57:37, wall=07:27 IST
=> training   73.95% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.945 Prec@5=94.015 rate=1.07 Hz, eta=0:20:18, total=0:57:37, wall=07:27 IST
=> training   75.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.945 Prec@5=94.015 rate=1.07 Hz, eta=0:18:44, total=0:59:10, wall=07:27 IST
=> training   75.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.779 Prec@1=79.945 Prec@5=94.015 rate=1.07 Hz, eta=0:18:44, total=0:59:10, wall=07:29 IST
=> training   75.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.778 Prec@1=79.948 Prec@5=94.019 rate=1.07 Hz, eta=0:18:44, total=0:59:10, wall=07:29 IST
=> training   77.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.778 Prec@1=79.948 Prec@5=94.019 rate=1.07 Hz, eta=0:17:11, total=1:00:43, wall=07:29 IST
=> training   77.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.936 DataTime=0.198 Loss=0.778 Prec@1=79.948 Prec@5=94.019 rate=1.07 Hz, eta=0:17:11, total=1:00:43, wall=07:30 IST
=> training   77.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.948 Prec@5=94.023 rate=1.07 Hz, eta=0:17:11, total=1:00:43, wall=07:30 IST
=> training   79.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.948 Prec@5=94.023 rate=1.07 Hz, eta=0:15:37, total=1:02:16, wall=07:30 IST
=> training   79.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.948 Prec@5=94.023 rate=1.07 Hz, eta=0:15:37, total=1:02:16, wall=07:32 IST
=> training   79.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.945 Prec@5=94.021 rate=1.07 Hz, eta=0:15:37, total=1:02:16, wall=07:32 IST
=> training   81.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.945 Prec@5=94.021 rate=1.07 Hz, eta=0:14:04, total=1:03:49, wall=07:32 IST
=> training   81.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.945 Prec@5=94.021 rate=1.07 Hz, eta=0:14:04, total=1:03:49, wall=07:33 IST
=> training   81.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.947 Prec@5=94.018 rate=1.07 Hz, eta=0:14:04, total=1:03:49, wall=07:33 IST
=> training   83.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.947 Prec@5=94.018 rate=1.07 Hz, eta=0:12:30, total=1:05:22, wall=07:33 IST
=> training   83.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.947 Prec@5=94.018 rate=1.07 Hz, eta=0:12:30, total=1:05:22, wall=07:35 IST
=> training   83.94% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.941 Prec@5=94.013 rate=1.07 Hz, eta=0:12:30, total=1:05:22, wall=07:35 IST
=> training   85.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.941 Prec@5=94.013 rate=1.07 Hz, eta=0:10:57, total=1:06:56, wall=07:35 IST
=> training   85.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.941 Prec@5=94.013 rate=1.07 Hz, eta=0:10:57, total=1:06:56, wall=07:37 IST
=> training   85.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.937 Prec@5=94.012 rate=1.07 Hz, eta=0:10:57, total=1:06:56, wall=07:37 IST
=> training   87.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.937 Prec@5=94.012 rate=1.07 Hz, eta=0:09:23, total=1:08:29, wall=07:37 IST
=> training   87.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.937 Prec@5=94.012 rate=1.07 Hz, eta=0:09:23, total=1:08:29, wall=07:38 IST
=> training   87.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.936 Prec@5=94.015 rate=1.07 Hz, eta=0:09:23, total=1:08:29, wall=07:38 IST
=> training   89.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.936 Prec@5=94.015 rate=1.07 Hz, eta=0:07:50, total=1:10:02, wall=07:38 IST
=> training   89.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.779 Prec@1=79.936 Prec@5=94.015 rate=1.07 Hz, eta=0:07:50, total=1:10:02, wall=07:40 IST
=> training   89.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.944 Prec@5=94.011 rate=1.07 Hz, eta=0:07:50, total=1:10:02, wall=07:40 IST
=> training   91.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.944 Prec@5=94.011 rate=1.07 Hz, eta=0:06:17, total=1:11:35, wall=07:40 IST
=> training   91.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.944 Prec@5=94.011 rate=1.07 Hz, eta=0:06:17, total=1:11:35, wall=07:41 IST
=> training   91.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.944 Prec@5=94.010 rate=1.07 Hz, eta=0:06:17, total=1:11:35, wall=07:41 IST
=> training   93.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.944 Prec@5=94.010 rate=1.07 Hz, eta=0:04:43, total=1:13:08, wall=07:41 IST
=> training   93.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.944 Prec@5=94.010 rate=1.07 Hz, eta=0:04:43, total=1:13:08, wall=07:43 IST
=> training   93.93% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.954 Prec@5=94.010 rate=1.07 Hz, eta=0:04:43, total=1:13:08, wall=07:43 IST
=> training   95.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.954 Prec@5=94.010 rate=1.07 Hz, eta=0:03:10, total=1:14:41, wall=07:43 IST
=> training   95.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.954 Prec@5=94.010 rate=1.07 Hz, eta=0:03:10, total=1:14:41, wall=07:44 IST
=> training   95.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.945 Prec@5=94.004 rate=1.07 Hz, eta=0:03:10, total=1:14:41, wall=07:44 IST
=> training   97.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.945 Prec@5=94.004 rate=1.07 Hz, eta=0:01:37, total=1:16:15, wall=07:44 IST
=> training   97.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.945 Prec@5=94.004 rate=1.07 Hz, eta=0:01:37, total=1:16:15, wall=07:46 IST
=> training   97.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.954 Prec@5=94.009 rate=1.07 Hz, eta=0:01:37, total=1:16:15, wall=07:46 IST
=> training   99.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.954 Prec@5=94.009 rate=1.07 Hz, eta=0:00:03, total=1:17:47, wall=07:46 IST
=> training   99.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.935 DataTime=0.197 Loss=0.778 Prec@1=79.954 Prec@5=94.009 rate=1.07 Hz, eta=0:00:03, total=1:17:47, wall=07:46 IST
=> training   99.92% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.934 DataTime=0.197 Loss=0.778 Prec@1=79.955 Prec@5=94.010 rate=1.07 Hz, eta=0:00:03, total=1:17:47, wall=07:46 IST
=> training   100.00% of 1x5005...Epoch=10/10 LR=0.00000 Time=0.934 DataTime=0.197 Loss=0.778 Prec@1=79.955 Prec@5=94.010 rate=1.07 Hz, eta=0:00:00, total=1:17:50, wall=07:46 IST
[39m
clips_act : 32.000 4.000 4.000 8.000 8.000 8.000 8.000 8.000 2.000 4.000 8.000 8.000 4.000 4.000 4.000 2.000 2.000 4.000 8.000 2.000 2.000 4.000 8.000 2.000 4.000 4.000 2.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 2.000 4.000 2.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 4.000 1.000 2.000 2.000 16.000[32m
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=07:46 IST
=> validation 0.00% of 1x196... rate=0 Hz, eta=?, total=0:00:00, wall=07:46 IST
=> validation 0.00% of 1x196...Epoch=10/10 LR=0.00000 Time=7.704 Loss=1.191 Prec@1=71.094 Prec@5=87.500 rate=0 Hz, eta=?, total=0:00:00, wall=07:46 IST
=> validation 0.51% of 1x196...Epoch=10/10 LR=0.00000 Time=7.704 Loss=1.191 Prec@1=71.094 Prec@5=87.500 rate=8299.97 Hz, eta=0:00:00, total=0:00:00, wall=07:46 IST
=> validation 0.51% of 1x196...Epoch=10/10 LR=0.00000 Time=7.704 Loss=1.191 Prec@1=71.094 Prec@5=87.500 rate=8299.97 Hz, eta=0:00:00, total=0:00:00, wall=07:47 IST
=> validation 0.51% of 1x196...Epoch=10/10 LR=0.00000 Time=0.709 Loss=1.160 Prec@1=72.022 Prec@5=90.532 rate=8299.97 Hz, eta=0:00:00, total=0:00:00, wall=07:47 IST
=> validation 51.53% of 1x196...Epoch=10/10 LR=0.00000 Time=0.709 Loss=1.160 Prec@1=72.022 Prec@5=90.532 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=07:47 IST
** validation 51.53% of 1x196...Epoch=10/10 LR=0.00000 Time=0.709 Loss=1.160 Prec@1=72.022 Prec@5=90.532 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=07:48 IST
** validation 51.53% of 1x196...Epoch=10/10 LR=0.00000 Time=0.651 Loss=1.171 Prec@1=71.728 Prec@5=90.356 rate=1.58 Hz, eta=0:01:00, total=0:01:03, wall=07:48 IST
** validation 100.00% of 1x196...Epoch=10/10 LR=0.00000 Time=0.651 Loss=1.171 Prec@1=71.728 Prec@5=90.356 rate=1.63 Hz, eta=0:00:00, total=0:01:59, wall=07:48 IST
[39m
