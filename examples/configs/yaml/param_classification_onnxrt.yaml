#################################################################################
# Copyright (c) 2018-2021, Texas Instruments Incorporated - http://www.ti.com
# All Rights Reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name of the copyright holder nor the names of its
#   contributors may be used to endorse or promote products derived from
#   this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#################################################################################


#################################################################################
# The following fields in this section are used by EDGEAI CPP.
# For EDGEAI inference, only these fields need to be specified.
#################################################################################

# Type of task that this model performs.
# Options: classification, detection, segmentation
task_type: classification

# Parameters used for pre-processing the input
# Currently supported pre-processing operations are
#   resizing, croping, mean subtraction, reversing channels (eg. RGB to BGR)
preprocess:
  # Backend resizer module
  # Options: cv2, pil
  backend: pil

  # Crop size - used to crop the resized input.
  # Options: a single integer or a list of two integers.
  #   if this is a single integer, a square crop is done.
  #   if this is a list [height,width], a rectangular crop is done.
  crop: 224

  # Data layout of the input tensor to be given out of pre-processing.
  # Options: NHWC, NCHW
  #   Typically tensorflow/tflite models use NHWC format, where as PyTorch/onnx models and MXNet models use NCHW format.
  data_layout: NCHW

  # Actual pixel interpolation type to be used the resizer.
  # If the backend is cv2, these interpolation modes are valid:
  #   cv::INTER_NEAREST, cv::INTER_LINEAR, cv::INTER_CUBIC, cv::INTER_AREA (default is cv::INTER_LINEAR)
  #   https://docs.opencv.org/4.5.2/da/d54/group__imgproc__transform.html
  # If the backend is pil, these interpolation modes are valid:
  #   PIL.Image.NEAREST, PIL.Image.BOX, PIL.Image.BILINEAR, PIL.Image.BICUBIC (default is PIL.Image.BILINEAR)
  #   https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.resize
  # Can specify null to use linear interpolation irrespective of the backend.
  interpolation: null

  # Resize size - used to resize the input.
  # Options: a single integer or a list of two integers.
  #   if this is a single integer, the smallest side of the image is resized to this size.
  #   if this is a list [height,width], a rectangular resize is done to fit the size exactly.
  resize: 256

  # If this option is enabled, aspect ration preserving resize is done
  # and the remaining region outside is filled with pad_color
  resize_with_pad: false

  # Pad color that is used only when resize_with_pad is set
  pad_color: 0
  
  # Reverse the order of channels - for example to convert RGB format to BGR.
  reverse_channels: false

# Parameters used to process or format the output prediction of the model
postprocess: {}

# Parameters to be passed to the metric function.
metric:
  # label_offset_pred is the offset to be added to the predicted offset to get the actual label value.
  # Options: and integer, list or a dictionary
  # For the classification models trained using tensorflow/models (https://github.com/tensorflow/models),
  #   this is typically -1 because, they use an extra class (that is not in the imagenet ground truth labels)
  #   in the beginning.
  # For classification models trained using torchvision (https://github.com/pytorch/vision), this is typically 0.
  # To map to different number of classes, eg. from 80 classes to 90 classes as in some in COCO detection,
  #   either a list or a dictionary can be used.
  label_offset_pred: -1

# Parameters for the inference session to be used
session:
  # Folder in which the imported model artifacts are located.
  artifacts_folder: artifacts

  # Folder in which the model is located. (eg. onnx, tflite, mxnet models are copied here)
  model_folder: model

  # The path to the actual model
  model_path: model/mobilenet_v1_1.0_224.onnx

  # Name that identifies the inference sesssion that can be used to infer the given artifacts
  # Options: tflitert, onnxrt, tvmdlr
  session_name: onnxrt

  # List of Mean values to be subtracted from the input tensor
  # The number of entries in the list must mach the number of channels in input tensor.
  input_mean:
  - 123.675
  - 116.28
  - 103.53

  # A list specifying scaling/multiplication to be done to the input values.
  # The number of entries in the list must mach the number of channels in input tensor.
  input_scale:
  - 0.017125
  - 0.017507
  - 0.017429

  # whether the input_mean and input_scale has been absorbed insode the model via operation inside the model or not
  # if this is true input_mean and input_scale should be null.
  input_optimization: false

  # Data layout of the input tensor to be given out of pre-processing.
  # Options: NHWC, NCHW
  #   Typically tensorflow/tflite models use NHWC format, where as PyTorch/onnx models and MXNet models use NCHW format.
  input_data_layout: NCHW

  # Details of the input to the model
  # Replace the name and shape with correct values
  # type should be as given by the runtime - tensor(uint8) for onnxruntime, and <class 'numpy.uint8'> - for tflite_runtime for utint8 type
  input_details:
  - name: input
    shape:
    - 1
    - 224
    - 224
    - 3
    type: tensor(uint8)

  # Details of the model output
  # Replace the name and shape with correct values
  # type should be as given by the runtime - tensor(uint8) for onnxruntime, and <class 'numpy.uint8'> - for tflite_runtime for utint8 type
  output_details:
  - name: MobilenetV1/Predictions/Reshape_1
    shape:
    - 1
    - 1001
    type: tensor(float)
